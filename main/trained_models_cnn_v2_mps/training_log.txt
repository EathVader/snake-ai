Logging to logs/PPO_CNN_V2/MaskablePPO_4
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 593      |
|    ep_rew_mean     | -2.84    |
| time/              |          |
|    fps             | 2480     |
|    iterations      | 1        |
|    time_elapsed    | 26       |
|    total_timesteps | 65536    |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 607         |
|    ep_rew_mean          | -5.35       |
| time/                   |             |
|    fps                  | 1613        |
|    iterations           | 2           |
|    time_elapsed         | 81          |
|    total_timesteps      | 131072      |
| train/                  |             |
|    approx_kl            | 0.011087131 |
|    clip_fraction        | 0.157       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.896      |
|    explained_variance   | -1.45       |
|    learning_rate        | 9.99e-05    |
|    loss                 | 8.88        |
|    n_updates            | 4           |
|    policy_gradient_loss | -0.00209    |
|    value_loss           | 32.5        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 637         |
|    ep_rew_mean          | -6.46       |
| time/                   |             |
|    fps                  | 1447        |
|    iterations           | 3           |
|    time_elapsed         | 135         |
|    total_timesteps      | 196608      |
| train/                  |             |
|    approx_kl            | 0.011266109 |
|    clip_fraction        | 0.137       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.865      |
|    explained_variance   | 0.61        |
|    learning_rate        | 9.99e-05    |
|    loss                 | 2.04        |
|    n_updates            | 8           |
|    policy_gradient_loss | -0.0069     |
|    value_loss           | 6.56        |
-----------------------------------------
Eval num_timesteps=249984, episode_reward=-10.34 +/- 0.50
Episode length: 6.50 +/- 1.91
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 6.5        |
|    mean_reward          | -10.3      |
| time/                   |            |
|    total_timesteps      | 249984     |
| train/                  |            |
|    approx_kl            | 0.01076737 |
|    clip_fraction        | 0.121      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.848     |
|    explained_variance   | 0.708      |
|    learning_rate        | 9.98e-05   |
|    loss                 | 1.23       |
|    n_updates            | 12         |
|    policy_gradient_loss | -0.00743   |
|    value_loss           | 3.53       |
----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 545      |
|    ep_rew_mean     | 5.53     |
| time/              |          |
|    fps             | 1342     |
|    iterations      | 4        |
|    time_elapsed    | 195      |
|    total_timesteps | 262144   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 527         |
|    ep_rew_mean          | 16          |
| time/                   |             |
|    fps                  | 979         |
|    iterations           | 5           |
|    time_elapsed         | 334         |
|    total_timesteps      | 327680      |
| train/                  |             |
|    approx_kl            | 0.010044414 |
|    clip_fraction        | 0.11        |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.831      |
|    explained_variance   | 0.636       |
|    learning_rate        | 9.97e-05    |
|    loss                 | 1.87        |
|    n_updates            | 16          |
|    policy_gradient_loss | -0.00876    |
|    value_loss           | 4.94        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 415         |
|    ep_rew_mean          | 31.4        |
| time/                   |             |
|    fps                  | 803         |
|    iterations           | 6           |
|    time_elapsed         | 489         |
|    total_timesteps      | 393216      |
| train/                  |             |
|    approx_kl            | 0.011309424 |
|    clip_fraction        | 0.128       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.816      |
|    explained_variance   | 0.54        |
|    learning_rate        | 9.97e-05    |
|    loss                 | 2.96        |
|    n_updates            | 20          |
|    policy_gradient_loss | -0.00962    |
|    value_loss           | 7.27        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 375         |
|    ep_rew_mean          | 42          |
| time/                   |             |
|    fps                  | 714         |
|    iterations           | 7           |
|    time_elapsed         | 641         |
|    total_timesteps      | 458752      |
| train/                  |             |
|    approx_kl            | 0.012511303 |
|    clip_fraction        | 0.137       |
|    clip_range           | 0.199       |
|    entropy_loss         | -0.801      |
|    explained_variance   | 0.446       |
|    learning_rate        | 9.96e-05    |
|    loss                 | 4.23        |
|    n_updates            | 24          |
|    policy_gradient_loss | -0.00754    |
|    value_loss           | 12.1        |
-----------------------------------------
Eval num_timesteps=499968, episode_reward=-9.75 +/- 0.44
Episode length: 8.40 +/- 3.20
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 8.4         |
|    mean_reward          | -9.75       |
| time/                   |             |
|    total_timesteps      | 499968      |
| train/                  |             |
|    approx_kl            | 0.014054313 |
|    clip_fraction        | 0.146       |
|    clip_range           | 0.199       |
|    entropy_loss         | -0.784      |
|    explained_variance   | 0.412       |
|    learning_rate        | 9.95e-05    |
|    loss                 | 8.17        |
|    n_updates            | 28          |
|    policy_gradient_loss | -0.00657    |
|    value_loss           | 16.6        |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 362      |
|    ep_rew_mean     | 50.5     |
| time/              |          |
|    fps             | 637      |
|    iterations      | 8        |
|    time_elapsed    | 822      |
|    total_timesteps | 524288   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 335         |
|    ep_rew_mean          | 64.6        |
| time/                   |             |
|    fps                  | 604         |
|    iterations           | 9           |
|    time_elapsed         | 976         |
|    total_timesteps      | 589824      |
| train/                  |             |
|    approx_kl            | 0.016208624 |
|    clip_fraction        | 0.151       |
|    clip_range           | 0.199       |
|    entropy_loss         | -0.77       |
|    explained_variance   | 0.342       |
|    learning_rate        | 9.95e-05    |
|    loss                 | 7.92        |
|    n_updates            | 32          |
|    policy_gradient_loss | -0.00459    |
|    value_loss           | 19.5        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 319         |
|    ep_rew_mean          | 72.3        |
| time/                   |             |
|    fps                  | 587         |
|    iterations           | 10          |
|    time_elapsed         | 1116        |
|    total_timesteps      | 655360      |
| train/                  |             |
|    approx_kl            | 0.018856175 |
|    clip_fraction        | 0.17        |
|    clip_range           | 0.199       |
|    entropy_loss         | -0.739      |
|    explained_variance   | 0.311       |
|    learning_rate        | 9.94e-05    |
|    loss                 | 9.52        |
|    n_updates            | 36          |
|    policy_gradient_loss | -0.00276    |
|    value_loss           | 23.6        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 356         |
|    ep_rew_mean          | 90.5        |
| time/                   |             |
|    fps                  | 578         |
|    iterations           | 11          |
|    time_elapsed         | 1247        |
|    total_timesteps      | 720896      |
| train/                  |             |
|    approx_kl            | 0.021249821 |
|    clip_fraction        | 0.2         |
|    clip_range           | 0.199       |
|    entropy_loss         | -0.726      |
|    explained_variance   | 0.229       |
|    learning_rate        | 9.94e-05    |
|    loss                 | 11.1        |
|    n_updates            | 40          |
|    policy_gradient_loss | 0.000854    |
|    value_loss           | 27.2        |
-----------------------------------------
Eval num_timesteps=749952, episode_reward=-6.30 +/- 5.06
Episode length: 10.90 +/- 6.01
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 10.9        |
|    mean_reward          | -6.3        |
| time/                   |             |
|    total_timesteps      | 749952      |
| train/                  |             |
|    approx_kl            | 0.023886982 |
|    clip_fraction        | 0.215       |
|    clip_range           | 0.199       |
|    entropy_loss         | -0.697      |
|    explained_variance   | 0.158       |
|    learning_rate        | 9.93e-05    |
|    loss                 | 11.2        |
|    n_updates            | 44          |
|    policy_gradient_loss | 0.00362     |
|    value_loss           | 30.8        |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 351      |
|    ep_rew_mean     | 102      |
| time/              |          |
|    fps             | 573      |
|    iterations      | 12       |
|    time_elapsed    | 1370     |
|    total_timesteps | 786432   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 371         |
|    ep_rew_mean          | 120         |
| time/                   |             |
|    fps                  | 566         |
|    iterations           | 13          |
|    time_elapsed         | 1503        |
|    total_timesteps      | 851968      |
| train/                  |             |
|    approx_kl            | 0.027378302 |
|    clip_fraction        | 0.216       |
|    clip_range           | 0.199       |
|    entropy_loss         | -0.661      |
|    explained_variance   | 0.227       |
|    learning_rate        | 9.92e-05    |
|    loss                 | 11.9        |
|    n_updates            | 48          |
|    policy_gradient_loss | 0.0053      |
|    value_loss           | 34.5        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 381         |
|    ep_rew_mean          | 134         |
| time/                   |             |
|    fps                  | 563         |
|    iterations           | 14          |
|    time_elapsed         | 1629        |
|    total_timesteps      | 917504      |
| train/                  |             |
|    approx_kl            | 0.028491475 |
|    clip_fraction        | 0.231       |
|    clip_range           | 0.199       |
|    entropy_loss         | -0.64       |
|    explained_variance   | 0.181       |
|    learning_rate        | 9.92e-05    |
|    loss                 | 15          |
|    n_updates            | 52          |
|    policy_gradient_loss | 0.00884     |
|    value_loss           | 39.4        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 366         |
|    ep_rew_mean          | 131         |
| time/                   |             |
|    fps                  | 562         |
|    iterations           | 15          |
|    time_elapsed         | 1748        |
|    total_timesteps      | 983040      |
| train/                  |             |
|    approx_kl            | 0.033574678 |
|    clip_fraction        | 0.233       |
|    clip_range           | 0.199       |
|    entropy_loss         | -0.626      |
|    explained_variance   | 0.176       |
|    learning_rate        | 9.91e-05    |
|    loss                 | 14.8        |
|    n_updates            | 56          |
|    policy_gradient_loss | 0.00944     |
|    value_loss           | 42.5        |
-----------------------------------------
Eval num_timesteps=999936, episode_reward=-8.10 +/- 4.36
Episode length: 8.90 +/- 4.81
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 8.9        |
|    mean_reward          | -8.1       |
| time/                   |            |
|    total_timesteps      | 999936     |
| train/                  |            |
|    approx_kl            | 0.03753111 |
|    clip_fraction        | 0.25       |
|    clip_range           | 0.199      |
|    entropy_loss         | -0.6       |
|    explained_variance   | 0.142      |
|    learning_rate        | 9.9e-05    |
|    loss                 | 17.3       |
|    n_updates            | 60         |
|    policy_gradient_loss | 0.0138     |
|    value_loss           | 44.3       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 378      |
|    ep_rew_mean     | 128      |
| time/              |          |
|    fps             | 558      |
|    iterations      | 16       |
|    time_elapsed    | 1876     |
|    total_timesteps | 1048576  |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 371         |
|    ep_rew_mean          | 132         |
| time/                   |             |
|    fps                  | 546         |
|    iterations           | 17          |
|    time_elapsed         | 2040        |
|    total_timesteps      | 1114112     |
| train/                  |             |
|    approx_kl            | 0.040525302 |
|    clip_fraction        | 0.258       |
|    clip_range           | 0.198       |
|    entropy_loss         | -0.584      |
|    explained_variance   | 0.179       |
|    learning_rate        | 9.9e-05     |
|    loss                 | 16.6        |
|    n_updates            | 64          |
|    policy_gradient_loss | 0.0146      |
|    value_loss           | 43.5        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 393         |
|    ep_rew_mean          | 155         |
| time/                   |             |
|    fps                  | 543         |
|    iterations           | 18          |
|    time_elapsed         | 2170        |
|    total_timesteps      | 1179648     |
| train/                  |             |
|    approx_kl            | 0.041321497 |
|    clip_fraction        | 0.251       |
|    clip_range           | 0.198       |
|    entropy_loss         | -0.56       |
|    explained_variance   | 0.153       |
|    learning_rate        | 9.89e-05    |
|    loss                 | 14.2        |
|    n_updates            | 68          |
|    policy_gradient_loss | 0.0135      |
|    value_loss           | 45.7        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 393         |
|    ep_rew_mean          | 156         |
| time/                   |             |
|    fps                  | 541         |
|    iterations           | 19          |
|    time_elapsed         | 2299        |
|    total_timesteps      | 1245184     |
| train/                  |             |
|    approx_kl            | 0.046002544 |
|    clip_fraction        | 0.251       |
|    clip_range           | 0.198       |
|    entropy_loss         | -0.516      |
|    explained_variance   | 0.231       |
|    learning_rate        | 9.88e-05    |
|    loss                 | 13.5        |
|    n_updates            | 72          |
|    policy_gradient_loss | 0.0157      |
|    value_loss           | 44.5        |
-----------------------------------------
Eval num_timesteps=1249920, episode_reward=-7.87 +/- 6.99
Episode length: 8.50 +/- 4.52
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 8.5        |
|    mean_reward          | -7.87      |
| time/                   |            |
|    total_timesteps      | 1249920    |
| train/                  |            |
|    approx_kl            | 0.04576553 |
|    clip_fraction        | 0.249      |
|    clip_range           | 0.198      |
|    entropy_loss         | -0.503     |
|    explained_variance   | 0.2        |
|    learning_rate        | 9.88e-05   |
|    loss                 | 17.1       |
|    n_updates            | 76         |
|    policy_gradient_loss | 0.0171     |
|    value_loss           | 51.4       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 391      |
|    ep_rew_mean     | 157      |
| time/              |          |
|    fps             | 539      |
|    iterations      | 20       |
|    time_elapsed    | 2429     |
|    total_timesteps | 1310720  |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 412         |
|    ep_rew_mean          | 144         |
| time/                   |             |
|    fps                  | 537         |
|    iterations           | 21          |
|    time_elapsed         | 2562        |
|    total_timesteps      | 1376256     |
| train/                  |             |
|    approx_kl            | 0.056496162 |
|    clip_fraction        | 0.256       |
|    clip_range           | 0.198       |
|    entropy_loss         | -0.482      |
|    explained_variance   | 0.214       |
|    learning_rate        | 9.87e-05    |
|    loss                 | 16          |
|    n_updates            | 80          |
|    policy_gradient_loss | 0.0199      |
|    value_loss           | 50.6        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 424         |
|    ep_rew_mean          | 152         |
| time/                   |             |
|    fps                  | 537         |
|    iterations           | 22          |
|    time_elapsed         | 2683        |
|    total_timesteps      | 1441792     |
| train/                  |             |
|    approx_kl            | 0.045049578 |
|    clip_fraction        | 0.238       |
|    clip_range           | 0.198       |
|    entropy_loss         | -0.473      |
|    explained_variance   | 0.228       |
|    learning_rate        | 9.86e-05    |
|    loss                 | 14.7        |
|    n_updates            | 84          |
|    policy_gradient_loss | 0.0165      |
|    value_loss           | 48          |
-----------------------------------------
Eval num_timesteps=1499904, episode_reward=-8.07 +/- 6.85
Episode length: 9.00 +/- 4.52
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 9           |
|    mean_reward          | -8.07       |
| time/                   |             |
|    total_timesteps      | 1499904     |
| train/                  |             |
|    approx_kl            | 0.051178057 |
|    clip_fraction        | 0.245       |
|    clip_range           | 0.198       |
|    entropy_loss         | -0.463      |
|    explained_variance   | 0.238       |
|    learning_rate        | 9.86e-05    |
|    loss                 | 15          |
|    n_updates            | 88          |
|    policy_gradient_loss | 0.018       |
|    value_loss           | 47.5        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 431      |
|    ep_rew_mean     | 159      |
| time/              |          |
|    fps             | 535      |
|    iterations      | 23       |
|    time_elapsed    | 2813     |
|    total_timesteps | 1507328  |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 488        |
|    ep_rew_mean          | 175        |
| time/                   |            |
|    fps                  | 535        |
|    iterations           | 24         |
|    time_elapsed         | 2939       |
|    total_timesteps      | 1572864    |
| train/                  |            |
|    approx_kl            | 0.05059736 |
|    clip_fraction        | 0.243      |
|    clip_range           | 0.198      |
|    entropy_loss         | -0.444     |
|    explained_variance   | 0.225      |
|    learning_rate        | 9.85e-05   |
|    loss                 | 13.9       |
|    n_updates            | 92         |
|    policy_gradient_loss | 0.0221     |
|    value_loss           | 48.4       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 422        |
|    ep_rew_mean          | 143        |
| time/                   |            |
|    fps                  | 534        |
|    iterations           | 25         |
|    time_elapsed         | 3065       |
|    total_timesteps      | 1638400    |
| train/                  |            |
|    approx_kl            | 0.05166822 |
|    clip_fraction        | 0.232      |
|    clip_range           | 0.198      |
|    entropy_loss         | -0.427     |
|    explained_variance   | 0.207      |
|    learning_rate        | 9.84e-05   |
|    loss                 | 14.7       |
|    n_updates            | 96         |
|    policy_gradient_loss | 0.0195     |
|    value_loss           | 46.1       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 480         |
|    ep_rew_mean          | 177         |
| time/                   |             |
|    fps                  | 533         |
|    iterations           | 26          |
|    time_elapsed         | 3191        |
|    total_timesteps      | 1703936     |
| train/                  |             |
|    approx_kl            | 0.054706287 |
|    clip_fraction        | 0.229       |
|    clip_range           | 0.198       |
|    entropy_loss         | -0.416      |
|    explained_variance   | 0.263       |
|    learning_rate        | 9.84e-05    |
|    loss                 | 16.1        |
|    n_updates            | 100         |
|    policy_gradient_loss | 0.019       |
|    value_loss           | 49.5        |
-----------------------------------------
Eval num_timesteps=1749888, episode_reward=-5.59 +/- 5.39
Episode length: 9.70 +/- 5.29
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 9.7         |
|    mean_reward          | -5.59       |
| time/                   |             |
|    total_timesteps      | 1749888     |
| train/                  |             |
|    approx_kl            | 0.053898644 |
|    clip_fraction        | 0.225       |
|    clip_range           | 0.197       |
|    entropy_loss         | -0.391      |
|    explained_variance   | 0.279       |
|    learning_rate        | 9.83e-05    |
|    loss                 | 14.7        |
|    n_updates            | 104         |
|    policy_gradient_loss | 0.0205      |
|    value_loss           | 48.2        |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 427      |
|    ep_rew_mean     | 154      |
| time/              |          |
|    fps             | 532      |
|    iterations      | 27       |
|    time_elapsed    | 3320     |
|    total_timesteps | 1769472  |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 443         |
|    ep_rew_mean          | 163         |
| time/                   |             |
|    fps                  | 532         |
|    iterations           | 28          |
|    time_elapsed         | 3446        |
|    total_timesteps      | 1835008     |
| train/                  |             |
|    approx_kl            | 0.053710245 |
|    clip_fraction        | 0.21        |
|    clip_range           | 0.197       |
|    entropy_loss         | -0.376      |
|    explained_variance   | 0.302       |
|    learning_rate        | 9.82e-05    |
|    loss                 | 14          |
|    n_updates            | 108         |
|    policy_gradient_loss | 0.0188      |
|    value_loss           | 48.4        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 460        |
|    ep_rew_mean          | 173        |
| time/                   |            |
|    fps                  | 531        |
|    iterations           | 29         |
|    time_elapsed         | 3573       |
|    total_timesteps      | 1900544    |
| train/                  |            |
|    approx_kl            | 0.05376471 |
|    clip_fraction        | 0.218      |
|    clip_range           | 0.197      |
|    entropy_loss         | -0.375     |
|    explained_variance   | 0.31       |
|    learning_rate        | 9.82e-05   |
|    loss                 | 15         |
|    n_updates            | 112        |
|    policy_gradient_loss | 0.0203     |
|    value_loss           | 47.8       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 439        |
|    ep_rew_mean          | 165        |
| time/                   |            |
|    fps                  | 530        |
|    iterations           | 30         |
|    time_elapsed         | 3708       |
|    total_timesteps      | 1966080    |
| train/                  |            |
|    approx_kl            | 0.05563084 |
|    clip_fraction        | 0.211      |
|    clip_range           | 0.197      |
|    entropy_loss         | -0.357     |
|    explained_variance   | 0.29       |
|    learning_rate        | 9.81e-05   |
|    loss                 | 15.4       |
|    n_updates            | 116        |
|    policy_gradient_loss | 0.0198     |
|    value_loss           | 48.7       |
----------------------------------------
Eval num_timesteps=1999872, episode_reward=-8.95 +/- 3.40
Episode length: 5.90 +/- 1.81
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 5.9        |
|    mean_reward          | -8.95      |
| time/                   |            |
|    total_timesteps      | 1999872    |
| train/                  |            |
|    approx_kl            | 0.04945631 |
|    clip_fraction        | 0.19       |
|    clip_range           | 0.197      |
|    entropy_loss         | -0.333     |
|    explained_variance   | 0.293      |
|    learning_rate        | 9.81e-05   |
|    loss                 | 17.3       |
|    n_updates            | 120        |
|    policy_gradient_loss | 0.017      |
|    value_loss           | 49.5       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 512      |
|    ep_rew_mean     | 199      |
| time/              |          |
|    fps             | 526      |
|    iterations      | 31       |
|    time_elapsed    | 3859     |
|    total_timesteps | 2031616  |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 488         |
|    ep_rew_mean          | 180         |
| time/                   |             |
|    fps                  | 524         |
|    iterations           | 32          |
|    time_elapsed         | 3998        |
|    total_timesteps      | 2097152     |
| train/                  |             |
|    approx_kl            | 0.048977707 |
|    clip_fraction        | 0.189       |
|    clip_range           | 0.197       |
|    entropy_loss         | -0.324      |
|    explained_variance   | 0.319       |
|    learning_rate        | 9.8e-05     |
|    loss                 | 13.5        |
|    n_updates            | 124         |
|    policy_gradient_loss | 0.0167      |
|    value_loss           | 44.8        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 527        |
|    ep_rew_mean          | 211        |
| time/                   |            |
|    fps                  | 523        |
|    iterations           | 33         |
|    time_elapsed         | 4128       |
|    total_timesteps      | 2162688    |
| train/                  |            |
|    approx_kl            | 0.04836152 |
|    clip_fraction        | 0.184      |
|    clip_range           | 0.197      |
|    entropy_loss         | -0.322     |
|    explained_variance   | 0.364      |
|    learning_rate        | 9.79e-05   |
|    loss                 | 14.5       |
|    n_updates            | 128        |
|    policy_gradient_loss | 0.016      |
|    value_loss           | 45.3       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 491        |
|    ep_rew_mean          | 189        |
| time/                   |            |
|    fps                  | 523        |
|    iterations           | 34         |
|    time_elapsed         | 4258       |
|    total_timesteps      | 2228224    |
| train/                  |            |
|    approx_kl            | 0.05060874 |
|    clip_fraction        | 0.18       |
|    clip_range           | 0.197      |
|    entropy_loss         | -0.309     |
|    explained_variance   | 0.372      |
|    learning_rate        | 9.79e-05   |
|    loss                 | 14.5       |
|    n_updates            | 132        |
|    policy_gradient_loss | 0.0162     |
|    value_loss           | 46.7       |
----------------------------------------
Eval num_timesteps=2249856, episode_reward=-5.71 +/- 10.81
Episode length: 11.40 +/- 9.67
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 11.4       |
|    mean_reward          | -5.71      |
| time/                   |            |
|    total_timesteps      | 2249856    |
| train/                  |            |
|    approx_kl            | 0.04987663 |
|    clip_fraction        | 0.181      |
|    clip_range           | 0.197      |
|    entropy_loss         | -0.309     |
|    explained_variance   | 0.419      |
|    learning_rate        | 9.78e-05   |
|    loss                 | 14.2       |
|    n_updates            | 136        |
|    policy_gradient_loss | 0.0179     |
|    value_loss           | 46.1       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 518      |
|    ep_rew_mean     | 210      |
| time/              |          |
|    fps             | 521      |
|    iterations      | 35       |
|    time_elapsed    | 4394     |
|    total_timesteps | 2293760  |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 565         |
|    ep_rew_mean          | 218         |
| time/                   |             |
|    fps                  | 522         |
|    iterations           | 36          |
|    time_elapsed         | 4518        |
|    total_timesteps      | 2359296     |
| train/                  |             |
|    approx_kl            | 0.051163115 |
|    clip_fraction        | 0.174       |
|    clip_range           | 0.197       |
|    entropy_loss         | -0.294      |
|    explained_variance   | 0.364       |
|    learning_rate        | 9.77e-05    |
|    loss                 | 14.4        |
|    n_updates            | 140         |
|    policy_gradient_loss | 0.0182      |
|    value_loss           | 44.8        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 575        |
|    ep_rew_mean          | 207        |
| time/                   |            |
|    fps                  | 522        |
|    iterations           | 37         |
|    time_elapsed         | 4638       |
|    total_timesteps      | 2424832    |
| train/                  |            |
|    approx_kl            | 0.05051696 |
|    clip_fraction        | 0.165      |
|    clip_range           | 0.196      |
|    entropy_loss         | -0.268     |
|    explained_variance   | 0.345      |
|    learning_rate        | 9.77e-05   |
|    loss                 | 13.4       |
|    n_updates            | 144        |
|    policy_gradient_loss | 0.0169     |
|    value_loss           | 45.8       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 529        |
|    ep_rew_mean          | 215        |
| time/                   |            |
|    fps                  | 523        |
|    iterations           | 38         |
|    time_elapsed         | 4760       |
|    total_timesteps      | 2490368    |
| train/                  |            |
|    approx_kl            | 0.04602851 |
|    clip_fraction        | 0.157      |
|    clip_range           | 0.196      |
|    entropy_loss         | -0.268     |
|    explained_variance   | 0.39       |
|    learning_rate        | 9.76e-05   |
|    loss                 | 11.6       |
|    n_updates            | 148        |
|    policy_gradient_loss | 0.0141     |
|    value_loss           | 42.9       |
----------------------------------------
Eval num_timesteps=2499840, episode_reward=-9.19 +/- 3.74
Episode length: 9.60 +/- 4.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 9.6       |
|    mean_reward          | -9.19     |
| time/                   |           |
|    total_timesteps      | 2499840   |
| train/                  |           |
|    approx_kl            | 0.0451549 |
|    clip_fraction        | 0.143     |
|    clip_range           | 0.196     |
|    entropy_loss         | -0.236    |
|    explained_variance   | 0.386     |
|    learning_rate        | 9.75e-05  |
|    loss                 | 13.1      |
|    n_updates            | 152       |
|    policy_gradient_loss | 0.0148    |
|    value_loss           | 46.3      |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 577      |
|    ep_rew_mean     | 214      |
| time/              |          |
|    fps             | 523      |
|    iterations      | 39       |
|    time_elapsed    | 4885     |
|    total_timesteps | 2555904  |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 617         |
|    ep_rew_mean          | 246         |
| time/                   |             |
|    fps                  | 523         |
|    iterations           | 40          |
|    time_elapsed         | 5007        |
|    total_timesteps      | 2621440     |
| train/                  |             |
|    approx_kl            | 0.044287976 |
|    clip_fraction        | 0.143       |
|    clip_range           | 0.196       |
|    entropy_loss         | -0.233      |
|    explained_variance   | 0.34        |
|    learning_rate        | 9.75e-05    |
|    loss                 | 12.6        |
|    n_updates            | 156         |
|    policy_gradient_loss | 0.0156      |
|    value_loss           | 41.3        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 516         |
|    ep_rew_mean          | 199         |
| time/                   |             |
|    fps                  | 523         |
|    iterations           | 41          |
|    time_elapsed         | 5128        |
|    total_timesteps      | 2686976     |
| train/                  |             |
|    approx_kl            | 0.045635857 |
|    clip_fraction        | 0.144       |
|    clip_range           | 0.196       |
|    entropy_loss         | -0.222      |
|    explained_variance   | 0.454       |
|    learning_rate        | 9.74e-05    |
|    loss                 | 11.3        |
|    n_updates            | 160         |
|    policy_gradient_loss | 0.0143      |
|    value_loss           | 40.8        |
-----------------------------------------
Eval num_timesteps=2749824, episode_reward=-8.71 +/- 3.26
Episode length: 8.00 +/- 2.14
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 8           |
|    mean_reward          | -8.71       |
| time/                   |             |
|    total_timesteps      | 2749824     |
| train/                  |             |
|    approx_kl            | 0.042755358 |
|    clip_fraction        | 0.141       |
|    clip_range           | 0.196       |
|    entropy_loss         | -0.231      |
|    explained_variance   | 0.362       |
|    learning_rate        | 9.73e-05    |
|    loss                 | 14.7        |
|    n_updates            | 164         |
|    policy_gradient_loss | 0.014       |
|    value_loss           | 47          |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 613      |
|    ep_rew_mean     | 234      |
| time/              |          |
|    fps             | 524      |
|    iterations      | 42       |
|    time_elapsed    | 5250     |
|    total_timesteps | 2752512  |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 604         |
|    ep_rew_mean          | 246         |
| time/                   |             |
|    fps                  | 524         |
|    iterations           | 43          |
|    time_elapsed         | 5372        |
|    total_timesteps      | 2818048     |
| train/                  |             |
|    approx_kl            | 0.044868268 |
|    clip_fraction        | 0.137       |
|    clip_range           | 0.196       |
|    entropy_loss         | -0.217      |
|    explained_variance   | 0.379       |
|    learning_rate        | 9.73e-05    |
|    loss                 | 12.8        |
|    n_updates            | 168         |
|    policy_gradient_loss | 0.0143      |
|    value_loss           | 43.2        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 616         |
|    ep_rew_mean          | 224         |
| time/                   |             |
|    fps                  | 524         |
|    iterations           | 44          |
|    time_elapsed         | 5494        |
|    total_timesteps      | 2883584     |
| train/                  |             |
|    approx_kl            | 0.041902754 |
|    clip_fraction        | 0.128       |
|    clip_range           | 0.196       |
|    entropy_loss         | -0.208      |
|    explained_variance   | 0.44        |
|    learning_rate        | 9.72e-05    |
|    loss                 | 13.3        |
|    n_updates            | 172         |
|    policy_gradient_loss | 0.011       |
|    value_loss           | 40.6        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 631         |
|    ep_rew_mean          | 262         |
| time/                   |             |
|    fps                  | 525         |
|    iterations           | 45          |
|    time_elapsed         | 5615        |
|    total_timesteps      | 2949120     |
| train/                  |             |
|    approx_kl            | 0.044131186 |
|    clip_fraction        | 0.138       |
|    clip_range           | 0.196       |
|    entropy_loss         | -0.228      |
|    explained_variance   | 0.462       |
|    learning_rate        | 9.71e-05    |
|    loss                 | 13.2        |
|    n_updates            | 176         |
|    policy_gradient_loss | 0.0123      |
|    value_loss           | 42.2        |
-----------------------------------------
Eval num_timesteps=2999808, episode_reward=-8.67 +/- 3.40
Episode length: 8.20 +/- 3.37
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 8.2         |
|    mean_reward          | -8.67       |
| time/                   |             |
|    total_timesteps      | 2999808     |
| train/                  |             |
|    approx_kl            | 0.041701198 |
|    clip_fraction        | 0.129       |
|    clip_range           | 0.196       |
|    entropy_loss         | -0.205      |
|    explained_variance   | 0.501       |
|    learning_rate        | 9.71e-05    |
|    loss                 | 12.2        |
|    n_updates            | 180         |
|    policy_gradient_loss | 0.0114      |
|    value_loss           | 41.3        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 583      |
|    ep_rew_mean     | 246      |
| time/              |          |
|    fps             | 525      |
|    iterations      | 46       |
|    time_elapsed    | 5740     |
|    total_timesteps | 3014656  |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 643        |
|    ep_rew_mean          | 270        |
| time/                   |            |
|    fps                  | 525        |
|    iterations           | 47         |
|    time_elapsed         | 5864       |
|    total_timesteps      | 3080192    |
| train/                  |            |
|    approx_kl            | 0.04715687 |
|    clip_fraction        | 0.137      |
|    clip_range           | 0.195      |
|    entropy_loss         | -0.205     |
|    explained_variance   | 0.493      |
|    learning_rate        | 9.7e-05    |
|    loss                 | 13.9       |
|    n_updates            | 184        |
|    policy_gradient_loss | 0.0137     |
|    value_loss           | 46         |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 581         |
|    ep_rew_mean          | 265         |
| time/                   |             |
|    fps                  | 525         |
|    iterations           | 48          |
|    time_elapsed         | 5988        |
|    total_timesteps      | 3145728     |
| train/                  |             |
|    approx_kl            | 0.045810126 |
|    clip_fraction        | 0.128       |
|    clip_range           | 0.195       |
|    entropy_loss         | -0.189      |
|    explained_variance   | 0.509       |
|    learning_rate        | 9.7e-05     |
|    loss                 | 11.3        |
|    n_updates            | 188         |
|    policy_gradient_loss | 0.0119      |
|    value_loss           | 39.7        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 604         |
|    ep_rew_mean          | 282         |
| time/                   |             |
|    fps                  | 525         |
|    iterations           | 49          |
|    time_elapsed         | 6111        |
|    total_timesteps      | 3211264     |
| train/                  |             |
|    approx_kl            | 0.043813728 |
|    clip_fraction        | 0.13        |
|    clip_range           | 0.195       |
|    entropy_loss         | -0.191      |
|    explained_variance   | 0.531       |
|    learning_rate        | 9.69e-05    |
|    loss                 | 13.9        |
|    n_updates            | 192         |
|    policy_gradient_loss | 0.0135      |
|    value_loss           | 46.1        |
-----------------------------------------
Eval num_timesteps=3249792, episode_reward=-9.28 +/- 3.52
Episode length: 6.90 +/- 1.51
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 6.9         |
|    mean_reward          | -9.28       |
| time/                   |             |
|    total_timesteps      | 3249792     |
| train/                  |             |
|    approx_kl            | 0.040451527 |
|    clip_fraction        | 0.113       |
|    clip_range           | 0.195       |
|    entropy_loss         | -0.169      |
|    explained_variance   | 0.483       |
|    learning_rate        | 9.68e-05    |
|    loss                 | 12.9        |
|    n_updates            | 196         |
|    policy_gradient_loss | 0.0135      |
|    value_loss           | 45.4        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 633      |
|    ep_rew_mean     | 281      |
| time/              |          |
|    fps             | 525      |
|    iterations      | 50       |
|    time_elapsed    | 6236     |
|    total_timesteps | 3276800  |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 661         |
|    ep_rew_mean          | 282         |
| time/                   |             |
|    fps                  | 525         |
|    iterations           | 51          |
|    time_elapsed         | 6357        |
|    total_timesteps      | 3342336     |
| train/                  |             |
|    approx_kl            | 0.040903755 |
|    clip_fraction        | 0.104       |
|    clip_range           | 0.195       |
|    entropy_loss         | -0.151      |
|    explained_variance   | 0.563       |
|    learning_rate        | 9.68e-05    |
|    loss                 | 11.5        |
|    n_updates            | 200         |
|    policy_gradient_loss | 0.00988     |
|    value_loss           | 42.6        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 646         |
|    ep_rew_mean          | 279         |
| time/                   |             |
|    fps                  | 526         |
|    iterations           | 52          |
|    time_elapsed         | 6475        |
|    total_timesteps      | 3407872     |
| train/                  |             |
|    approx_kl            | 0.036957905 |
|    clip_fraction        | 0.0962      |
|    clip_range           | 0.195       |
|    entropy_loss         | -0.143      |
|    explained_variance   | 0.571       |
|    learning_rate        | 9.67e-05    |
|    loss                 | 10.7        |
|    n_updates            | 204         |
|    policy_gradient_loss | 0.01        |
|    value_loss           | 39.3        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 581         |
|    ep_rew_mean          | 286         |
| time/                   |             |
|    fps                  | 526         |
|    iterations           | 53          |
|    time_elapsed         | 6598        |
|    total_timesteps      | 3473408     |
| train/                  |             |
|    approx_kl            | 0.033885766 |
|    clip_fraction        | 0.0961      |
|    clip_range           | 0.195       |
|    entropy_loss         | -0.15       |
|    explained_variance   | 0.6         |
|    learning_rate        | 9.66e-05    |
|    loss                 | 9.53        |
|    n_updates            | 208         |
|    policy_gradient_loss | 0.00898     |
|    value_loss           | 35.5        |
-----------------------------------------
Eval num_timesteps=3499776, episode_reward=-9.98 +/- 0.61
Episode length: 9.40 +/- 4.54
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 9.4         |
|    mean_reward          | -9.98       |
| time/                   |             |
|    total_timesteps      | 3499776     |
| train/                  |             |
|    approx_kl            | 0.040307634 |
|    clip_fraction        | 0.11        |
|    clip_range           | 0.195       |
|    entropy_loss         | -0.163      |
|    explained_variance   | 0.61        |
|    learning_rate        | 9.66e-05    |
|    loss                 | 13.2        |
|    n_updates            | 212         |
|    policy_gradient_loss | 0.0103      |
|    value_loss           | 43.2        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 631      |
|    ep_rew_mean     | 309      |
| time/              |          |
|    fps             | 526      |
|    iterations      | 54       |
|    time_elapsed    | 6721     |
|    total_timesteps | 3538944  |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 574        |
|    ep_rew_mean          | 289        |
| time/                   |            |
|    fps                  | 527        |
|    iterations           | 55         |
|    time_elapsed         | 6839       |
|    total_timesteps      | 3604480    |
| train/                  |            |
|    approx_kl            | 0.03909993 |
|    clip_fraction        | 0.0971     |
|    clip_range           | 0.195      |
|    entropy_loss         | -0.138     |
|    explained_variance   | 0.658      |
|    learning_rate        | 9.65e-05   |
|    loss                 | 14.1       |
|    n_updates            | 216        |
|    policy_gradient_loss | 0.01       |
|    value_loss           | 44.7       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 671         |
|    ep_rew_mean          | 304         |
| time/                   |             |
|    fps                  | 527         |
|    iterations           | 56          |
|    time_elapsed         | 6956        |
|    total_timesteps      | 3670016     |
| train/                  |             |
|    approx_kl            | 0.034854837 |
|    clip_fraction        | 0.0941      |
|    clip_range           | 0.195       |
|    entropy_loss         | -0.137      |
|    explained_variance   | 0.639       |
|    learning_rate        | 9.64e-05    |
|    loss                 | 13.2        |
|    n_updates            | 220         |
|    policy_gradient_loss | 0.0102      |
|    value_loss           | 42.2        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 574        |
|    ep_rew_mean          | 289        |
| time/                   |            |
|    fps                  | 528        |
|    iterations           | 57         |
|    time_elapsed         | 7072       |
|    total_timesteps      | 3735552    |
| train/                  |            |
|    approx_kl            | 0.04022273 |
|    clip_fraction        | 0.103      |
|    clip_range           | 0.194      |
|    entropy_loss         | -0.144     |
|    explained_variance   | 0.645      |
|    learning_rate        | 9.64e-05   |
|    loss                 | 11.8       |
|    n_updates            | 224        |
|    policy_gradient_loss | 0.00942    |
|    value_loss           | 37.4       |
----------------------------------------
Eval num_timesteps=3749760, episode_reward=-10.16 +/- 0.58
Episode length: 6.30 +/- 1.55
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 6.3        |
|    mean_reward          | -10.2      |
| time/                   |            |
|    total_timesteps      | 3749760    |
| train/                  |            |
|    approx_kl            | 0.04194153 |
|    clip_fraction        | 0.103      |
|    clip_range           | 0.194      |
|    entropy_loss         | -0.14      |
|    explained_variance   | 0.665      |
|    learning_rate        | 9.63e-05   |
|    loss                 | 14.5       |
|    n_updates            | 228        |
|    policy_gradient_loss | 0.0123     |
|    value_loss           | 44.2       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 612      |
|    ep_rew_mean     | 295      |
| time/              |          |
|    fps             | 528      |
|    iterations      | 58       |
|    time_elapsed    | 7192     |
|    total_timesteps | 3801088  |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 639         |
|    ep_rew_mean          | 303         |
| time/                   |             |
|    fps                  | 528         |
|    iterations           | 59          |
|    time_elapsed         | 7312        |
|    total_timesteps      | 3866624     |
| train/                  |             |
|    approx_kl            | 0.040918324 |
|    clip_fraction        | 0.108       |
|    clip_range           | 0.194       |
|    entropy_loss         | -0.155      |
|    explained_variance   | 0.692       |
|    learning_rate        | 9.62e-05    |
|    loss                 | 13.2        |
|    n_updates            | 232         |
|    policy_gradient_loss | 0.0104      |
|    value_loss           | 40.9        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 675        |
|    ep_rew_mean          | 324        |
| time/                   |            |
|    fps                  | 529        |
|    iterations           | 60         |
|    time_elapsed         | 7429       |
|    total_timesteps      | 3932160    |
| train/                  |            |
|    approx_kl            | 0.04219951 |
|    clip_fraction        | 0.103      |
|    clip_range           | 0.194      |
|    entropy_loss         | -0.146     |
|    explained_variance   | 0.661      |
|    learning_rate        | 9.62e-05   |
|    loss                 | 14.2       |
|    n_updates            | 236        |
|    policy_gradient_loss | 0.0106     |
|    value_loss           | 42.2       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 676         |
|    ep_rew_mean          | 323         |
| time/                   |             |
|    fps                  | 529         |
|    iterations           | 61          |
|    time_elapsed         | 7550        |
|    total_timesteps      | 3997696     |
| train/                  |             |
|    approx_kl            | 0.043856457 |
|    clip_fraction        | 0.106       |
|    clip_range           | 0.194       |
|    entropy_loss         | -0.15       |
|    explained_variance   | 0.642       |
|    learning_rate        | 9.61e-05    |
|    loss                 | 12.3        |
|    n_updates            | 240         |
|    policy_gradient_loss | 0.0102      |
|    value_loss           | 38.4        |
-----------------------------------------
Eval num_timesteps=3999744, episode_reward=-6.44 +/- 5.38
Episode length: 10.50 +/- 5.26
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 10.5        |
|    mean_reward          | -6.44       |
| time/                   |             |
|    total_timesteps      | 3999744     |
| train/                  |             |
|    approx_kl            | 0.037142627 |
|    clip_fraction        | 0.0949      |
|    clip_range           | 0.194       |
|    entropy_loss         | -0.138      |
|    explained_variance   | 0.685       |
|    learning_rate        | 9.6e-05     |
|    loss                 | 10.7        |
|    n_updates            | 244         |
|    policy_gradient_loss | 0.00795     |
|    value_loss           | 37.7        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 666      |
|    ep_rew_mean     | 347      |
| time/              |          |
|    fps             | 529      |
|    iterations      | 62       |
|    time_elapsed    | 7673     |
|    total_timesteps | 4063232  |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 616         |
|    ep_rew_mean          | 282         |
| time/                   |             |
|    fps                  | 529         |
|    iterations           | 63          |
|    time_elapsed         | 7794        |
|    total_timesteps      | 4128768     |
| train/                  |             |
|    approx_kl            | 0.034636967 |
|    clip_fraction        | 0.0859      |
|    clip_range           | 0.194       |
|    entropy_loss         | -0.124      |
|    explained_variance   | 0.719       |
|    learning_rate        | 9.6e-05     |
|    loss                 | 13.4        |
|    n_updates            | 248         |
|    policy_gradient_loss | 0.0106      |
|    value_loss           | 41.6        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 667        |
|    ep_rew_mean          | 324        |
| time/                   |            |
|    fps                  | 530        |
|    iterations           | 64         |
|    time_elapsed         | 7911       |
|    total_timesteps      | 4194304    |
| train/                  |            |
|    approx_kl            | 0.04337932 |
|    clip_fraction        | 0.101      |
|    clip_range           | 0.194      |
|    entropy_loss         | -0.134     |
|    explained_variance   | 0.679      |
|    learning_rate        | 9.59e-05   |
|    loss                 | 13.4       |
|    n_updates            | 252        |
|    policy_gradient_loss | 0.0105     |
|    value_loss           | 43.6       |
----------------------------------------
Eval num_timesteps=4249728, episode_reward=-10.16 +/- 0.48
Episode length: 5.70 +/- 1.10
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 5.7         |
|    mean_reward          | -10.2       |
| time/                   |             |
|    total_timesteps      | 4249728     |
| train/                  |             |
|    approx_kl            | 0.039539166 |
|    clip_fraction        | 0.0861      |
|    clip_range           | 0.194       |
|    entropy_loss         | -0.114      |
|    explained_variance   | 0.706       |
|    learning_rate        | 9.58e-05    |
|    loss                 | 12.7        |
|    n_updates            | 256         |
|    policy_gradient_loss | 0.0101      |
|    value_loss           | 41.3        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 677      |
|    ep_rew_mean     | 334      |
| time/              |          |
|    fps             | 530      |
|    iterations      | 65       |
|    time_elapsed    | 8026     |
|    total_timesteps | 4259840  |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 656         |
|    ep_rew_mean          | 320         |
| time/                   |             |
|    fps                  | 531         |
|    iterations           | 66          |
|    time_elapsed         | 8143        |
|    total_timesteps      | 4325376     |
| train/                  |             |
|    approx_kl            | 0.036048267 |
|    clip_fraction        | 0.0884      |
|    clip_range           | 0.194       |
|    entropy_loss         | -0.115      |
|    explained_variance   | 0.725       |
|    learning_rate        | 9.58e-05    |
|    loss                 | 11.2        |
|    n_updates            | 260         |
|    policy_gradient_loss | 0.0104      |
|    value_loss           | 38.8        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 703        |
|    ep_rew_mean          | 350        |
| time/                   |            |
|    fps                  | 531        |
|    iterations           | 67         |
|    time_elapsed         | 8264       |
|    total_timesteps      | 4390912    |
| train/                  |            |
|    approx_kl            | 0.04394129 |
|    clip_fraction        | 0.0882     |
|    clip_range           | 0.194      |
|    entropy_loss         | -0.117     |
|    explained_variance   | 0.718      |
|    learning_rate        | 9.57e-05   |
|    loss                 | 13.1       |
|    n_updates            | 264        |
|    policy_gradient_loss | 0.00807    |
|    value_loss           | 39.5       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 671         |
|    ep_rew_mean          | 338         |
| time/                   |             |
|    fps                  | 531         |
|    iterations           | 68          |
|    time_elapsed         | 8388        |
|    total_timesteps      | 4456448     |
| train/                  |             |
|    approx_kl            | 0.035969384 |
|    clip_fraction        | 0.088       |
|    clip_range           | 0.193       |
|    entropy_loss         | -0.117      |
|    explained_variance   | 0.703       |
|    learning_rate        | 9.57e-05    |
|    loss                 | 13.1        |
|    n_updates            | 268         |
|    policy_gradient_loss | 0.00969     |
|    value_loss           | 42.7        |
-----------------------------------------
Eval num_timesteps=4499712, episode_reward=-7.78 +/- 4.42
Episode length: 6.70 +/- 1.68
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 6.7         |
|    mean_reward          | -7.78       |
| time/                   |             |
|    total_timesteps      | 4499712     |
| train/                  |             |
|    approx_kl            | 0.038508765 |
|    clip_fraction        | 0.0905      |
|    clip_range           | 0.193       |
|    entropy_loss         | -0.124      |
|    explained_variance   | 0.74        |
|    learning_rate        | 9.56e-05    |
|    loss                 | 12.4        |
|    n_updates            | 272         |
|    policy_gradient_loss | 0.00907     |
|    value_loss           | 36.4        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 669      |
|    ep_rew_mean     | 339      |
| time/              |          |
|    fps             | 531      |
|    iterations      | 69       |
|    time_elapsed    | 8509     |
|    total_timesteps | 4521984  |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 647        |
|    ep_rew_mean          | 313        |
| time/                   |            |
|    fps                  | 531        |
|    iterations           | 70         |
|    time_elapsed         | 8627       |
|    total_timesteps      | 4587520    |
| train/                  |            |
|    approx_kl            | 0.04238787 |
|    clip_fraction        | 0.0893     |
|    clip_range           | 0.193      |
|    entropy_loss         | -0.125     |
|    explained_variance   | 0.715      |
|    learning_rate        | 9.55e-05   |
|    loss                 | 12.8       |
|    n_updates            | 276        |
|    policy_gradient_loss | 0.00718    |
|    value_loss           | 41.7       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 670         |
|    ep_rew_mean          | 343         |
| time/                   |             |
|    fps                  | 531         |
|    iterations           | 71          |
|    time_elapsed         | 8747        |
|    total_timesteps      | 4653056     |
| train/                  |             |
|    approx_kl            | 0.046799805 |
|    clip_fraction        | 0.1         |
|    clip_range           | 0.193       |
|    entropy_loss         | -0.13       |
|    explained_variance   | 0.747       |
|    learning_rate        | 9.55e-05    |
|    loss                 | 13.3        |
|    n_updates            | 280         |
|    policy_gradient_loss | 0.00955     |
|    value_loss           | 41          |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 663        |
|    ep_rew_mean          | 341        |
| time/                   |            |
|    fps                  | 531        |
|    iterations           | 72         |
|    time_elapsed         | 8870       |
|    total_timesteps      | 4718592    |
| train/                  |            |
|    approx_kl            | 0.04120017 |
|    clip_fraction        | 0.0874     |
|    clip_range           | 0.193      |
|    entropy_loss         | -0.107     |
|    explained_variance   | 0.71       |
|    learning_rate        | 9.54e-05   |
|    loss                 | 13.2       |
|    n_updates            | 284        |
|    policy_gradient_loss | 0.0128     |
|    value_loss           | 43.2       |
----------------------------------------
Eval num_timesteps=4749696, episode_reward=-9.17 +/- 3.31
Episode length: 6.20 +/- 1.08
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 6.2         |
|    mean_reward          | -9.17       |
| time/                   |             |
|    total_timesteps      | 4749696     |
| train/                  |             |
|    approx_kl            | 0.055451177 |
|    clip_fraction        | 0.0936      |
|    clip_range           | 0.193       |
|    entropy_loss         | -0.111      |
|    explained_variance   | 0.68        |
|    learning_rate        | 9.53e-05    |
|    loss                 | 13.1        |
|    n_updates            | 288         |
|    policy_gradient_loss | 0.0103      |
|    value_loss           | 40.9        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 625      |
|    ep_rew_mean     | 314      |
| time/              |          |
|    fps             | 531      |
|    iterations      | 73       |
|    time_elapsed    | 8993     |
|    total_timesteps | 4784128  |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 645         |
|    ep_rew_mean          | 330         |
| time/                   |             |
|    fps                  | 531         |
|    iterations           | 74          |
|    time_elapsed         | 9118        |
|    total_timesteps      | 4849664     |
| train/                  |             |
|    approx_kl            | 0.060721345 |
|    clip_fraction        | 0.106       |
|    clip_range           | 0.193       |
|    entropy_loss         | -0.122      |
|    explained_variance   | 0.691       |
|    learning_rate        | 9.53e-05    |
|    loss                 | 12.8        |
|    n_updates            | 292         |
|    policy_gradient_loss | 0.0147      |
|    value_loss           | 39.7        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 647        |
|    ep_rew_mean          | 337        |
| time/                   |            |
|    fps                  | 531        |
|    iterations           | 75         |
|    time_elapsed         | 9240       |
|    total_timesteps      | 4915200    |
| train/                  |            |
|    approx_kl            | 0.07343598 |
|    clip_fraction        | 0.0963     |
|    clip_range           | 0.193      |
|    entropy_loss         | -0.118     |
|    explained_variance   | 0.703      |
|    learning_rate        | 9.52e-05   |
|    loss                 | 13.2       |
|    n_updates            | 296        |
|    policy_gradient_loss | 0.00924    |
|    value_loss           | 41.3       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 660        |
|    ep_rew_mean          | 345        |
| time/                   |            |
|    fps                  | 532        |
|    iterations           | 76         |
|    time_elapsed         | 9362       |
|    total_timesteps      | 4980736    |
| train/                  |            |
|    approx_kl            | 0.04356788 |
|    clip_fraction        | 0.0826     |
|    clip_range           | 0.193      |
|    entropy_loss         | -0.105     |
|    explained_variance   | 0.666      |
|    learning_rate        | 9.51e-05   |
|    loss                 | 11         |
|    n_updates            | 300        |
|    policy_gradient_loss | 0.00985    |
|    value_loss           | 41.1       |
----------------------------------------
Eval num_timesteps=4999680, episode_reward=-9.22 +/- 3.33
Episode length: 6.80 +/- 1.54
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 6.8         |
|    mean_reward          | -9.22       |
| time/                   |             |
|    total_timesteps      | 4999680     |
| train/                  |             |
|    approx_kl            | 0.054664988 |
|    clip_fraction        | 0.0968      |
|    clip_range           | 0.193       |
|    entropy_loss         | -0.113      |
|    explained_variance   | 0.677       |
|    learning_rate        | 9.51e-05    |
|    loss                 | 14.9        |
|    n_updates            | 304         |
|    policy_gradient_loss | 0.0113      |
|    value_loss           | 44.5        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 679      |
|    ep_rew_mean     | 366      |
| time/              |          |
|    fps             | 532      |
|    iterations      | 77       |
|    time_elapsed    | 9483     |
|    total_timesteps | 5046272  |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 697         |
|    ep_rew_mean          | 358         |
| time/                   |             |
|    fps                  | 532         |
|    iterations           | 78          |
|    time_elapsed         | 9604        |
|    total_timesteps      | 5111808     |
| train/                  |             |
|    approx_kl            | 0.041433938 |
|    clip_fraction        | 0.0856      |
|    clip_range           | 0.192       |
|    entropy_loss         | -0.0987     |
|    explained_variance   | 0.702       |
|    learning_rate        | 9.5e-05     |
|    loss                 | 11.5        |
|    n_updates            | 308         |
|    policy_gradient_loss | 0.0126      |
|    value_loss           | 40.6        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 651         |
|    ep_rew_mean          | 331         |
| time/                   |             |
|    fps                  | 532         |
|    iterations           | 79          |
|    time_elapsed         | 9727        |
|    total_timesteps      | 5177344     |
| train/                  |             |
|    approx_kl            | 0.046153203 |
|    clip_fraction        | 0.0845      |
|    clip_range           | 0.192       |
|    entropy_loss         | -0.101      |
|    explained_variance   | 0.677       |
|    learning_rate        | 9.49e-05    |
|    loss                 | 12.8        |
|    n_updates            | 312         |
|    policy_gradient_loss | 0.0106      |
|    value_loss           | 42.3        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 669         |
|    ep_rew_mean          | 366         |
| time/                   |             |
|    fps                  | 532         |
|    iterations           | 80          |
|    time_elapsed         | 9848        |
|    total_timesteps      | 5242880     |
| train/                  |             |
|    approx_kl            | 0.055544622 |
|    clip_fraction        | 0.0951      |
|    clip_range           | 0.192       |
|    entropy_loss         | -0.113      |
|    explained_variance   | 0.674       |
|    learning_rate        | 9.49e-05    |
|    loss                 | 11.9        |
|    n_updates            | 316         |
|    policy_gradient_loss | 0.00926     |
|    value_loss           | 41.5        |
-----------------------------------------
Eval num_timesteps=5249664, episode_reward=-7.92 +/- 4.63
Episode length: 6.20 +/- 1.40
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 6.2         |
|    mean_reward          | -7.92       |
| time/                   |             |
|    total_timesteps      | 5249664     |
| train/                  |             |
|    approx_kl            | 0.050943386 |
|    clip_fraction        | 0.0992      |
|    clip_range           | 0.192       |
|    entropy_loss         | -0.119      |
|    explained_variance   | 0.66        |
|    learning_rate        | 9.48e-05    |
|    loss                 | 13.6        |
|    n_updates            | 320         |
|    policy_gradient_loss | 0.0127      |
|    value_loss           | 46.7        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 618      |
|    ep_rew_mean     | 354      |
| time/              |          |
|    fps             | 532      |
|    iterations      | 81       |
|    time_elapsed    | 9969     |
|    total_timesteps | 5308416  |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 670         |
|    ep_rew_mean          | 377         |
| time/                   |             |
|    fps                  | 532         |
|    iterations           | 82          |
|    time_elapsed         | 10088       |
|    total_timesteps      | 5373952     |
| train/                  |             |
|    approx_kl            | 0.052231878 |
|    clip_fraction        | 0.0884      |
|    clip_range           | 0.192       |
|    entropy_loss         | -0.1        |
|    explained_variance   | 0.656       |
|    learning_rate        | 9.47e-05    |
|    loss                 | 12.8        |
|    n_updates            | 324         |
|    policy_gradient_loss | 0.0114      |
|    value_loss           | 42.3        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 625         |
|    ep_rew_mean          | 329         |
| time/                   |             |
|    fps                  | 532         |
|    iterations           | 83          |
|    time_elapsed         | 10210       |
|    total_timesteps      | 5439488     |
| train/                  |             |
|    approx_kl            | 0.049523473 |
|    clip_fraction        | 0.0877      |
|    clip_range           | 0.192       |
|    entropy_loss         | -0.105      |
|    explained_variance   | 0.656       |
|    learning_rate        | 9.47e-05    |
|    loss                 | 13          |
|    n_updates            | 328         |
|    policy_gradient_loss | 0.0114      |
|    value_loss           | 43.5        |
-----------------------------------------
Eval num_timesteps=5499648, episode_reward=-9.13 +/- 3.27
Episode length: 7.20 +/- 2.14
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 7.2         |
|    mean_reward          | -9.13       |
| time/                   |             |
|    total_timesteps      | 5499648     |
| train/                  |             |
|    approx_kl            | 0.062258832 |
|    clip_fraction        | 0.0974      |
|    clip_range           | 0.192       |
|    entropy_loss         | -0.11       |
|    explained_variance   | 0.617       |
|    learning_rate        | 9.46e-05    |
|    loss                 | 13          |
|    n_updates            | 332         |
|    policy_gradient_loss | 0.0134      |
|    value_loss           | 46.4        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 656      |
|    ep_rew_mean     | 344      |
| time/              |          |
|    fps             | 532      |
|    iterations      | 84       |
|    time_elapsed    | 10334    |
|    total_timesteps | 5505024  |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 587        |
|    ep_rew_mean          | 286        |
| time/                   |            |
|    fps                  | 532        |
|    iterations           | 85         |
|    time_elapsed         | 10460      |
|    total_timesteps      | 5570560    |
| train/                  |            |
|    approx_kl            | 0.05353484 |
|    clip_fraction        | 0.0962     |
|    clip_range           | 0.192      |
|    entropy_loss         | -0.106     |
|    explained_variance   | 0.672      |
|    learning_rate        | 9.46e-05   |
|    loss                 | 14.5       |
|    n_updates            | 336        |
|    policy_gradient_loss | 0.0112     |
|    value_loss           | 45.8       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 689         |
|    ep_rew_mean          | 319         |
| time/                   |             |
|    fps                  | 532         |
|    iterations           | 86          |
|    time_elapsed         | 10585       |
|    total_timesteps      | 5636096     |
| train/                  |             |
|    approx_kl            | 0.074374735 |
|    clip_fraction        | 0.109       |
|    clip_range           | 0.192       |
|    entropy_loss         | -0.129      |
|    explained_variance   | 0.685       |
|    learning_rate        | 9.45e-05    |
|    loss                 | 12.2        |
|    n_updates            | 340         |
|    policy_gradient_loss | 0.0161      |
|    value_loss           | 44          |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 657         |
|    ep_rew_mean          | 336         |
| time/                   |             |
|    fps                  | 532         |
|    iterations           | 87          |
|    time_elapsed         | 10707       |
|    total_timesteps      | 5701632     |
| train/                  |             |
|    approx_kl            | 0.051475815 |
|    clip_fraction        | 0.0976      |
|    clip_range           | 0.192       |
|    entropy_loss         | -0.116      |
|    explained_variance   | 0.649       |
|    learning_rate        | 9.44e-05    |
|    loss                 | 14.2        |
|    n_updates            | 344         |
|    policy_gradient_loss | 0.0111      |
|    value_loss           | 42          |
-----------------------------------------
Eval num_timesteps=5749632, episode_reward=-10.18 +/- 0.56
Episode length: 6.10 +/- 1.51
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 6.1        |
|    mean_reward          | -10.2      |
| time/                   |            |
|    total_timesteps      | 5749632    |
| train/                  |            |
|    approx_kl            | 0.05045315 |
|    clip_fraction        | 0.104      |
|    clip_range           | 0.191      |
|    entropy_loss         | -0.127     |
|    explained_variance   | 0.648      |
|    learning_rate        | 9.44e-05   |
|    loss                 | 14         |
|    n_updates            | 348        |
|    policy_gradient_loss | 0.0115     |
|    value_loss           | 46.4       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 667      |
|    ep_rew_mean     | 330      |
| time/              |          |
|    fps             | 532      |
|    iterations      | 88       |
|    time_elapsed    | 10831    |
|    total_timesteps | 5767168  |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 663       |
|    ep_rew_mean          | 325       |
| time/                   |           |
|    fps                  | 532       |
|    iterations           | 89        |
|    time_elapsed         | 10952     |
|    total_timesteps      | 5832704   |
| train/                  |           |
|    approx_kl            | 0.0626013 |
|    clip_fraction        | 0.104     |
|    clip_range           | 0.191     |
|    entropy_loss         | -0.121    |
|    explained_variance   | 0.636     |
|    learning_rate        | 9.43e-05  |
|    loss                 | 14.6      |
|    n_updates            | 352       |
|    policy_gradient_loss | 0.0119    |
|    value_loss           | 45.3      |
---------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 732         |
|    ep_rew_mean          | 335         |
| time/                   |             |
|    fps                  | 532         |
|    iterations           | 90          |
|    time_elapsed         | 11074       |
|    total_timesteps      | 5898240     |
| train/                  |             |
|    approx_kl            | 0.052405827 |
|    clip_fraction        | 0.0957      |
|    clip_range           | 0.191       |
|    entropy_loss         | -0.11       |
|    explained_variance   | 0.613       |
|    learning_rate        | 9.42e-05    |
|    loss                 | 11.3        |
|    n_updates            | 356         |
|    policy_gradient_loss | 0.0113      |
|    value_loss           | 42.1        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 655         |
|    ep_rew_mean          | 331         |
| time/                   |             |
|    fps                  | 532         |
|    iterations           | 91          |
|    time_elapsed         | 11204       |
|    total_timesteps      | 5963776     |
| train/                  |             |
|    approx_kl            | 0.052614156 |
|    clip_fraction        | 0.0978      |
|    clip_range           | 0.191       |
|    entropy_loss         | -0.118      |
|    explained_variance   | 0.67        |
|    learning_rate        | 9.42e-05    |
|    loss                 | 10.7        |
|    n_updates            | 360         |
|    policy_gradient_loss | 0.00778     |
|    value_loss           | 35.5        |
-----------------------------------------
Eval num_timesteps=5999616, episode_reward=-9.19 +/- 3.28
Episode length: 7.40 +/- 3.14
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 7.4         |
|    mean_reward          | -9.19       |
| time/                   |             |
|    total_timesteps      | 5999616     |
| train/                  |             |
|    approx_kl            | 0.054646626 |
|    clip_fraction        | 0.0937      |
|    clip_range           | 0.191       |
|    entropy_loss         | -0.103      |
|    explained_variance   | 0.668       |
|    learning_rate        | 9.41e-05    |
|    loss                 | 14          |
|    n_updates            | 364         |
|    policy_gradient_loss | 0.0127      |
|    value_loss           | 43.9        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 677      |
|    ep_rew_mean     | 368      |
| time/              |          |
|    fps             | 532      |
|    iterations      | 92       |
|    time_elapsed    | 11328    |
|    total_timesteps | 6029312  |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 673        |
|    ep_rew_mean          | 354        |
| time/                   |            |
|    fps                  | 532        |
|    iterations           | 93         |
|    time_elapsed         | 11450      |
|    total_timesteps      | 6094848    |
| train/                  |            |
|    approx_kl            | 0.05749716 |
|    clip_fraction        | 0.0891     |
|    clip_range           | 0.191      |
|    entropy_loss         | -0.101     |
|    explained_variance   | 0.685      |
|    learning_rate        | 9.4e-05    |
|    loss                 | 11.8       |
|    n_updates            | 368        |
|    policy_gradient_loss | 0.00971    |
|    value_loss           | 44         |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 639       |
|    ep_rew_mean          | 359       |
| time/                   |           |
|    fps                  | 532       |
|    iterations           | 94        |
|    time_elapsed         | 11572     |
|    total_timesteps      | 6160384   |
| train/                  |           |
|    approx_kl            | 0.0650464 |
|    clip_fraction        | 0.0971    |
|    clip_range           | 0.191     |
|    entropy_loss         | -0.109    |
|    explained_variance   | 0.659     |
|    learning_rate        | 9.4e-05   |
|    loss                 | 12.9      |
|    n_updates            | 372       |
|    policy_gradient_loss | 0.0109    |
|    value_loss           | 41.4      |
---------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 671         |
|    ep_rew_mean          | 376         |
| time/                   |             |
|    fps                  | 532         |
|    iterations           | 95          |
|    time_elapsed         | 11694       |
|    total_timesteps      | 6225920     |
| train/                  |             |
|    approx_kl            | 0.046695076 |
|    clip_fraction        | 0.0858      |
|    clip_range           | 0.191       |
|    entropy_loss         | -0.101      |
|    explained_variance   | 0.647       |
|    learning_rate        | 9.39e-05    |
|    loss                 | 14.3        |
|    n_updates            | 376         |
|    policy_gradient_loss | 0.0119      |
|    value_loss           | 45.6        |
-----------------------------------------
Eval num_timesteps=6249600, episode_reward=-7.99 +/- 4.53
Episode length: 6.80 +/- 0.98
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 6.8        |
|    mean_reward          | -7.99      |
| time/                   |            |
|    total_timesteps      | 6249600    |
| train/                  |            |
|    approx_kl            | 0.05042923 |
|    clip_fraction        | 0.0882     |
|    clip_range           | 0.191      |
|    entropy_loss         | -0.0992    |
|    explained_variance   | 0.727      |
|    learning_rate        | 9.38e-05   |
|    loss                 | 12         |
|    n_updates            | 380        |
|    policy_gradient_loss | 0.0103     |
|    value_loss           | 40.2       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 667      |
|    ep_rew_mean     | 340      |
| time/              |          |
|    fps             | 532      |
|    iterations      | 96       |
|    time_elapsed    | 11815    |
|    total_timesteps | 6291456  |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 723         |
|    ep_rew_mean          | 373         |
| time/                   |             |
|    fps                  | 532         |
|    iterations           | 97          |
|    time_elapsed         | 11935       |
|    total_timesteps      | 6356992     |
| train/                  |             |
|    approx_kl            | 0.079156466 |
|    clip_fraction        | 0.0981      |
|    clip_range           | 0.191       |
|    entropy_loss         | -0.0929     |
|    explained_variance   | 0.668       |
|    learning_rate        | 9.38e-05    |
|    loss                 | 15.1        |
|    n_updates            | 384         |
|    policy_gradient_loss | 0.0169      |
|    value_loss           | 42.1        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 664        |
|    ep_rew_mean          | 332        |
| time/                   |            |
|    fps                  | 532        |
|    iterations           | 98         |
|    time_elapsed         | 12058      |
|    total_timesteps      | 6422528    |
| train/                  |            |
|    approx_kl            | 0.06065153 |
|    clip_fraction        | 0.0894     |
|    clip_range           | 0.19       |
|    entropy_loss         | -0.0928    |
|    explained_variance   | 0.641      |
|    learning_rate        | 9.37e-05   |
|    loss                 | 10.2       |
|    n_updates            | 388        |
|    policy_gradient_loss | 0.0148     |
|    value_loss           | 39.1       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 680         |
|    ep_rew_mean          | 324         |
| time/                   |             |
|    fps                  | 532         |
|    iterations           | 99          |
|    time_elapsed         | 12175       |
|    total_timesteps      | 6488064     |
| train/                  |             |
|    approx_kl            | 0.057054117 |
|    clip_fraction        | 0.0869      |
|    clip_range           | 0.19        |
|    entropy_loss         | -0.0933     |
|    explained_variance   | 0.651       |
|    learning_rate        | 9.36e-05    |
|    loss                 | 11.8        |
|    n_updates            | 392         |
|    policy_gradient_loss | 0.0116      |
|    value_loss           | 40.7        |
-----------------------------------------
Eval num_timesteps=6499584, episode_reward=-9.24 +/- 3.82
Episode length: 7.90 +/- 3.65
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 7.9         |
|    mean_reward          | -9.24       |
| time/                   |             |
|    total_timesteps      | 6499584     |
| train/                  |             |
|    approx_kl            | 0.073589414 |
|    clip_fraction        | 0.0999      |
|    clip_range           | 0.19        |
|    entropy_loss         | -0.102      |
|    explained_variance   | 0.639       |
|    learning_rate        | 9.36e-05    |
|    loss                 | 9.52        |
|    n_updates            | 396         |
|    policy_gradient_loss | 0.0117      |
|    value_loss           | 41.5        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 679      |
|    ep_rew_mean     | 318      |
| time/              |          |
|    fps             | 532      |
|    iterations      | 100      |
|    time_elapsed    | 12295    |
|    total_timesteps | 6553600  |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 655       |
|    ep_rew_mean          | 186       |
| time/                   |           |
|    fps                  | 533       |
|    iterations           | 101       |
|    time_elapsed         | 12415     |
|    total_timesteps      | 6619136   |
| train/                  |           |
|    approx_kl            | 0.1384567 |
|    clip_fraction        | 0.0976    |
|    clip_range           | 0.19      |
|    entropy_loss         | -0.0975   |
|    explained_variance   | 0.636     |
|    learning_rate        | 9.35e-05  |
|    loss                 | 14.1      |
|    n_updates            | 400       |
|    policy_gradient_loss | 0.016     |
|    value_loss           | 45.1      |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 684        |
|    ep_rew_mean          | 239        |
| time/                   |            |
|    fps                  | 533        |
|    iterations           | 102        |
|    time_elapsed         | 12532      |
|    total_timesteps      | 6684672    |
| train/                  |            |
|    approx_kl            | 0.06801049 |
|    clip_fraction        | 0.0768     |
|    clip_range           | 0.19       |
|    entropy_loss         | -0.0915    |
|    explained_variance   | 0.662      |
|    learning_rate        | 9.34e-05   |
|    loss                 | 8.62       |
|    n_updates            | 404        |
|    policy_gradient_loss | 0.00609    |
|    value_loss           | 28.7       |
----------------------------------------
Eval num_timesteps=6749568, episode_reward=-10.19 +/- 0.56
Episode length: 7.10 +/- 1.64
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 7.1         |
|    mean_reward          | -10.2       |
| time/                   |             |
|    total_timesteps      | 6749568     |
| train/                  |             |
|    approx_kl            | 0.041751925 |
|    clip_fraction        | 0.0761      |
|    clip_range           | 0.19        |
|    entropy_loss         | -0.0893     |
|    explained_variance   | 0.698       |
|    learning_rate        | 9.34e-05    |
|    loss                 | 12.5        |
|    n_updates            | 408         |
|    policy_gradient_loss | 0.0103      |
|    value_loss           | 40.2        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 660      |
|    ep_rew_mean     | 265      |
| time/              |          |
|    fps             | 533      |
|    iterations      | 103      |
|    time_elapsed    | 12655    |
|    total_timesteps | 6750208  |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 692         |
|    ep_rew_mean          | 318         |
| time/                   |             |
|    fps                  | 533         |
|    iterations           | 104         |
|    time_elapsed         | 12771       |
|    total_timesteps      | 6815744     |
| train/                  |             |
|    approx_kl            | 0.084422976 |
|    clip_fraction        | 0.0783      |
|    clip_range           | 0.19        |
|    entropy_loss         | -0.0881     |
|    explained_variance   | 0.693       |
|    learning_rate        | 9.33e-05    |
|    loss                 | 8.82        |
|    n_updates            | 412         |
|    policy_gradient_loss | 0.00831     |
|    value_loss           | 36.1        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 650        |
|    ep_rew_mean          | 292        |
| time/                   |            |
|    fps                  | 533        |
|    iterations           | 105        |
|    time_elapsed         | 12888      |
|    total_timesteps      | 6881280    |
| train/                  |            |
|    approx_kl            | 0.04452358 |
|    clip_fraction        | 0.0773     |
|    clip_range           | 0.19       |
|    entropy_loss         | -0.0858    |
|    explained_variance   | 0.727      |
|    learning_rate        | 9.33e-05   |
|    loss                 | 10.4       |
|    n_updates            | 416        |
|    policy_gradient_loss | 0.0115     |
|    value_loss           | 38.5       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 635        |
|    ep_rew_mean          | 300        |
| time/                   |            |
|    fps                  | 534        |
|    iterations           | 106        |
|    time_elapsed         | 12999      |
|    total_timesteps      | 6946816    |
| train/                  |            |
|    approx_kl            | 0.04226105 |
|    clip_fraction        | 0.0776     |
|    clip_range           | 0.19       |
|    entropy_loss         | -0.0861    |
|    explained_variance   | 0.737      |
|    learning_rate        | 9.32e-05   |
|    loss                 | 11.3       |
|    n_updates            | 420        |
|    policy_gradient_loss | 0.0106     |
|    value_loss           | 40.8       |
----------------------------------------
Eval num_timesteps=6999552, episode_reward=-10.15 +/- 0.42
Episode length: 5.60 +/- 0.66
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 5.6       |
|    mean_reward          | -10.1     |
| time/                   |           |
|    total_timesteps      | 6999552   |
| train/                  |           |
|    approx_kl            | 0.0614102 |
|    clip_fraction        | 0.0845    |
|    clip_range           | 0.19      |
|    entropy_loss         | -0.0904   |
|    explained_variance   | 0.759     |
|    learning_rate        | 9.31e-05  |
|    loss                 | 13.3      |
|    n_updates            | 424       |
|    policy_gradient_loss | 0.0149    |
|    value_loss           | 41.9      |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 672      |
|    ep_rew_mean     | 324      |
| time/              |          |
|    fps             | 534      |
|    iterations      | 107      |
|    time_elapsed    | 13117    |
|    total_timesteps | 7012352  |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 700         |
|    ep_rew_mean          | 318         |
| time/                   |             |
|    fps                  | 534         |
|    iterations           | 108         |
|    time_elapsed         | 13239       |
|    total_timesteps      | 7077888     |
| train/                  |             |
|    approx_kl            | 0.059107613 |
|    clip_fraction        | 0.0872      |
|    clip_range           | 0.189       |
|    entropy_loss         | -0.0899     |
|    explained_variance   | 0.707       |
|    learning_rate        | 9.31e-05    |
|    loss                 | 14.9        |
|    n_updates            | 428         |
|    policy_gradient_loss | 0.0158      |
|    value_loss           | 41          |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 671        |
|    ep_rew_mean          | 330        |
| time/                   |            |
|    fps                  | 534        |
|    iterations           | 109        |
|    time_elapsed         | 13354      |
|    total_timesteps      | 7143424    |
| train/                  |            |
|    approx_kl            | 0.05505921 |
|    clip_fraction        | 0.0902     |
|    clip_range           | 0.189      |
|    entropy_loss         | -0.103     |
|    explained_variance   | 0.76       |
|    learning_rate        | 9.3e-05    |
|    loss                 | 10.3       |
|    n_updates            | 432        |
|    policy_gradient_loss | 0.0094     |
|    value_loss           | 40.5       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 683         |
|    ep_rew_mean          | 316         |
| time/                   |             |
|    fps                  | 535         |
|    iterations           | 110         |
|    time_elapsed         | 13468       |
|    total_timesteps      | 7208960     |
| train/                  |             |
|    approx_kl            | 0.062181897 |
|    clip_fraction        | 0.0936      |
|    clip_range           | 0.189       |
|    entropy_loss         | -0.0982     |
|    explained_variance   | 0.715       |
|    learning_rate        | 9.29e-05    |
|    loss                 | 11.5        |
|    n_updates            | 436         |
|    policy_gradient_loss | 0.0148      |
|    value_loss           | 45.3        |
-----------------------------------------
Eval num_timesteps=7249536, episode_reward=-8.04 +/- 4.41
Episode length: 7.90 +/- 4.35
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 7.9         |
|    mean_reward          | -8.04       |
| time/                   |             |
|    total_timesteps      | 7249536     |
| train/                  |             |
|    approx_kl            | 0.069024794 |
|    clip_fraction        | 0.103       |
|    clip_range           | 0.189       |
|    entropy_loss         | -0.11       |
|    explained_variance   | 0.723       |
|    learning_rate        | 9.29e-05    |
|    loss                 | 12.6        |
|    n_updates            | 440         |
|    policy_gradient_loss | 0.0126      |
|    value_loss           | 39.9        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 705      |
|    ep_rew_mean     | 295      |
| time/              |          |
|    fps             | 535      |
|    iterations      | 111      |
|    time_elapsed    | 13586    |
|    total_timesteps | 7274496  |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 694         |
|    ep_rew_mean          | 314         |
| time/                   |             |
|    fps                  | 535         |
|    iterations           | 112         |
|    time_elapsed         | 13707       |
|    total_timesteps      | 7340032     |
| train/                  |             |
|    approx_kl            | 0.064500906 |
|    clip_fraction        | 0.104       |
|    clip_range           | 0.189       |
|    entropy_loss         | -0.114      |
|    explained_variance   | 0.651       |
|    learning_rate        | 9.28e-05    |
|    loss                 | 10.5        |
|    n_updates            | 444         |
|    policy_gradient_loss | 0.011       |
|    value_loss           | 41          |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 692        |
|    ep_rew_mean          | 351        |
| time/                   |            |
|    fps                  | 535        |
|    iterations           | 113        |
|    time_elapsed         | 13826      |
|    total_timesteps      | 7405568    |
| train/                  |            |
|    approx_kl            | 0.06833814 |
|    clip_fraction        | 0.0931     |
|    clip_range           | 0.189      |
|    entropy_loss         | -0.098     |
|    explained_variance   | 0.694      |
|    learning_rate        | 9.27e-05   |
|    loss                 | 12.1       |
|    n_updates            | 448        |
|    policy_gradient_loss | 0.0153     |
|    value_loss           | 41.9       |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 672       |
|    ep_rew_mean          | 333       |
| time/                   |           |
|    fps                  | 535       |
|    iterations           | 114       |
|    time_elapsed         | 13945     |
|    total_timesteps      | 7471104   |
| train/                  |           |
|    approx_kl            | 0.0732289 |
|    clip_fraction        | 0.0991    |
|    clip_range           | 0.189     |
|    entropy_loss         | -0.0997   |
|    explained_variance   | 0.639     |
|    learning_rate        | 9.27e-05  |
|    loss                 | 14.6      |
|    n_updates            | 452       |
|    policy_gradient_loss | 0.0139    |
|    value_loss           | 49        |
---------------------------------------
Eval num_timesteps=7499520, episode_reward=-10.13 +/- 0.43
Episode length: 6.30 +/- 2.33
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 6.3        |
|    mean_reward          | -10.1      |
| time/                   |            |
|    total_timesteps      | 7499520    |
| train/                  |            |
|    approx_kl            | 0.06513338 |
|    clip_fraction        | 0.103      |
|    clip_range           | 0.189      |
|    entropy_loss         | -0.11      |
|    explained_variance   | 0.635      |
|    learning_rate        | 9.26e-05   |
|    loss                 | 11.8       |
|    n_updates            | 456        |
|    policy_gradient_loss | 0.0155     |
|    value_loss           | 44.5       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 661      |
|    ep_rew_mean     | 308      |
| time/              |          |
|    fps             | 535      |
|    iterations      | 115      |
|    time_elapsed    | 14067    |
|    total_timesteps | 7536640  |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 646        |
|    ep_rew_mean          | 314        |
| time/                   |            |
|    fps                  | 535        |
|    iterations           | 116        |
|    time_elapsed         | 14187      |
|    total_timesteps      | 7602176    |
| train/                  |            |
|    approx_kl            | 0.06954261 |
|    clip_fraction        | 0.103      |
|    clip_range           | 0.189      |
|    entropy_loss         | -0.109     |
|    explained_variance   | 0.647      |
|    learning_rate        | 9.25e-05   |
|    loss                 | 13.4       |
|    n_updates            | 460        |
|    policy_gradient_loss | 0.0153     |
|    value_loss           | 44.5       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 608         |
|    ep_rew_mean          | 291         |
| time/                   |             |
|    fps                  | 535         |
|    iterations           | 117         |
|    time_elapsed         | 14316       |
|    total_timesteps      | 7667712     |
| train/                  |             |
|    approx_kl            | 0.061811205 |
|    clip_fraction        | 0.098       |
|    clip_range           | 0.189       |
|    entropy_loss         | -0.106      |
|    explained_variance   | 0.68        |
|    learning_rate        | 9.25e-05    |
|    loss                 | 13.6        |
|    n_updates            | 464         |
|    policy_gradient_loss | 0.0123      |
|    value_loss           | 45.8        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 661         |
|    ep_rew_mean          | 271         |
| time/                   |             |
|    fps                  | 535         |
|    iterations           | 118         |
|    time_elapsed         | 14438       |
|    total_timesteps      | 7733248     |
| train/                  |             |
|    approx_kl            | 0.106224775 |
|    clip_fraction        | 0.112       |
|    clip_range           | 0.188       |
|    entropy_loss         | -0.0961     |
|    explained_variance   | 0.674       |
|    learning_rate        | 9.24e-05    |
|    loss                 | 13.4        |
|    n_updates            | 468         |
|    policy_gradient_loss | 0.0328      |
|    value_loss           | 46.6        |
-----------------------------------------
Eval num_timesteps=7749504, episode_reward=-9.20 +/- 3.45
Episode length: 6.70 +/- 2.72
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 6.7        |
|    mean_reward          | -9.2       |
| time/                   |            |
|    total_timesteps      | 7749504    |
| train/                  |            |
|    approx_kl            | 0.05835565 |
|    clip_fraction        | 0.0798     |
|    clip_range           | 0.188      |
|    entropy_loss         | -0.0844    |
|    explained_variance   | 0.715      |
|    learning_rate        | 9.23e-05   |
|    loss                 | 9.99       |
|    n_updates            | 472        |
|    policy_gradient_loss | 0.0126     |
|    value_loss           | 37.8       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 700      |
|    ep_rew_mean     | 316      |
| time/              |          |
|    fps             | 535      |
|    iterations      | 119      |
|    time_elapsed    | 14558    |
|    total_timesteps | 7798784  |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 663         |
|    ep_rew_mean          | 278         |
| time/                   |             |
|    fps                  | 535         |
|    iterations           | 120         |
|    time_elapsed         | 14678       |
|    total_timesteps      | 7864320     |
| train/                  |             |
|    approx_kl            | 0.053574964 |
|    clip_fraction        | 0.0779      |
|    clip_range           | 0.188       |
|    entropy_loss         | -0.0822     |
|    explained_variance   | 0.678       |
|    learning_rate        | 9.23e-05    |
|    loss                 | 11.6        |
|    n_updates            | 476         |
|    policy_gradient_loss | 0.0118      |
|    value_loss           | 39.4        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 691         |
|    ep_rew_mean          | 294         |
| time/                   |             |
|    fps                  | 535         |
|    iterations           | 121         |
|    time_elapsed         | 14801       |
|    total_timesteps      | 7929856     |
| train/                  |             |
|    approx_kl            | 0.055920422 |
|    clip_fraction        | 0.0765      |
|    clip_range           | 0.188       |
|    entropy_loss         | -0.0841     |
|    explained_variance   | 0.767       |
|    learning_rate        | 9.22e-05    |
|    loss                 | 11.6        |
|    n_updates            | 480         |
|    policy_gradient_loss | 0.0106      |
|    value_loss           | 35.2        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 676        |
|    ep_rew_mean          | 314        |
| time/                   |            |
|    fps                  | 535        |
|    iterations           | 122        |
|    time_elapsed         | 14921      |
|    total_timesteps      | 7995392    |
| train/                  |            |
|    approx_kl            | 0.04873389 |
|    clip_fraction        | 0.0754     |
|    clip_range           | 0.188      |
|    entropy_loss         | -0.0834    |
|    explained_variance   | 0.744      |
|    learning_rate        | 9.21e-05   |
|    loss                 | 10.9       |
|    n_updates            | 484        |
|    policy_gradient_loss | 0.0104     |
|    value_loss           | 37.5       |
----------------------------------------
Eval num_timesteps=7999488, episode_reward=-8.98 +/- 3.02
Episode length: 6.40 +/- 2.29
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 6.4         |
|    mean_reward          | -8.98       |
| time/                   |             |
|    total_timesteps      | 7999488     |
| train/                  |             |
|    approx_kl            | 0.053186953 |
|    clip_fraction        | 0.0839      |
|    clip_range           | 0.188       |
|    entropy_loss         | -0.0898     |
|    explained_variance   | 0.734       |
|    learning_rate        | 9.21e-05    |
|    loss                 | 9.84        |
|    n_updates            | 488         |
|    policy_gradient_loss | 0.0122      |
|    value_loss           | 39.4        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 665      |
|    ep_rew_mean     | 339      |
| time/              |          |
|    fps             | 535      |
|    iterations      | 123      |
|    time_elapsed    | 15051    |
|    total_timesteps | 8060928  |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 654         |
|    ep_rew_mean          | 283         |
| time/                   |             |
|    fps                  | 535         |
|    iterations           | 124         |
|    time_elapsed         | 15174       |
|    total_timesteps      | 8126464     |
| train/                  |             |
|    approx_kl            | 0.055734225 |
|    clip_fraction        | 0.0819      |
|    clip_range           | 0.188       |
|    entropy_loss         | -0.0807     |
|    explained_variance   | 0.74        |
|    learning_rate        | 9.2e-05     |
|    loss                 | 10.7        |
|    n_updates            | 492         |
|    policy_gradient_loss | 0.0104      |
|    value_loss           | 38.9        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 663        |
|    ep_rew_mean          | 318        |
| time/                   |            |
|    fps                  | 535        |
|    iterations           | 125        |
|    time_elapsed         | 15297      |
|    total_timesteps      | 8192000    |
| train/                  |            |
|    approx_kl            | 0.06888046 |
|    clip_fraction        | 0.0971     |
|    clip_range           | 0.188      |
|    entropy_loss         | -0.0896    |
|    explained_variance   | 0.788      |
|    learning_rate        | 9.2e-05    |
|    loss                 | 10.3       |
|    n_updates            | 496        |
|    policy_gradient_loss | 0.0177     |
|    value_loss           | 37.2       |
----------------------------------------
Eval num_timesteps=8249472, episode_reward=-10.20 +/- 0.46
Episode length: 7.50 +/- 4.25
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 7.5        |
|    mean_reward          | -10.2      |
| time/                   |            |
|    total_timesteps      | 8249472    |
| train/                  |            |
|    approx_kl            | 0.04810033 |
|    clip_fraction        | 0.0729     |
|    clip_range           | 0.188      |
|    entropy_loss         | -0.0835    |
|    explained_variance   | 0.765      |
|    learning_rate        | 9.19e-05   |
|    loss                 | 12.5       |
|    n_updates            | 500        |
|    policy_gradient_loss | 0.0105     |
|    value_loss           | 37.7       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 669      |
|    ep_rew_mean     | 340      |
| time/              |          |
|    fps             | 535      |
|    iterations      | 126      |
|    time_elapsed    | 15424    |
|    total_timesteps | 8257536  |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 716        |
|    ep_rew_mean          | 372        |
| time/                   |            |
|    fps                  | 535        |
|    iterations           | 127        |
|    time_elapsed         | 15548      |
|    total_timesteps      | 8323072    |
| train/                  |            |
|    approx_kl            | 0.06901344 |
|    clip_fraction        | 0.0914     |
|    clip_range           | 0.188      |
|    entropy_loss         | -0.0908    |
|    explained_variance   | 0.675      |
|    learning_rate        | 9.18e-05   |
|    loss                 | 12.2       |
|    n_updates            | 504        |
|    policy_gradient_loss | 0.0117     |
|    value_loss           | 42.8       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 670         |
|    ep_rew_mean          | 358         |
| time/                   |             |
|    fps                  | 535         |
|    iterations           | 128         |
|    time_elapsed         | 15671       |
|    total_timesteps      | 8388608     |
| train/                  |             |
|    approx_kl            | 0.065848365 |
|    clip_fraction        | 0.0903      |
|    clip_range           | 0.188       |
|    entropy_loss         | -0.086      |
|    explained_variance   | 0.658       |
|    learning_rate        | 9.18e-05    |
|    loss                 | 12.7        |
|    n_updates            | 508         |
|    policy_gradient_loss | 0.0131      |
|    value_loss           | 42.9        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 721         |
|    ep_rew_mean          | 378         |
| time/                   |             |
|    fps                  | 535         |
|    iterations           | 129         |
|    time_elapsed         | 15795       |
|    total_timesteps      | 8454144     |
| train/                  |             |
|    approx_kl            | 0.063729584 |
|    clip_fraction        | 0.0926      |
|    clip_range           | 0.187       |
|    entropy_loss         | -0.0929     |
|    explained_variance   | 0.71        |
|    learning_rate        | 9.17e-05    |
|    loss                 | 11.6        |
|    n_updates            | 512         |
|    policy_gradient_loss | 0.0114      |
|    value_loss           | 40.5        |
-----------------------------------------
Eval num_timesteps=8499456, episode_reward=-7.97 +/- 4.45
Episode length: 7.60 +/- 2.50
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 7.6         |
|    mean_reward          | -7.97       |
| time/                   |             |
|    total_timesteps      | 8499456     |
| train/                  |             |
|    approx_kl            | 0.089950904 |
|    clip_fraction        | 0.0922      |
|    clip_range           | 0.187       |
|    entropy_loss         | -0.0817     |
|    explained_variance   | 0.701       |
|    learning_rate        | 9.16e-05    |
|    loss                 | 10.6        |
|    n_updates            | 516         |
|    policy_gradient_loss | 0.0147      |
|    value_loss           | 37.3        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 740      |
|    ep_rew_mean     | 356      |
| time/              |          |
|    fps             | 535      |
|    iterations      | 130      |
|    time_elapsed    | 15917    |
|    total_timesteps | 8519680  |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 701        |
|    ep_rew_mean          | 372        |
| time/                   |            |
|    fps                  | 535        |
|    iterations           | 131        |
|    time_elapsed         | 16039      |
|    total_timesteps      | 8585216    |
| train/                  |            |
|    approx_kl            | 0.06362377 |
|    clip_fraction        | 0.0855     |
|    clip_range           | 0.187      |
|    entropy_loss         | -0.0829    |
|    explained_variance   | 0.655      |
|    learning_rate        | 9.16e-05   |
|    loss                 | 11.7       |
|    n_updates            | 520        |
|    policy_gradient_loss | 0.0119     |
|    value_loss           | 40.7       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 691        |
|    ep_rew_mean          | 355        |
| time/                   |            |
|    fps                  | 535        |
|    iterations           | 132        |
|    time_elapsed         | 16162      |
|    total_timesteps      | 8650752    |
| train/                  |            |
|    approx_kl            | 0.06680572 |
|    clip_fraction        | 0.0914     |
|    clip_range           | 0.187      |
|    entropy_loss         | -0.0893    |
|    explained_variance   | 0.649      |
|    learning_rate        | 9.15e-05   |
|    loss                 | 12.7       |
|    n_updates            | 524        |
|    policy_gradient_loss | 0.014      |
|    value_loss           | 46.8       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 728         |
|    ep_rew_mean          | 351         |
| time/                   |             |
|    fps                  | 535         |
|    iterations           | 133         |
|    time_elapsed         | 16285       |
|    total_timesteps      | 8716288     |
| train/                  |             |
|    approx_kl            | 0.069990925 |
|    clip_fraction        | 0.0933      |
|    clip_range           | 0.187       |
|    entropy_loss         | -0.0941     |
|    explained_variance   | 0.618       |
|    learning_rate        | 9.14e-05    |
|    loss                 | 12.2        |
|    n_updates            | 528         |
|    policy_gradient_loss | 0.015       |
|    value_loss           | 45.7        |
-----------------------------------------
Eval num_timesteps=8749440, episode_reward=-9.74 +/- 0.38
Episode length: 6.80 +/- 1.40
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 6.8        |
|    mean_reward          | -9.74      |
| time/                   |            |
|    total_timesteps      | 8749440    |
| train/                  |            |
|    approx_kl            | 0.07048747 |
|    clip_fraction        | 0.0907     |
|    clip_range           | 0.187      |
|    entropy_loss         | -0.0916    |
|    explained_variance   | 0.612      |
|    learning_rate        | 9.14e-05   |
|    loss                 | 14.8       |
|    n_updates            | 532        |
|    policy_gradient_loss | 0.0129     |
|    value_loss           | 41.2       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 769      |
|    ep_rew_mean     | 354      |
| time/              |          |
|    fps             | 535      |
|    iterations      | 134      |
|    time_elapsed    | 16407    |
|    total_timesteps | 8781824  |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 654        |
|    ep_rew_mean          | 363        |
| time/                   |            |
|    fps                  | 535        |
|    iterations           | 135        |
|    time_elapsed         | 16530      |
|    total_timesteps      | 8847360    |
| train/                  |            |
|    approx_kl            | 0.08935465 |
|    clip_fraction        | 0.0936     |
|    clip_range           | 0.187      |
|    entropy_loss         | -0.0897    |
|    explained_variance   | 0.604      |
|    learning_rate        | 9.13e-05   |
|    loss                 | 13.2       |
|    n_updates            | 536        |
|    policy_gradient_loss | 0.0114     |
|    value_loss           | 42.1       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 714         |
|    ep_rew_mean          | 354         |
| time/                   |             |
|    fps                  | 535         |
|    iterations           | 136         |
|    time_elapsed         | 16652       |
|    total_timesteps      | 8912896     |
| train/                  |             |
|    approx_kl            | 0.068581775 |
|    clip_fraction        | 0.094       |
|    clip_range           | 0.187       |
|    entropy_loss         | -0.0904     |
|    explained_variance   | 0.589       |
|    learning_rate        | 9.12e-05    |
|    loss                 | 12.5        |
|    n_updates            | 540         |
|    policy_gradient_loss | 0.0156      |
|    value_loss           | 48.2        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 702        |
|    ep_rew_mean          | 352        |
| time/                   |            |
|    fps                  | 535        |
|    iterations           | 137        |
|    time_elapsed         | 16774      |
|    total_timesteps      | 8978432    |
| train/                  |            |
|    approx_kl            | 0.07015248 |
|    clip_fraction        | 0.088      |
|    clip_range           | 0.187      |
|    entropy_loss         | -0.089     |
|    explained_variance   | 0.598      |
|    learning_rate        | 9.12e-05   |
|    loss                 | 12.3       |
|    n_updates            | 544        |
|    policy_gradient_loss | 0.0139     |
|    value_loss           | 43.6       |
----------------------------------------
Eval num_timesteps=8999424, episode_reward=-6.80 +/- 5.27
Episode length: 6.80 +/- 1.83
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 6.8        |
|    mean_reward          | -6.8       |
| time/                   |            |
|    total_timesteps      | 8999424    |
| train/                  |            |
|    approx_kl            | 0.07154067 |
|    clip_fraction        | 0.0929     |
|    clip_range           | 0.187      |
|    entropy_loss         | -0.0885    |
|    explained_variance   | 0.604      |
|    learning_rate        | 9.11e-05   |
|    loss                 | 15.4       |
|    n_updates            | 548        |
|    policy_gradient_loss | 0.013      |
|    value_loss           | 46.5       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 661      |
|    ep_rew_mean     | 340      |
| time/              |          |
|    fps             | 535      |
|    iterations      | 138      |
|    time_elapsed    | 16899    |
|    total_timesteps | 9043968  |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 671        |
|    ep_rew_mean          | 348        |
| time/                   |            |
|    fps                  | 535        |
|    iterations           | 139        |
|    time_elapsed         | 17021      |
|    total_timesteps      | 9109504    |
| train/                  |            |
|    approx_kl            | 0.09423129 |
|    clip_fraction        | 0.0962     |
|    clip_range           | 0.186      |
|    entropy_loss         | -0.0929    |
|    explained_variance   | 0.62       |
|    learning_rate        | 9.1e-05    |
|    loss                 | 12.8       |
|    n_updates            | 552        |
|    policy_gradient_loss | 0.0104     |
|    value_loss           | 43.7       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 723        |
|    ep_rew_mean          | 426        |
| time/                   |            |
|    fps                  | 535        |
|    iterations           | 140        |
|    time_elapsed         | 17145      |
|    total_timesteps      | 9175040    |
| train/                  |            |
|    approx_kl            | 0.07753692 |
|    clip_fraction        | 0.0987     |
|    clip_range           | 0.186      |
|    entropy_loss         | -0.0912    |
|    explained_variance   | 0.559      |
|    learning_rate        | 9.1e-05    |
|    loss                 | 14.3       |
|    n_updates            | 556        |
|    policy_gradient_loss | 0.0165     |
|    value_loss           | 46.5       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 700        |
|    ep_rew_mean          | 384        |
| time/                   |            |
|    fps                  | 535        |
|    iterations           | 141        |
|    time_elapsed         | 17266      |
|    total_timesteps      | 9240576    |
| train/                  |            |
|    approx_kl            | 0.07387009 |
|    clip_fraction        | 0.0937     |
|    clip_range           | 0.186      |
|    entropy_loss         | -0.0879    |
|    explained_variance   | 0.62       |
|    learning_rate        | 9.09e-05   |
|    loss                 | 15.3       |
|    n_updates            | 560        |
|    policy_gradient_loss | 0.0154     |
|    value_loss           | 48         |
----------------------------------------
Eval num_timesteps=9249408, episode_reward=-8.07 +/- 4.23
Episode length: 7.60 +/- 2.15
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 7.6         |
|    mean_reward          | -8.07       |
| time/                   |             |
|    total_timesteps      | 9249408     |
| train/                  |             |
|    approx_kl            | 0.098581105 |
|    clip_fraction        | 0.0942      |
|    clip_range           | 0.186       |
|    entropy_loss         | -0.0853     |
|    explained_variance   | 0.565       |
|    learning_rate        | 9.09e-05    |
|    loss                 | 11          |
|    n_updates            | 564         |
|    policy_gradient_loss | 0.0133      |
|    value_loss           | 45.8        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 670      |
|    ep_rew_mean     | 356      |
| time/              |          |
|    fps             | 535      |
|    iterations      | 142      |
|    time_elapsed    | 17389    |
|    total_timesteps | 9306112  |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 646        |
|    ep_rew_mean          | 359        |
| time/                   |            |
|    fps                  | 535        |
|    iterations           | 143        |
|    time_elapsed         | 17513      |
|    total_timesteps      | 9371648    |
| train/                  |            |
|    approx_kl            | 0.07136008 |
|    clip_fraction        | 0.0991     |
|    clip_range           | 0.186      |
|    entropy_loss         | -0.0912    |
|    explained_variance   | 0.557      |
|    learning_rate        | 9.08e-05   |
|    loss                 | 13.4       |
|    n_updates            | 568        |
|    policy_gradient_loss | 0.0157     |
|    value_loss           | 44.2       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 731        |
|    ep_rew_mean          | 418        |
| time/                   |            |
|    fps                  | 535        |
|    iterations           | 144        |
|    time_elapsed         | 17634      |
|    total_timesteps      | 9437184    |
| train/                  |            |
|    approx_kl            | 0.06681515 |
|    clip_fraction        | 0.0869     |
|    clip_range           | 0.186      |
|    entropy_loss         | -0.083     |
|    explained_variance   | 0.589      |
|    learning_rate        | 9.07e-05   |
|    loss                 | 12.2       |
|    n_updates            | 572        |
|    policy_gradient_loss | 0.0131     |
|    value_loss           | 48.1       |
----------------------------------------
Eval num_timesteps=9499392, episode_reward=-9.32 +/- 3.47
Episode length: 9.80 +/- 5.15
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 9.8        |
|    mean_reward          | -9.32      |
| time/                   |            |
|    total_timesteps      | 9499392    |
| train/                  |            |
|    approx_kl            | 0.06998631 |
|    clip_fraction        | 0.0893     |
|    clip_range           | 0.186      |
|    entropy_loss         | -0.0836    |
|    explained_variance   | 0.571      |
|    learning_rate        | 9.07e-05   |
|    loss                 | 13.5       |
|    n_updates            | 576        |
|    policy_gradient_loss | 0.0161     |
|    value_loss           | 45.2       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 733      |
|    ep_rew_mean     | 400      |
| time/              |          |
|    fps             | 535      |
|    iterations      | 145      |
|    time_elapsed    | 17761    |
|    total_timesteps | 9502720  |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 755        |
|    ep_rew_mean          | 407        |
| time/                   |            |
|    fps                  | 535        |
|    iterations           | 146        |
|    time_elapsed         | 17884      |
|    total_timesteps      | 9568256    |
| train/                  |            |
|    approx_kl            | 0.07487666 |
|    clip_fraction        | 0.0943     |
|    clip_range           | 0.186      |
|    entropy_loss         | -0.0851    |
|    explained_variance   | 0.599      |
|    learning_rate        | 9.06e-05   |
|    loss                 | 12.5       |
|    n_updates            | 580        |
|    policy_gradient_loss | 0.018      |
|    value_loss           | 46.8       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 813        |
|    ep_rew_mean          | 379        |
| time/                   |            |
|    fps                  | 535        |
|    iterations           | 147        |
|    time_elapsed         | 18002      |
|    total_timesteps      | 9633792    |
| train/                  |            |
|    approx_kl            | 0.12786508 |
|    clip_fraction        | 0.101      |
|    clip_range           | 0.186      |
|    entropy_loss         | -0.0877    |
|    explained_variance   | 0.597      |
|    learning_rate        | 9.05e-05   |
|    loss                 | 12.2       |
|    n_updates            | 584        |
|    policy_gradient_loss | 0.0194     |
|    value_loss           | 41.3       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 728         |
|    ep_rew_mean          | 288         |
| time/                   |             |
|    fps                  | 535         |
|    iterations           | 148         |
|    time_elapsed         | 18114       |
|    total_timesteps      | 9699328     |
| train/                  |             |
|    approx_kl            | 0.068112984 |
|    clip_fraction        | 0.095       |
|    clip_range           | 0.186       |
|    entropy_loss         | -0.0853     |
|    explained_variance   | 0.475       |
|    learning_rate        | 9.05e-05    |
|    loss                 | 10.9        |
|    n_updates            | 588         |
|    policy_gradient_loss | 0.0195      |
|    value_loss           | 41.5        |
-----------------------------------------
Eval num_timesteps=9749376, episode_reward=-7.89 +/- 4.33
Episode length: 6.00 +/- 1.10
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 6          |
|    mean_reward          | -7.89      |
| time/                   |            |
|    total_timesteps      | 9749376    |
| train/                  |            |
|    approx_kl            | 0.08830422 |
|    clip_fraction        | 0.0824     |
|    clip_range           | 0.185      |
|    entropy_loss         | -0.0809    |
|    explained_variance   | 0.598      |
|    learning_rate        | 9.04e-05   |
|    loss                 | 9.8        |
|    n_updates            | 592        |
|    policy_gradient_loss | 0.0102     |
|    value_loss           | 37.4       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 672      |
|    ep_rew_mean     | 277      |
| time/              |          |
|    fps             | 535      |
|    iterations      | 149      |
|    time_elapsed    | 18229    |
|    total_timesteps | 9764864  |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 677        |
|    ep_rew_mean          | 307        |
| time/                   |            |
|    fps                  | 535        |
|    iterations           | 150        |
|    time_elapsed         | 18347      |
|    total_timesteps      | 9830400    |
| train/                  |            |
|    approx_kl            | 0.06465998 |
|    clip_fraction        | 0.0928     |
|    clip_range           | 0.185      |
|    entropy_loss         | -0.0951    |
|    explained_variance   | 0.626      |
|    learning_rate        | 9.03e-05   |
|    loss                 | 10.5       |
|    n_updates            | 596        |
|    policy_gradient_loss | 0.0124     |
|    value_loss           | 40.3       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 735        |
|    ep_rew_mean          | 336        |
| time/                   |            |
|    fps                  | 536        |
|    iterations           | 151        |
|    time_elapsed         | 18458      |
|    total_timesteps      | 9895936    |
| train/                  |            |
|    approx_kl            | 0.08020892 |
|    clip_fraction        | 0.085      |
|    clip_range           | 0.185      |
|    entropy_loss         | -0.0832    |
|    explained_variance   | 0.651      |
|    learning_rate        | 9.03e-05   |
|    loss                 | 12.6       |
|    n_updates            | 600        |
|    policy_gradient_loss | 0.0117     |
|    value_loss           | 40.7       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 686         |
|    ep_rew_mean          | 335         |
| time/                   |             |
|    fps                  | 536         |
|    iterations           | 152         |
|    time_elapsed         | 18577       |
|    total_timesteps      | 9961472     |
| train/                  |             |
|    approx_kl            | 0.080342785 |
|    clip_fraction        | 0.0941      |
|    clip_range           | 0.185       |
|    entropy_loss         | -0.0869     |
|    explained_variance   | 0.657       |
|    learning_rate        | 9.02e-05    |
|    loss                 | 10.9        |
|    n_updates            | 604         |
|    policy_gradient_loss | 0.0131      |
|    value_loss           | 42.5        |
-----------------------------------------
Eval num_timesteps=9999360, episode_reward=-6.66 +/- 5.16
Episode length: 7.20 +/- 2.36
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 7.2        |
|    mean_reward          | -6.66      |
| time/                   |            |
|    total_timesteps      | 9999360    |
| train/                  |            |
|    approx_kl            | 0.08399373 |
|    clip_fraction        | 0.0933     |
|    clip_range           | 0.185      |
|    entropy_loss         | -0.0841    |
|    explained_variance   | 0.645      |
|    learning_rate        | 9.01e-05   |
|    loss                 | 11.2       |
|    n_updates            | 608        |
|    policy_gradient_loss | 0.0139     |
|    value_loss           | 46.6       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 766      |
|    ep_rew_mean     | 381      |
| time/              |          |
|    fps             | 536      |
|    iterations      | 153      |
|    time_elapsed    | 18701    |
|    total_timesteps | 10027008 |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 692        |
|    ep_rew_mean          | 348        |
| time/                   |            |
|    fps                  | 536        |
|    iterations           | 154        |
|    time_elapsed         | 18821      |
|    total_timesteps      | 10092544   |
| train/                  |            |
|    approx_kl            | 0.06370735 |
|    clip_fraction        | 0.088      |
|    clip_range           | 0.185      |
|    entropy_loss         | -0.0842    |
|    explained_variance   | 0.619      |
|    learning_rate        | 9.01e-05   |
|    loss                 | 13.4       |
|    n_updates            | 612        |
|    policy_gradient_loss | 0.0134     |
|    value_loss           | 47.2       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 825        |
|    ep_rew_mean          | 393        |
| time/                   |            |
|    fps                  | 536        |
|    iterations           | 155        |
|    time_elapsed         | 18942      |
|    total_timesteps      | 10158080   |
| train/                  |            |
|    approx_kl            | 0.07497764 |
|    clip_fraction        | 0.0981     |
|    clip_range           | 0.185      |
|    entropy_loss         | -0.0912    |
|    explained_variance   | 0.586      |
|    learning_rate        | 9e-05      |
|    loss                 | 12.6       |
|    n_updates            | 616        |
|    policy_gradient_loss | 0.0138     |
|    value_loss           | 48.2       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 776        |
|    ep_rew_mean          | 354        |
| time/                   |            |
|    fps                  | 536        |
|    iterations           | 156        |
|    time_elapsed         | 19063      |
|    total_timesteps      | 10223616   |
| train/                  |            |
|    approx_kl            | 0.07401171 |
|    clip_fraction        | 0.086      |
|    clip_range           | 0.185      |
|    entropy_loss         | -0.0808    |
|    explained_variance   | 0.559      |
|    learning_rate        | 8.99e-05   |
|    loss                 | 14.9       |
|    n_updates            | 620        |
|    policy_gradient_loss | 0.0154     |
|    value_loss           | 46.7       |
----------------------------------------
Eval num_timesteps=10249344, episode_reward=-6.90 +/- 5.16
Episode length: 7.60 +/- 2.29
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 7.6         |
|    mean_reward          | -6.9        |
| time/                   |             |
|    total_timesteps      | 10249344    |
| train/                  |             |
|    approx_kl            | 0.107276976 |
|    clip_fraction        | 0.104       |
|    clip_range           | 0.185       |
|    entropy_loss         | -0.0916     |
|    explained_variance   | 0.673       |
|    learning_rate        | 8.99e-05    |
|    loss                 | 11.7        |
|    n_updates            | 624         |
|    policy_gradient_loss | 0.016       |
|    value_loss           | 43.9        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 719      |
|    ep_rew_mean     | 358      |
| time/              |          |
|    fps             | 536      |
|    iterations      | 157      |
|    time_elapsed    | 19186    |
|    total_timesteps | 10289152 |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 673        |
|    ep_rew_mean          | 280        |
| time/                   |            |
|    fps                  | 536        |
|    iterations           | 158        |
|    time_elapsed         | 19307      |
|    total_timesteps      | 10354688   |
| train/                  |            |
|    approx_kl            | 0.10714975 |
|    clip_fraction        | 0.104      |
|    clip_range           | 0.185      |
|    entropy_loss         | -0.0792    |
|    explained_variance   | 0.6        |
|    learning_rate        | 8.98e-05   |
|    loss                 | 15.9       |
|    n_updates            | 628        |
|    policy_gradient_loss | 0.03       |
|    value_loss           | 50.8       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 737        |
|    ep_rew_mean          | 334        |
| time/                   |            |
|    fps                  | 536        |
|    iterations           | 159        |
|    time_elapsed         | 19430      |
|    total_timesteps      | 10420224   |
| train/                  |            |
|    approx_kl            | 0.08806664 |
|    clip_fraction        | 0.0976     |
|    clip_range           | 0.184      |
|    entropy_loss         | -0.0936    |
|    explained_variance   | 0.672      |
|    learning_rate        | 8.97e-05   |
|    loss                 | 10.4       |
|    n_updates            | 632        |
|    policy_gradient_loss | 0.0149     |
|    value_loss           | 40.9       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 736        |
|    ep_rew_mean          | 356        |
| time/                   |            |
|    fps                  | 536        |
|    iterations           | 160        |
|    time_elapsed         | 19551      |
|    total_timesteps      | 10485760   |
| train/                  |            |
|    approx_kl            | 0.09079735 |
|    clip_fraction        | 0.107      |
|    clip_range           | 0.184      |
|    entropy_loss         | -0.0932    |
|    explained_variance   | 0.618      |
|    learning_rate        | 8.97e-05   |
|    loss                 | 13         |
|    n_updates            | 636        |
|    policy_gradient_loss | 0.0191     |
|    value_loss           | 46.6       |
----------------------------------------
Eval num_timesteps=10499328, episode_reward=-7.89 +/- 4.43
Episode length: 7.70 +/- 4.31
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 7.7        |
|    mean_reward          | -7.89      |
| time/                   |            |
|    total_timesteps      | 10499328   |
| train/                  |            |
|    approx_kl            | 0.08595191 |
|    clip_fraction        | 0.0967     |
|    clip_range           | 0.184      |
|    entropy_loss         | -0.0854    |
|    explained_variance   | 0.67       |
|    learning_rate        | 8.96e-05   |
|    loss                 | 12.6       |
|    n_updates            | 640        |
|    policy_gradient_loss | 0.0154     |
|    value_loss           | 42.3       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 680      |
|    ep_rew_mean     | 300      |
| time/              |          |
|    fps             | 536      |
|    iterations      | 161      |
|    time_elapsed    | 19677    |
|    total_timesteps | 10551296 |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 695        |
|    ep_rew_mean          | 338        |
| time/                   |            |
|    fps                  | 536        |
|    iterations           | 162        |
|    time_elapsed         | 19798      |
|    total_timesteps      | 10616832   |
| train/                  |            |
|    approx_kl            | 0.07151802 |
|    clip_fraction        | 0.0812     |
|    clip_range           | 0.184      |
|    entropy_loss         | -0.0771    |
|    explained_variance   | 0.649      |
|    learning_rate        | 8.96e-05   |
|    loss                 | 15         |
|    n_updates            | 644        |
|    policy_gradient_loss | 0.0121     |
|    value_loss           | 45.5       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 683        |
|    ep_rew_mean          | 339        |
| time/                   |            |
|    fps                  | 536        |
|    iterations           | 163        |
|    time_elapsed         | 19918      |
|    total_timesteps      | 10682368   |
| train/                  |            |
|    approx_kl            | 0.07224466 |
|    clip_fraction        | 0.0852     |
|    clip_range           | 0.184      |
|    entropy_loss         | -0.0771    |
|    explained_variance   | 0.677      |
|    learning_rate        | 8.95e-05   |
|    loss                 | 12.6       |
|    n_updates            | 648        |
|    policy_gradient_loss | 0.0131     |
|    value_loss           | 45.2       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 717        |
|    ep_rew_mean          | 330        |
| time/                   |            |
|    fps                  | 536        |
|    iterations           | 164        |
|    time_elapsed         | 20039      |
|    total_timesteps      | 10747904   |
| train/                  |            |
|    approx_kl            | 0.07247086 |
|    clip_fraction        | 0.0945     |
|    clip_range           | 0.184      |
|    entropy_loss         | -0.0882    |
|    explained_variance   | 0.694      |
|    learning_rate        | 8.94e-05   |
|    loss                 | 13.8       |
|    n_updates            | 652        |
|    policy_gradient_loss | 0.0147     |
|    value_loss           | 44.9       |
----------------------------------------
Eval num_timesteps=10749312, episode_reward=-4.79 +/- 7.28
Episode length: 8.90 +/- 3.65
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 8.9        |
|    mean_reward          | -4.79      |
| time/                   |            |
|    total_timesteps      | 10749312   |
| train/                  |            |
|    approx_kl            | 0.07575321 |
|    clip_fraction        | 0.0896     |
|    clip_range           | 0.184      |
|    entropy_loss         | -0.0791    |
|    explained_variance   | 0.606      |
|    learning_rate        | 8.94e-05   |
|    loss                 | 11.6       |
|    n_updates            | 656        |
|    policy_gradient_loss | 0.0115     |
|    value_loss           | 40.5       |
----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 741      |
|    ep_rew_mean     | 337      |
| time/              |          |
|    fps             | 536      |
|    iterations      | 165      |
|    time_elapsed    | 20165    |
|    total_timesteps | 10813440 |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 718        |
|    ep_rew_mean          | 351        |
| time/                   |            |
|    fps                  | 536        |
|    iterations           | 166        |
|    time_elapsed         | 20287      |
|    total_timesteps      | 10878976   |
| train/                  |            |
|    approx_kl            | 0.06934809 |
|    clip_fraction        | 0.0943     |
|    clip_range           | 0.184      |
|    entropy_loss         | -0.0907    |
|    explained_variance   | 0.613      |
|    learning_rate        | 8.93e-05   |
|    loss                 | 12.8       |
|    n_updates            | 660        |
|    policy_gradient_loss | 0.0117     |
|    value_loss           | 44.4       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 671         |
|    ep_rew_mean          | 308         |
| time/                   |             |
|    fps                  | 536         |
|    iterations           | 167         |
|    time_elapsed         | 20411       |
|    total_timesteps      | 10944512    |
| train/                  |             |
|    approx_kl            | 0.082887955 |
|    clip_fraction        | 0.0927      |
|    clip_range           | 0.184       |
|    entropy_loss         | -0.0841     |
|    explained_variance   | 0.597       |
|    learning_rate        | 8.92e-05    |
|    loss                 | 14.2        |
|    n_updates            | 664         |
|    policy_gradient_loss | 0.0145      |
|    value_loss           | 48.9        |
-----------------------------------------
Eval num_timesteps=10999296, episode_reward=-9.15 +/- 2.95
Episode length: 8.40 +/- 3.64
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 8.4        |
|    mean_reward          | -9.15      |
| time/                   |            |
|    total_timesteps      | 10999296   |
| train/                  |            |
|    approx_kl            | 0.07606846 |
|    clip_fraction        | 0.0956     |
|    clip_range           | 0.184      |
|    entropy_loss         | -0.0873    |
|    explained_variance   | 0.592      |
|    learning_rate        | 8.92e-05   |
|    loss                 | 16.3       |
|    n_updates            | 668        |
|    policy_gradient_loss | 0.0145     |
|    value_loss           | 48.2       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 739      |
|    ep_rew_mean     | 324      |
| time/              |          |
|    fps             | 536      |
|    iterations      | 168      |
|    time_elapsed    | 20535    |
|    total_timesteps | 11010048 |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 701        |
|    ep_rew_mean          | 335        |
| time/                   |            |
|    fps                  | 536        |
|    iterations           | 169        |
|    time_elapsed         | 20658      |
|    total_timesteps      | 11075584   |
| train/                  |            |
|    approx_kl            | 0.07696566 |
|    clip_fraction        | 0.0837     |
|    clip_range           | 0.183      |
|    entropy_loss         | -0.0758    |
|    explained_variance   | 0.65       |
|    learning_rate        | 8.91e-05   |
|    loss                 | 10.4       |
|    n_updates            | 672        |
|    policy_gradient_loss | 0.013      |
|    value_loss           | 43.1       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 678        |
|    ep_rew_mean          | 334        |
| time/                   |            |
|    fps                  | 536        |
|    iterations           | 170        |
|    time_elapsed         | 20780      |
|    total_timesteps      | 11141120   |
| train/                  |            |
|    approx_kl            | 0.07883729 |
|    clip_fraction        | 0.0911     |
|    clip_range           | 0.183      |
|    entropy_loss         | -0.0788    |
|    explained_variance   | 0.652      |
|    learning_rate        | 8.9e-05    |
|    loss                 | 14.4       |
|    n_updates            | 676        |
|    policy_gradient_loss | 0.0179     |
|    value_loss           | 46.6       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 688        |
|    ep_rew_mean          | 339        |
| time/                   |            |
|    fps                  | 536        |
|    iterations           | 171        |
|    time_elapsed         | 20903      |
|    total_timesteps      | 11206656   |
| train/                  |            |
|    approx_kl            | 0.06521186 |
|    clip_fraction        | 0.0852     |
|    clip_range           | 0.183      |
|    entropy_loss         | -0.0826    |
|    explained_variance   | 0.631      |
|    learning_rate        | 8.9e-05    |
|    loss                 | 15         |
|    n_updates            | 680        |
|    policy_gradient_loss | 0.0114     |
|    value_loss           | 46.4       |
----------------------------------------
Eval num_timesteps=11249280, episode_reward=-5.52 +/- 5.44
Episode length: 7.70 +/- 2.93
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 7.7         |
|    mean_reward          | -5.52       |
| time/                   |             |
|    total_timesteps      | 11249280    |
| train/                  |             |
|    approx_kl            | 0.093608186 |
|    clip_fraction        | 0.1         |
|    clip_range           | 0.183       |
|    entropy_loss         | -0.0837     |
|    explained_variance   | 0.625       |
|    learning_rate        | 8.89e-05    |
|    loss                 | 12.4        |
|    n_updates            | 684         |
|    policy_gradient_loss | 0.019       |
|    value_loss           | 40.7        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 717      |
|    ep_rew_mean     | 335      |
| time/              |          |
|    fps             | 536      |
|    iterations      | 172      |
|    time_elapsed    | 21026    |
|    total_timesteps | 11272192 |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 694         |
|    ep_rew_mean          | 293         |
| time/                   |             |
|    fps                  | 536         |
|    iterations           | 173         |
|    time_elapsed         | 21149       |
|    total_timesteps      | 11337728    |
| train/                  |             |
|    approx_kl            | 0.067021966 |
|    clip_fraction        | 0.0901      |
|    clip_range           | 0.183       |
|    entropy_loss         | -0.085      |
|    explained_variance   | 0.634       |
|    learning_rate        | 8.88e-05    |
|    loss                 | 11.1        |
|    n_updates            | 688         |
|    policy_gradient_loss | 0.0132      |
|    value_loss           | 39.5        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 686        |
|    ep_rew_mean          | 189        |
| time/                   |            |
|    fps                  | 536        |
|    iterations           | 174        |
|    time_elapsed         | 21271      |
|    total_timesteps      | 11403264   |
| train/                  |            |
|    approx_kl            | 0.08113165 |
|    clip_fraction        | 0.0875     |
|    clip_range           | 0.183      |
|    entropy_loss         | -0.0858    |
|    explained_variance   | 0.63       |
|    learning_rate        | 8.88e-05   |
|    loss                 | 11.7       |
|    n_updates            | 692        |
|    policy_gradient_loss | 0.0128     |
|    value_loss           | 41         |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 685        |
|    ep_rew_mean          | 117        |
| time/                   |            |
|    fps                  | 536        |
|    iterations           | 175        |
|    time_elapsed         | 21393      |
|    total_timesteps      | 11468800   |
| train/                  |            |
|    approx_kl            | 0.06353307 |
|    clip_fraction        | 0.0962     |
|    clip_range           | 0.183      |
|    entropy_loss         | -0.0984    |
|    explained_variance   | 0.674      |
|    learning_rate        | 8.87e-05   |
|    loss                 | 6.03       |
|    n_updates            | 696        |
|    policy_gradient_loss | 0.00994    |
|    value_loss           | 26.5       |
----------------------------------------
Eval num_timesteps=11499264, episode_reward=-7.95 +/- 4.65
Episode length: 7.60 +/- 4.27
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 7.6        |
|    mean_reward          | -7.95      |
| time/                   |            |
|    total_timesteps      | 11499264   |
| train/                  |            |
|    approx_kl            | 0.07739541 |
|    clip_fraction        | 0.0948     |
|    clip_range           | 0.183      |
|    entropy_loss         | -0.0995    |
|    explained_variance   | 0.717      |
|    learning_rate        | 8.86e-05   |
|    loss                 | 7.44       |
|    n_updates            | 700        |
|    policy_gradient_loss | 0.0113     |
|    value_loss           | 23.4       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 728      |
|    ep_rew_mean     | 183      |
| time/              |          |
|    fps             | 536      |
|    iterations      | 176      |
|    time_elapsed    | 21517    |
|    total_timesteps | 11534336 |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 762         |
|    ep_rew_mean          | 192         |
| time/                   |             |
|    fps                  | 536         |
|    iterations           | 177         |
|    time_elapsed         | 21638       |
|    total_timesteps      | 11599872    |
| train/                  |             |
|    approx_kl            | 0.058357112 |
|    clip_fraction        | 0.0792      |
|    clip_range           | 0.183       |
|    entropy_loss         | -0.0796     |
|    explained_variance   | 0.716       |
|    learning_rate        | 8.86e-05    |
|    loss                 | 8.99        |
|    n_updates            | 704         |
|    policy_gradient_loss | 0.0108      |
|    value_loss           | 30.4        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 770        |
|    ep_rew_mean          | 186        |
| time/                   |            |
|    fps                  | 536        |
|    iterations           | 178        |
|    time_elapsed         | 21761      |
|    total_timesteps      | 11665408   |
| train/                  |            |
|    approx_kl            | 0.04951733 |
|    clip_fraction        | 0.0786     |
|    clip_range           | 0.183      |
|    entropy_loss         | -0.0801    |
|    explained_variance   | 0.768      |
|    learning_rate        | 8.85e-05   |
|    loss                 | 7.99       |
|    n_updates            | 708        |
|    policy_gradient_loss | 0.0108     |
|    value_loss           | 27.9       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 735         |
|    ep_rew_mean          | 205         |
| time/                   |             |
|    fps                  | 536         |
|    iterations           | 179         |
|    time_elapsed         | 21882       |
|    total_timesteps      | 11730944    |
| train/                  |             |
|    approx_kl            | 0.057801872 |
|    clip_fraction        | 0.0761      |
|    clip_range           | 0.183       |
|    entropy_loss         | -0.0755     |
|    explained_variance   | 0.795       |
|    learning_rate        | 8.85e-05    |
|    loss                 | 6.6         |
|    n_updates            | 712         |
|    policy_gradient_loss | 0.00975     |
|    value_loss           | 26.8        |
-----------------------------------------
Eval num_timesteps=11749248, episode_reward=-6.74 +/- 7.53
Episode length: 9.10 +/- 8.15
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 9.1       |
|    mean_reward          | -6.74     |
| time/                   |           |
|    total_timesteps      | 11749248  |
| train/                  |           |
|    approx_kl            | 0.0553784 |
|    clip_fraction        | 0.072     |
|    clip_range           | 0.182     |
|    entropy_loss         | -0.0677   |
|    explained_variance   | 0.794     |
|    learning_rate        | 8.84e-05  |
|    loss                 | 7.6       |
|    n_updates            | 716       |
|    policy_gradient_loss | 0.0132    |
|    value_loss           | 32.1      |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 764      |
|    ep_rew_mean     | 206      |
| time/              |          |
|    fps             | 536      |
|    iterations      | 180      |
|    time_elapsed    | 22007    |
|    total_timesteps | 11796480 |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 770         |
|    ep_rew_mean          | 227         |
| time/                   |             |
|    fps                  | 536         |
|    iterations           | 181         |
|    time_elapsed         | 22128       |
|    total_timesteps      | 11862016    |
| train/                  |             |
|    approx_kl            | 0.087394945 |
|    clip_fraction        | 0.0839      |
|    clip_range           | 0.182       |
|    entropy_loss         | -0.0676     |
|    explained_variance   | 0.8         |
|    learning_rate        | 8.83e-05    |
|    loss                 | 9.14        |
|    n_updates            | 720         |
|    policy_gradient_loss | 0.0136      |
|    value_loss           | 29.5        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 773        |
|    ep_rew_mean          | 217        |
| time/                   |            |
|    fps                  | 536        |
|    iterations           | 182        |
|    time_elapsed         | 22251      |
|    total_timesteps      | 11927552   |
| train/                  |            |
|    approx_kl            | 0.09588966 |
|    clip_fraction        | 0.084      |
|    clip_range           | 0.182      |
|    entropy_loss         | -0.07      |
|    explained_variance   | 0.791      |
|    learning_rate        | 8.83e-05   |
|    loss                 | 9.32       |
|    n_updates            | 724        |
|    policy_gradient_loss | 0.0163     |
|    value_loss           | 31         |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 763         |
|    ep_rew_mean          | 227         |
| time/                   |             |
|    fps                  | 536         |
|    iterations           | 183         |
|    time_elapsed         | 22373       |
|    total_timesteps      | 11993088    |
| train/                  |             |
|    approx_kl            | 0.052573543 |
|    clip_fraction        | 0.0709      |
|    clip_range           | 0.182       |
|    entropy_loss         | -0.0697     |
|    explained_variance   | 0.802       |
|    learning_rate        | 8.82e-05    |
|    loss                 | 9.09        |
|    n_updates            | 728         |
|    policy_gradient_loss | 0.0128      |
|    value_loss           | 30          |
-----------------------------------------
Eval num_timesteps=11999232, episode_reward=-6.98 +/- 4.84
Episode length: 8.10 +/- 3.08
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 8.1         |
|    mean_reward          | -6.98       |
| time/                   |             |
|    total_timesteps      | 11999232    |
| train/                  |             |
|    approx_kl            | 0.054444507 |
|    clip_fraction        | 0.0718      |
|    clip_range           | 0.182       |
|    entropy_loss         | -0.0713     |
|    explained_variance   | 0.815       |
|    learning_rate        | 8.81e-05    |
|    loss                 | 9.2         |
|    n_updates            | 732         |
|    policy_gradient_loss | 0.0113      |
|    value_loss           | 32.9        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 682      |
|    ep_rew_mean     | 186      |
| time/              |          |
|    fps             | 535      |
|    iterations      | 184      |
|    time_elapsed    | 22498    |
|    total_timesteps | 12058624 |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 743        |
|    ep_rew_mean          | 276        |
| time/                   |            |
|    fps                  | 536        |
|    iterations           | 185        |
|    time_elapsed         | 22617      |
|    total_timesteps      | 12124160   |
| train/                  |            |
|    approx_kl            | 0.06618607 |
|    clip_fraction        | 0.0791     |
|    clip_range           | 0.182      |
|    entropy_loss         | -0.0818    |
|    explained_variance   | 0.818      |
|    learning_rate        | 8.81e-05   |
|    loss                 | 12.4       |
|    n_updates            | 736        |
|    policy_gradient_loss | 0.0103     |
|    value_loss           | 35.9       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 737         |
|    ep_rew_mean          | 244         |
| time/                   |             |
|    fps                  | 536         |
|    iterations           | 186         |
|    time_elapsed         | 22733       |
|    total_timesteps      | 12189696    |
| train/                  |             |
|    approx_kl            | 0.059761394 |
|    clip_fraction        | 0.0687      |
|    clip_range           | 0.182       |
|    entropy_loss         | -0.0616     |
|    explained_variance   | 0.786       |
|    learning_rate        | 8.8e-05     |
|    loss                 | 9.63        |
|    n_updates            | 740         |
|    policy_gradient_loss | 0.0132      |
|    value_loss           | 35.6        |
-----------------------------------------
Eval num_timesteps=12249216, episode_reward=-7.93 +/- 4.19
Episode length: 8.90 +/- 3.39
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 8.9        |
|    mean_reward          | -7.93      |
| time/                   |            |
|    total_timesteps      | 12249216   |
| train/                  |            |
|    approx_kl            | 0.06981107 |
|    clip_fraction        | 0.074      |
|    clip_range           | 0.182      |
|    entropy_loss         | -0.0719    |
|    explained_variance   | 0.759      |
|    learning_rate        | 8.79e-05   |
|    loss                 | 12.5       |
|    n_updates            | 744        |
|    policy_gradient_loss | 0.0127     |
|    value_loss           | 38.6       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 791      |
|    ep_rew_mean     | 292      |
| time/              |          |
|    fps             | 536      |
|    iterations      | 187      |
|    time_elapsed    | 22846    |
|    total_timesteps | 12255232 |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 740        |
|    ep_rew_mean          | 251        |
| time/                   |            |
|    fps                  | 536        |
|    iterations           | 188        |
|    time_elapsed         | 22957      |
|    total_timesteps      | 12320768   |
| train/                  |            |
|    approx_kl            | 0.06724398 |
|    clip_fraction        | 0.0797     |
|    clip_range           | 0.182      |
|    entropy_loss         | -0.0737    |
|    explained_variance   | 0.788      |
|    learning_rate        | 8.79e-05   |
|    loss                 | 11.1       |
|    n_updates            | 748        |
|    policy_gradient_loss | 0.0141     |
|    value_loss           | 35.9       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 786         |
|    ep_rew_mean          | 292         |
| time/                   |             |
|    fps                  | 536         |
|    iterations           | 189         |
|    time_elapsed         | 23078       |
|    total_timesteps      | 12386304    |
| train/                  |             |
|    approx_kl            | 0.062215634 |
|    clip_fraction        | 0.079       |
|    clip_range           | 0.182       |
|    entropy_loss         | -0.0704     |
|    explained_variance   | 0.817       |
|    learning_rate        | 8.78e-05    |
|    loss                 | 10.9        |
|    n_updates            | 752         |
|    policy_gradient_loss | 0.0154      |
|    value_loss           | 36.7        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 829         |
|    ep_rew_mean          | 301         |
| time/                   |             |
|    fps                  | 536         |
|    iterations           | 190         |
|    time_elapsed         | 23195       |
|    total_timesteps      | 12451840    |
| train/                  |             |
|    approx_kl            | 0.060852423 |
|    clip_fraction        | 0.0652      |
|    clip_range           | 0.181       |
|    entropy_loss         | -0.0585     |
|    explained_variance   | 0.776       |
|    learning_rate        | 8.77e-05    |
|    loss                 | 10.5        |
|    n_updates            | 756         |
|    policy_gradient_loss | 0.0117      |
|    value_loss           | 35.3        |
-----------------------------------------
Eval num_timesteps=12499200, episode_reward=-8.18 +/- 4.58
Episode length: 8.10 +/- 2.47
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 8.1        |
|    mean_reward          | -8.18      |
| time/                   |            |
|    total_timesteps      | 12499200   |
| train/                  |            |
|    approx_kl            | 0.10094028 |
|    clip_fraction        | 0.079      |
|    clip_range           | 0.181      |
|    entropy_loss         | -0.0688    |
|    explained_variance   | 0.787      |
|    learning_rate        | 8.77e-05   |
|    loss                 | 10         |
|    n_updates            | 760        |
|    policy_gradient_loss | 0.0126     |
|    value_loss           | 35.2       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 837      |
|    ep_rew_mean     | 306      |
| time/              |          |
|    fps             | 536      |
|    iterations      | 191      |
|    time_elapsed    | 23315    |
|    total_timesteps | 12517376 |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 785        |
|    ep_rew_mean          | 284        |
| time/                   |            |
|    fps                  | 536        |
|    iterations           | 192        |
|    time_elapsed         | 23436      |
|    total_timesteps      | 12582912   |
| train/                  |            |
|    approx_kl            | 0.08107211 |
|    clip_fraction        | 0.0862     |
|    clip_range           | 0.181      |
|    entropy_loss         | -0.0734    |
|    explained_variance   | 0.74       |
|    learning_rate        | 8.76e-05   |
|    loss                 | 10.3       |
|    n_updates            | 764        |
|    policy_gradient_loss | 0.0135     |
|    value_loss           | 36.5       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 780        |
|    ep_rew_mean          | 288        |
| time/                   |            |
|    fps                  | 537        |
|    iterations           | 193        |
|    time_elapsed         | 23553      |
|    total_timesteps      | 12648448   |
| train/                  |            |
|    approx_kl            | 0.06652559 |
|    clip_fraction        | 0.0784     |
|    clip_range           | 0.181      |
|    entropy_loss         | -0.0729    |
|    explained_variance   | 0.77       |
|    learning_rate        | 8.75e-05   |
|    loss                 | 9.02       |
|    n_updates            | 768        |
|    policy_gradient_loss | 0.0113     |
|    value_loss           | 35         |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 833        |
|    ep_rew_mean          | 281        |
| time/                   |            |
|    fps                  | 537        |
|    iterations           | 194        |
|    time_elapsed         | 23670      |
|    total_timesteps      | 12713984   |
| train/                  |            |
|    approx_kl            | 0.07714741 |
|    clip_fraction        | 0.0808     |
|    clip_range           | 0.181      |
|    entropy_loss         | -0.0755    |
|    explained_variance   | 0.734      |
|    learning_rate        | 8.75e-05   |
|    loss                 | 10.4       |
|    n_updates            | 772        |
|    policy_gradient_loss | 0.0118     |
|    value_loss           | 36.9       |
----------------------------------------
Eval num_timesteps=12749184, episode_reward=-9.24 +/- 3.29
Episode length: 7.90 +/- 3.21
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 7.9         |
|    mean_reward          | -9.24       |
| time/                   |             |
|    total_timesteps      | 12749184    |
| train/                  |             |
|    approx_kl            | 0.075410575 |
|    clip_fraction        | 0.0858      |
|    clip_range           | 0.181       |
|    entropy_loss         | -0.079      |
|    explained_variance   | 0.754       |
|    learning_rate        | 8.74e-05    |
|    loss                 | 9.27        |
|    n_updates            | 776         |
|    policy_gradient_loss | 0.0154      |
|    value_loss           | 33.7        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 855      |
|    ep_rew_mean     | 267      |
| time/              |          |
|    fps             | 537      |
|    iterations      | 195      |
|    time_elapsed    | 23787    |
|    total_timesteps | 12779520 |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 811        |
|    ep_rew_mean          | 264        |
| time/                   |            |
|    fps                  | 537        |
|    iterations           | 196        |
|    time_elapsed         | 23906      |
|    total_timesteps      | 12845056   |
| train/                  |            |
|    approx_kl            | 0.06804453 |
|    clip_fraction        | 0.0829     |
|    clip_range           | 0.181      |
|    entropy_loss         | -0.0789    |
|    explained_variance   | 0.762      |
|    learning_rate        | 8.73e-05   |
|    loss                 | 8.69       |
|    n_updates            | 780        |
|    policy_gradient_loss | 0.0107     |
|    value_loss           | 31.3       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 768         |
|    ep_rew_mean          | 233         |
| time/                   |             |
|    fps                  | 537         |
|    iterations           | 197         |
|    time_elapsed         | 24026       |
|    total_timesteps      | 12910592    |
| train/                  |             |
|    approx_kl            | 0.052796483 |
|    clip_fraction        | 0.0687      |
|    clip_range           | 0.181       |
|    entropy_loss         | -0.0659     |
|    explained_variance   | 0.768       |
|    learning_rate        | 8.73e-05    |
|    loss                 | 10.8        |
|    n_updates            | 784         |
|    policy_gradient_loss | 0.0107      |
|    value_loss           | 33.8        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 809         |
|    ep_rew_mean          | 292         |
| time/                   |             |
|    fps                  | 537         |
|    iterations           | 198         |
|    time_elapsed         | 24143       |
|    total_timesteps      | 12976128    |
| train/                  |             |
|    approx_kl            | 0.060355533 |
|    clip_fraction        | 0.0754      |
|    clip_range           | 0.181       |
|    entropy_loss         | -0.0719     |
|    explained_variance   | 0.733       |
|    learning_rate        | 8.72e-05    |
|    loss                 | 7.78        |
|    n_updates            | 788         |
|    policy_gradient_loss | 0.0117      |
|    value_loss           | 31.1        |
-----------------------------------------
Eval num_timesteps=12999168, episode_reward=-7.89 +/- 4.40
Episode length: 8.50 +/- 4.10
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 8.5        |
|    mean_reward          | -7.89      |
| time/                   |            |
|    total_timesteps      | 12999168   |
| train/                  |            |
|    approx_kl            | 0.06288293 |
|    clip_fraction        | 0.0739     |
|    clip_range           | 0.181      |
|    entropy_loss         | -0.067     |
|    explained_variance   | 0.72       |
|    learning_rate        | 8.72e-05   |
|    loss                 | 12.5       |
|    n_updates            | 792        |
|    policy_gradient_loss | 0.011      |
|    value_loss           | 36         |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 803      |
|    ep_rew_mean     | 288      |
| time/              |          |
|    fps             | 537      |
|    iterations      | 199      |
|    time_elapsed    | 24272    |
|    total_timesteps | 13041664 |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 751       |
|    ep_rew_mean          | 275       |
| time/                   |           |
|    fps                  | 537       |
|    iterations           | 200       |
|    time_elapsed         | 24399     |
|    total_timesteps      | 13107200  |
| train/                  |           |
|    approx_kl            | 0.0781129 |
|    clip_fraction        | 0.0737    |
|    clip_range           | 0.18      |
|    entropy_loss         | -0.0622   |
|    explained_variance   | 0.763     |
|    learning_rate        | 8.71e-05  |
|    loss                 | 8.68      |
|    n_updates            | 796       |
|    policy_gradient_loss | 0.0153    |
|    value_loss           | 30.8      |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 770        |
|    ep_rew_mean          | 288        |
| time/                   |            |
|    fps                  | 537        |
|    iterations           | 201        |
|    time_elapsed         | 24519      |
|    total_timesteps      | 13172736   |
| train/                  |            |
|    approx_kl            | 0.06328934 |
|    clip_fraction        | 0.0781     |
|    clip_range           | 0.18       |
|    entropy_loss         | -0.0757    |
|    explained_variance   | 0.786      |
|    learning_rate        | 8.7e-05    |
|    loss                 | 7.88       |
|    n_updates            | 800        |
|    policy_gradient_loss | 0.0112     |
|    value_loss           | 33.5       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 850        |
|    ep_rew_mean          | 294        |
| time/                   |            |
|    fps                  | 537        |
|    iterations           | 202        |
|    time_elapsed         | 24641      |
|    total_timesteps      | 13238272   |
| train/                  |            |
|    approx_kl            | 0.07048605 |
|    clip_fraction        | 0.0933     |
|    clip_range           | 0.18       |
|    entropy_loss         | -0.0957    |
|    explained_variance   | 0.73       |
|    learning_rate        | 8.7e-05    |
|    loss                 | 10.1       |
|    n_updates            | 804        |
|    policy_gradient_loss | 0.0148     |
|    value_loss           | 34.3       |
----------------------------------------
Eval num_timesteps=13249152, episode_reward=-10.15 +/- 0.49
Episode length: 8.10 +/- 3.36
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 8.1         |
|    mean_reward          | -10.1       |
| time/                   |             |
|    total_timesteps      | 13249152    |
| train/                  |             |
|    approx_kl            | 0.092433706 |
|    clip_fraction        | 0.0835      |
|    clip_range           | 0.18        |
|    entropy_loss         | -0.0706     |
|    explained_variance   | 0.764       |
|    learning_rate        | 8.69e-05    |
|    loss                 | 8.98        |
|    n_updates            | 808         |
|    policy_gradient_loss | 0.015       |
|    value_loss           | 31.8        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 869      |
|    ep_rew_mean     | 281      |
| time/              |          |
|    fps             | 537      |
|    iterations      | 203      |
|    time_elapsed    | 24763    |
|    total_timesteps | 13303808 |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 837        |
|    ep_rew_mean          | 248        |
| time/                   |            |
|    fps                  | 537        |
|    iterations           | 204        |
|    time_elapsed         | 24884      |
|    total_timesteps      | 13369344   |
| train/                  |            |
|    approx_kl            | 0.07194066 |
|    clip_fraction        | 0.0845     |
|    clip_range           | 0.18       |
|    entropy_loss         | -0.0757    |
|    explained_variance   | 0.808      |
|    learning_rate        | 8.68e-05   |
|    loss                 | 8.31       |
|    n_updates            | 812        |
|    policy_gradient_loss | 0.0113     |
|    value_loss           | 28.3       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 763         |
|    ep_rew_mean          | 249         |
| time/                   |             |
|    fps                  | 537         |
|    iterations           | 205         |
|    time_elapsed         | 25005       |
|    total_timesteps      | 13434880    |
| train/                  |             |
|    approx_kl            | 0.057841986 |
|    clip_fraction        | 0.0783      |
|    clip_range           | 0.18        |
|    entropy_loss         | -0.074      |
|    explained_variance   | 0.757       |
|    learning_rate        | 8.68e-05    |
|    loss                 | 8.58        |
|    n_updates            | 816         |
|    policy_gradient_loss | 0.014       |
|    value_loss           | 32.9        |
-----------------------------------------
Eval num_timesteps=13499136, episode_reward=-10.31 +/- 0.33
Episode length: 7.70 +/- 3.55
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 7.7        |
|    mean_reward          | -10.3      |
| time/                   |            |
|    total_timesteps      | 13499136   |
| train/                  |            |
|    approx_kl            | 0.06507076 |
|    clip_fraction        | 0.0865     |
|    clip_range           | 0.18       |
|    entropy_loss         | -0.0837    |
|    explained_variance   | 0.748      |
|    learning_rate        | 8.67e-05   |
|    loss                 | 8.02       |
|    n_updates            | 820        |
|    policy_gradient_loss | 0.0151     |
|    value_loss           | 31.8       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 814      |
|    ep_rew_mean     | 281      |
| time/              |          |
|    fps             | 537      |
|    iterations      | 206      |
|    time_elapsed    | 25126    |
|    total_timesteps | 13500416 |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 745         |
|    ep_rew_mean          | 250         |
| time/                   |             |
|    fps                  | 537         |
|    iterations           | 207         |
|    time_elapsed         | 25247       |
|    total_timesteps      | 13565952    |
| train/                  |             |
|    approx_kl            | 0.062050223 |
|    clip_fraction        | 0.0838      |
|    clip_range           | 0.18        |
|    entropy_loss         | -0.0799     |
|    explained_variance   | 0.723       |
|    learning_rate        | 8.66e-05    |
|    loss                 | 10.3        |
|    n_updates            | 824         |
|    policy_gradient_loss | 0.0139      |
|    value_loss           | 33.4        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 699        |
|    ep_rew_mean          | 228        |
| time/                   |            |
|    fps                  | 537        |
|    iterations           | 208        |
|    time_elapsed         | 25369      |
|    total_timesteps      | 13631488   |
| train/                  |            |
|    approx_kl            | 0.06239701 |
|    clip_fraction        | 0.0921     |
|    clip_range           | 0.18       |
|    entropy_loss         | -0.0896    |
|    explained_variance   | 0.723      |
|    learning_rate        | 8.66e-05   |
|    loss                 | 9.53       |
|    n_updates            | 828        |
|    policy_gradient_loss | 0.015      |
|    value_loss           | 31.4       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 745        |
|    ep_rew_mean          | 278        |
| time/                   |            |
|    fps                  | 537        |
|    iterations           | 209        |
|    time_elapsed         | 25489      |
|    total_timesteps      | 13697024   |
| train/                  |            |
|    approx_kl            | 0.06340916 |
|    clip_fraction        | 0.0841     |
|    clip_range           | 0.18       |
|    entropy_loss         | -0.0771    |
|    explained_variance   | 0.735      |
|    learning_rate        | 8.65e-05   |
|    loss                 | 11.7       |
|    n_updates            | 832        |
|    policy_gradient_loss | 0.0149     |
|    value_loss           | 36.7       |
----------------------------------------
Eval num_timesteps=13749120, episode_reward=-3.59 +/- 9.10
Episode length: 11.10 +/- 4.55
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 11.1       |
|    mean_reward          | -3.59      |
| time/                   |            |
|    total_timesteps      | 13749120   |
| train/                  |            |
|    approx_kl            | 0.06436079 |
|    clip_fraction        | 0.0831     |
|    clip_range           | 0.179      |
|    entropy_loss         | -0.0766    |
|    explained_variance   | 0.783      |
|    learning_rate        | 8.64e-05   |
|    loss                 | 11.3       |
|    n_updates            | 836        |
|    policy_gradient_loss | 0.0129     |
|    value_loss           | 34.9       |
----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 737      |
|    ep_rew_mean     | 278      |
| time/              |          |
|    fps             | 537      |
|    iterations      | 210      |
|    time_elapsed    | 25615    |
|    total_timesteps | 13762560 |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 748       |
|    ep_rew_mean          | 309       |
| time/                   |           |
|    fps                  | 537       |
|    iterations           | 211       |
|    time_elapsed         | 25736     |
|    total_timesteps      | 13828096  |
| train/                  |           |
|    approx_kl            | 0.0855296 |
|    clip_fraction        | 0.085     |
|    clip_range           | 0.179     |
|    entropy_loss         | -0.0722   |
|    explained_variance   | 0.728     |
|    learning_rate        | 8.64e-05  |
|    loss                 | 10.6      |
|    n_updates            | 840       |
|    policy_gradient_loss | 0.019     |
|    value_loss           | 36.4      |
---------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 800         |
|    ep_rew_mean          | 321         |
| time/                   |             |
|    fps                  | 537         |
|    iterations           | 212         |
|    time_elapsed         | 25856       |
|    total_timesteps      | 13893632    |
| train/                  |             |
|    approx_kl            | 0.060174555 |
|    clip_fraction        | 0.0741      |
|    clip_range           | 0.179       |
|    entropy_loss         | -0.0709     |
|    explained_variance   | 0.714       |
|    learning_rate        | 8.63e-05    |
|    loss                 | 11.3        |
|    n_updates            | 844         |
|    policy_gradient_loss | 0.0116      |
|    value_loss           | 37.8        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 775        |
|    ep_rew_mean          | 330        |
| time/                   |            |
|    fps                  | 537        |
|    iterations           | 213        |
|    time_elapsed         | 25978      |
|    total_timesteps      | 13959168   |
| train/                  |            |
|    approx_kl            | 0.06059073 |
|    clip_fraction        | 0.0843     |
|    clip_range           | 0.179      |
|    entropy_loss         | -0.0759    |
|    explained_variance   | 0.732      |
|    learning_rate        | 8.62e-05   |
|    loss                 | 10.4       |
|    n_updates            | 848        |
|    policy_gradient_loss | 0.0152     |
|    value_loss           | 37.3       |
----------------------------------------
Eval num_timesteps=13999104, episode_reward=-9.93 +/- 4.86
Episode length: 64.20 +/- 170.94
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 64.2       |
|    mean_reward          | -9.93      |
| time/                   |            |
|    total_timesteps      | 13999104   |
| train/                  |            |
|    approx_kl            | 0.06688431 |
|    clip_fraction        | 0.0788     |
|    clip_range           | 0.179      |
|    entropy_loss         | -0.0716    |
|    explained_variance   | 0.753      |
|    learning_rate        | 8.62e-05   |
|    loss                 | 9.8        |
|    n_updates            | 852        |
|    policy_gradient_loss | 0.0117     |
|    value_loss           | 35.7       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 745      |
|    ep_rew_mean     | 296      |
| time/              |          |
|    fps             | 537      |
|    iterations      | 214      |
|    time_elapsed    | 26113    |
|    total_timesteps | 14024704 |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 718         |
|    ep_rew_mean          | 306         |
| time/                   |             |
|    fps                  | 537         |
|    iterations           | 215         |
|    time_elapsed         | 26236       |
|    total_timesteps      | 14090240    |
| train/                  |             |
|    approx_kl            | 0.060149133 |
|    clip_fraction        | 0.0752      |
|    clip_range           | 0.179       |
|    entropy_loss         | -0.0684     |
|    explained_variance   | 0.727       |
|    learning_rate        | 8.61e-05    |
|    loss                 | 10.9        |
|    n_updates            | 856         |
|    policy_gradient_loss | 0.0132      |
|    value_loss           | 37.9        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 722        |
|    ep_rew_mean          | 319        |
| time/                   |            |
|    fps                  | 537        |
|    iterations           | 216        |
|    time_elapsed         | 26358      |
|    total_timesteps      | 14155776   |
| train/                  |            |
|    approx_kl            | 0.06459902 |
|    clip_fraction        | 0.0822     |
|    clip_range           | 0.179      |
|    entropy_loss         | -0.0741    |
|    explained_variance   | 0.746      |
|    learning_rate        | 8.61e-05   |
|    loss                 | 11         |
|    n_updates            | 860        |
|    policy_gradient_loss | 0.0127     |
|    value_loss           | 39.6       |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 724       |
|    ep_rew_mean          | 296       |
| time/                   |           |
|    fps                  | 537       |
|    iterations           | 217       |
|    time_elapsed         | 26480     |
|    total_timesteps      | 14221312  |
| train/                  |           |
|    approx_kl            | 0.0638572 |
|    clip_fraction        | 0.0864    |
|    clip_range           | 0.179     |
|    entropy_loss         | -0.0805   |
|    explained_variance   | 0.677     |
|    learning_rate        | 8.6e-05   |
|    loss                 | 12        |
|    n_updates            | 864       |
|    policy_gradient_loss | 0.0138    |
|    value_loss           | 39.9      |
---------------------------------------
Eval num_timesteps=14249088, episode_reward=-7.96 +/- 4.31
Episode length: 7.20 +/- 1.47
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 7.2        |
|    mean_reward          | -7.96      |
| time/                   |            |
|    total_timesteps      | 14249088   |
| train/                  |            |
|    approx_kl            | 0.07218948 |
|    clip_fraction        | 0.0782     |
|    clip_range           | 0.179      |
|    entropy_loss         | -0.0696    |
|    explained_variance   | 0.702      |
|    learning_rate        | 8.59e-05   |
|    loss                 | 10.9       |
|    n_updates            | 868        |
|    policy_gradient_loss | 0.0143     |
|    value_loss           | 39.5       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 710      |
|    ep_rew_mean     | 297      |
| time/              |          |
|    fps             | 537      |
|    iterations      | 218      |
|    time_elapsed    | 26603    |
|    total_timesteps | 14286848 |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 747        |
|    ep_rew_mean          | 308        |
| time/                   |            |
|    fps                  | 536        |
|    iterations           | 219        |
|    time_elapsed         | 26728      |
|    total_timesteps      | 14352384   |
| train/                  |            |
|    approx_kl            | 0.08476557 |
|    clip_fraction        | 0.0928     |
|    clip_range           | 0.179      |
|    entropy_loss         | -0.0751    |
|    explained_variance   | 0.714      |
|    learning_rate        | 8.59e-05   |
|    loss                 | 10.7       |
|    n_updates            | 872        |
|    policy_gradient_loss | 0.0191     |
|    value_loss           | 38.4       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 818        |
|    ep_rew_mean          | 342        |
| time/                   |            |
|    fps                  | 536        |
|    iterations           | 220        |
|    time_elapsed         | 26851      |
|    total_timesteps      | 14417920   |
| train/                  |            |
|    approx_kl            | 0.07579169 |
|    clip_fraction        | 0.0973     |
|    clip_range           | 0.178      |
|    entropy_loss         | -0.0865    |
|    explained_variance   | 0.685      |
|    learning_rate        | 8.58e-05   |
|    loss                 | 12         |
|    n_updates            | 876        |
|    policy_gradient_loss | 0.0147     |
|    value_loss           | 39.2       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 745        |
|    ep_rew_mean          | 284        |
| time/                   |            |
|    fps                  | 536        |
|    iterations           | 221        |
|    time_elapsed         | 26973      |
|    total_timesteps      | 14483456   |
| train/                  |            |
|    approx_kl            | 0.06302613 |
|    clip_fraction        | 0.0731     |
|    clip_range           | 0.178      |
|    entropy_loss         | -0.0703    |
|    explained_variance   | 0.687      |
|    learning_rate        | 8.57e-05   |
|    loss                 | 10.6       |
|    n_updates            | 880        |
|    policy_gradient_loss | 0.0113     |
|    value_loss           | 37.3       |
----------------------------------------
Eval num_timesteps=14499072, episode_reward=-8.11 +/- 4.45
Episode length: 7.50 +/- 1.36
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 7.5       |
|    mean_reward          | -8.11     |
| time/                   |           |
|    total_timesteps      | 14499072  |
| train/                  |           |
|    approx_kl            | 0.0663306 |
|    clip_fraction        | 0.0744    |
|    clip_range           | 0.178     |
|    entropy_loss         | -0.0738   |
|    explained_variance   | 0.691     |
|    learning_rate        | 8.57e-05  |
|    loss                 | 11.9      |
|    n_updates            | 884       |
|    policy_gradient_loss | 0.0122    |
|    value_loss           | 38.3      |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 721      |
|    ep_rew_mean     | 303      |
| time/              |          |
|    fps             | 536      |
|    iterations      | 222      |
|    time_elapsed    | 27095    |
|    total_timesteps | 14548992 |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 827        |
|    ep_rew_mean          | 400        |
| time/                   |            |
|    fps                  | 537        |
|    iterations           | 223        |
|    time_elapsed         | 27214      |
|    total_timesteps      | 14614528   |
| train/                  |            |
|    approx_kl            | 0.06687245 |
|    clip_fraction        | 0.0806     |
|    clip_range           | 0.178      |
|    entropy_loss         | -0.0726    |
|    explained_variance   | 0.667      |
|    learning_rate        | 8.56e-05   |
|    loss                 | 9.26       |
|    n_updates            | 888        |
|    policy_gradient_loss | 0.0115     |
|    value_loss           | 37.7       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 765         |
|    ep_rew_mean          | 336         |
| time/                   |             |
|    fps                  | 537         |
|    iterations           | 224         |
|    time_elapsed         | 27330       |
|    total_timesteps      | 14680064    |
| train/                  |             |
|    approx_kl            | 0.071777046 |
|    clip_fraction        | 0.076       |
|    clip_range           | 0.178       |
|    entropy_loss         | -0.0658     |
|    explained_variance   | 0.605       |
|    learning_rate        | 8.55e-05    |
|    loss                 | 11.1        |
|    n_updates            | 892         |
|    policy_gradient_loss | 0.0134      |
|    value_loss           | 39.9        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 742        |
|    ep_rew_mean          | 385        |
| time/                   |            |
|    fps                  | 536        |
|    iterations           | 225        |
|    time_elapsed         | 27459      |
|    total_timesteps      | 14745600   |
| train/                  |            |
|    approx_kl            | 0.06653057 |
|    clip_fraction        | 0.0743     |
|    clip_range           | 0.178      |
|    entropy_loss         | -0.0657    |
|    explained_variance   | 0.653      |
|    learning_rate        | 8.55e-05   |
|    loss                 | 9.89       |
|    n_updates            | 896        |
|    policy_gradient_loss | 0.011      |
|    value_loss           | 39.5       |
----------------------------------------
Eval num_timesteps=14749056, episode_reward=-5.86 +/- 10.71
Episode length: 7.50 +/- 4.22
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 7.5       |
|    mean_reward          | -5.86     |
| time/                   |           |
|    total_timesteps      | 14749056  |
| train/                  |           |
|    approx_kl            | 0.0669688 |
|    clip_fraction        | 0.0741    |
|    clip_range           | 0.178     |
|    entropy_loss         | -0.0606   |
|    explained_variance   | 0.646     |
|    learning_rate        | 8.54e-05  |
|    loss                 | 13.5      |
|    n_updates            | 900       |
|    policy_gradient_loss | 0.0156    |
|    value_loss           | 46.4      |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 718      |
|    ep_rew_mean     | 346      |
| time/              |          |
|    fps             | 536      |
|    iterations      | 226      |
|    time_elapsed    | 27582    |
|    total_timesteps | 14811136 |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 755        |
|    ep_rew_mean          | 375        |
| time/                   |            |
|    fps                  | 536        |
|    iterations           | 227        |
|    time_elapsed         | 27705      |
|    total_timesteps      | 14876672   |
| train/                  |            |
|    approx_kl            | 0.06956572 |
|    clip_fraction        | 0.0804     |
|    clip_range           | 0.178      |
|    entropy_loss         | -0.07      |
|    explained_variance   | 0.647      |
|    learning_rate        | 8.53e-05   |
|    loss                 | 13.7       |
|    n_updates            | 904        |
|    policy_gradient_loss | 0.013      |
|    value_loss           | 41.2       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 770        |
|    ep_rew_mean          | 378        |
| time/                   |            |
|    fps                  | 536        |
|    iterations           | 228        |
|    time_elapsed         | 27827      |
|    total_timesteps      | 14942208   |
| train/                  |            |
|    approx_kl            | 0.09039267 |
|    clip_fraction        | 0.0907     |
|    clip_range           | 0.178      |
|    entropy_loss         | -0.0614    |
|    explained_variance   | 0.671      |
|    learning_rate        | 8.53e-05   |
|    loss                 | 13         |
|    n_updates            | 908        |
|    policy_gradient_loss | 0.0254     |
|    value_loss           | 44.3       |
----------------------------------------
Eval num_timesteps=14999040, episode_reward=-7.98 +/- 6.90
Episode length: 7.20 +/- 2.60
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 7.2        |
|    mean_reward          | -7.98      |
| time/                   |            |
|    total_timesteps      | 14999040   |
| train/                  |            |
|    approx_kl            | 0.11479279 |
|    clip_fraction        | 0.0838     |
|    clip_range           | 0.178      |
|    entropy_loss         | -0.071     |
|    explained_variance   | 0.705      |
|    learning_rate        | 8.52e-05   |
|    loss                 | 11.3       |
|    n_updates            | 912        |
|    policy_gradient_loss | 0.0135     |
|    value_loss           | 41.5       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 785      |
|    ep_rew_mean     | 367      |
| time/              |          |
|    fps             | 536      |
|    iterations      | 229      |
|    time_elapsed    | 27951    |
|    total_timesteps | 15007744 |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 774        |
|    ep_rew_mean          | 347        |
| time/                   |            |
|    fps                  | 536        |
|    iterations           | 230        |
|    time_elapsed         | 28073      |
|    total_timesteps      | 15073280   |
| train/                  |            |
|    approx_kl            | 0.15338698 |
|    clip_fraction        | 0.0893     |
|    clip_range           | 0.177      |
|    entropy_loss         | -0.0712    |
|    explained_variance   | 0.667      |
|    learning_rate        | 8.51e-05   |
|    loss                 | 12.1       |
|    n_updates            | 916        |
|    policy_gradient_loss | 0.0149     |
|    value_loss           | 42.7       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 727        |
|    ep_rew_mean          | 307        |
| time/                   |            |
|    fps                  | 536        |
|    iterations           | 231        |
|    time_elapsed         | 28194      |
|    total_timesteps      | 15138816   |
| train/                  |            |
|    approx_kl            | 0.19010231 |
|    clip_fraction        | 0.0985     |
|    clip_range           | 0.177      |
|    entropy_loss         | -0.0747    |
|    explained_variance   | 0.628      |
|    learning_rate        | 8.51e-05   |
|    loss                 | 13.2       |
|    n_updates            | 920        |
|    policy_gradient_loss | 0.0236     |
|    value_loss           | 43.9       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 724         |
|    ep_rew_mean          | 360         |
| time/                   |             |
|    fps                  | 536         |
|    iterations           | 232         |
|    time_elapsed         | 28313       |
|    total_timesteps      | 15204352    |
| train/                  |             |
|    approx_kl            | 0.080858625 |
|    clip_fraction        | 0.08        |
|    clip_range           | 0.177       |
|    entropy_loss         | -0.0686     |
|    explained_variance   | 0.72        |
|    learning_rate        | 8.5e-05     |
|    loss                 | 10.6        |
|    n_updates            | 924         |
|    policy_gradient_loss | 0.0174      |
|    value_loss           | 39.5        |
-----------------------------------------
Eval num_timesteps=15249024, episode_reward=-6.83 +/- 5.00
Episode length: 8.60 +/- 2.94
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 8.6        |
|    mean_reward          | -6.83      |
| time/                   |            |
|    total_timesteps      | 15249024   |
| train/                  |            |
|    approx_kl            | 0.06820433 |
|    clip_fraction        | 0.076      |
|    clip_range           | 0.177      |
|    entropy_loss         | -0.0656    |
|    explained_variance   | 0.692      |
|    learning_rate        | 8.49e-05   |
|    loss                 | 12.7       |
|    n_updates            | 928        |
|    policy_gradient_loss | 0.0124     |
|    value_loss           | 43.3       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 768      |
|    ep_rew_mean     | 420      |
| time/              |          |
|    fps             | 537      |
|    iterations      | 233      |
|    time_elapsed    | 28432    |
|    total_timesteps | 15269888 |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 746        |
|    ep_rew_mean          | 402        |
| time/                   |            |
|    fps                  | 537        |
|    iterations           | 234        |
|    time_elapsed         | 28549      |
|    total_timesteps      | 15335424   |
| train/                  |            |
|    approx_kl            | 0.06825532 |
|    clip_fraction        | 0.0763     |
|    clip_range           | 0.177      |
|    entropy_loss         | -0.0637    |
|    explained_variance   | 0.64       |
|    learning_rate        | 8.49e-05   |
|    loss                 | 12.8       |
|    n_updates            | 932        |
|    policy_gradient_loss | 0.0147     |
|    value_loss           | 43.9       |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 710       |
|    ep_rew_mean          | 284       |
| time/                   |           |
|    fps                  | 537       |
|    iterations           | 235       |
|    time_elapsed         | 28670     |
|    total_timesteps      | 15400960  |
| train/                  |           |
|    approx_kl            | 0.0999889 |
|    clip_fraction        | 0.089     |
|    clip_range           | 0.177     |
|    entropy_loss         | -0.0738   |
|    explained_variance   | 0.681     |
|    learning_rate        | 8.48e-05  |
|    loss                 | 13.9      |
|    n_updates            | 936       |
|    policy_gradient_loss | 0.015     |
|    value_loss           | 43.3      |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 740        |
|    ep_rew_mean          | 271        |
| time/                   |            |
|    fps                  | 537        |
|    iterations           | 236        |
|    time_elapsed         | 28789      |
|    total_timesteps      | 15466496   |
| train/                  |            |
|    approx_kl            | 0.06428368 |
|    clip_fraction        | 0.0698     |
|    clip_range           | 0.177      |
|    entropy_loss         | -0.0645    |
|    explained_variance   | 0.64       |
|    learning_rate        | 8.48e-05   |
|    loss                 | 8.58       |
|    n_updates            | 940        |
|    policy_gradient_loss | 0.0093     |
|    value_loss           | 36.4       |
----------------------------------------
Eval num_timesteps=15499008, episode_reward=-6.87 +/- 4.98
Episode length: 7.90 +/- 2.39
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 7.9        |
|    mean_reward          | -6.87      |
| time/                   |            |
|    total_timesteps      | 15499008   |
| train/                  |            |
|    approx_kl            | 0.07373897 |
|    clip_fraction        | 0.0744     |
|    clip_range           | 0.177      |
|    entropy_loss         | -0.0643    |
|    explained_variance   | 0.695      |
|    learning_rate        | 8.47e-05   |
|    loss                 | 9.18       |
|    n_updates            | 944        |
|    policy_gradient_loss | 0.00981    |
|    value_loss           | 33.9       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 682      |
|    ep_rew_mean     | 314      |
| time/              |          |
|    fps             | 537      |
|    iterations      | 237      |
|    time_elapsed    | 28907    |
|    total_timesteps | 15532032 |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 708         |
|    ep_rew_mean          | 341         |
| time/                   |             |
|    fps                  | 537         |
|    iterations           | 238         |
|    time_elapsed         | 29025       |
|    total_timesteps      | 15597568    |
| train/                  |             |
|    approx_kl            | 0.073484346 |
|    clip_fraction        | 0.0749      |
|    clip_range           | 0.177       |
|    entropy_loss         | -0.0619     |
|    explained_variance   | 0.638       |
|    learning_rate        | 8.46e-05    |
|    loss                 | 14.6        |
|    n_updates            | 948         |
|    policy_gradient_loss | 0.0139      |
|    value_loss           | 44.2        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 750        |
|    ep_rew_mean          | 357        |
| time/                   |            |
|    fps                  | 537        |
|    iterations           | 239        |
|    time_elapsed         | 29144      |
|    total_timesteps      | 15663104   |
| train/                  |            |
|    approx_kl            | 0.07378716 |
|    clip_fraction        | 0.0769     |
|    clip_range           | 0.177      |
|    entropy_loss         | -0.062     |
|    explained_variance   | 0.665      |
|    learning_rate        | 8.46e-05   |
|    loss                 | 13.9       |
|    n_updates            | 952        |
|    policy_gradient_loss | 0.0141     |
|    value_loss           | 44.3       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 708         |
|    ep_rew_mean          | 340         |
| time/                   |             |
|    fps                  | 537         |
|    iterations           | 240         |
|    time_elapsed         | 29269       |
|    total_timesteps      | 15728640    |
| train/                  |             |
|    approx_kl            | 0.058162477 |
|    clip_fraction        | 0.0751      |
|    clip_range           | 0.177       |
|    entropy_loss         | -0.0643     |
|    explained_variance   | 0.655       |
|    learning_rate        | 8.45e-05    |
|    loss                 | 12.4        |
|    n_updates            | 956         |
|    policy_gradient_loss | 0.0134      |
|    value_loss           | 43.4        |
-----------------------------------------
Eval num_timesteps=15748992, episode_reward=-9.23 +/- 3.21
Episode length: 6.70 +/- 1.49
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 6.7        |
|    mean_reward          | -9.23      |
| time/                   |            |
|    total_timesteps      | 15748992   |
| train/                  |            |
|    approx_kl            | 0.08203434 |
|    clip_fraction        | 0.0835     |
|    clip_range           | 0.176      |
|    entropy_loss         | -0.0683    |
|    explained_variance   | 0.669      |
|    learning_rate        | 8.44e-05   |
|    loss                 | 12.2       |
|    n_updates            | 960        |
|    policy_gradient_loss | 0.0129     |
|    value_loss           | 43.3       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 769      |
|    ep_rew_mean     | 363      |
| time/              |          |
|    fps             | 537      |
|    iterations      | 241      |
|    time_elapsed    | 29391    |
|    total_timesteps | 15794176 |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 758        |
|    ep_rew_mean          | 318        |
| time/                   |            |
|    fps                  | 537        |
|    iterations           | 242        |
|    time_elapsed         | 29510      |
|    total_timesteps      | 15859712   |
| train/                  |            |
|    approx_kl            | 0.17638448 |
|    clip_fraction        | 0.102      |
|    clip_range           | 0.176      |
|    entropy_loss         | -0.0671    |
|    explained_variance   | 0.676      |
|    learning_rate        | 8.44e-05   |
|    loss                 | 12.9       |
|    n_updates            | 964        |
|    policy_gradient_loss | 0.0237     |
|    value_loss           | 42.7       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 710        |
|    ep_rew_mean          | 306        |
| time/                   |            |
|    fps                  | 537        |
|    iterations           | 243        |
|    time_elapsed         | 29633      |
|    total_timesteps      | 15925248   |
| train/                  |            |
|    approx_kl            | 0.22401665 |
|    clip_fraction        | 0.0952     |
|    clip_range           | 0.176      |
|    entropy_loss         | -0.0701    |
|    explained_variance   | 0.736      |
|    learning_rate        | 8.43e-05   |
|    loss                 | 11.2       |
|    n_updates            | 968        |
|    policy_gradient_loss | 0.00972    |
|    value_loss           | 33.7       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 710        |
|    ep_rew_mean          | 298        |
| time/                   |            |
|    fps                  | 537        |
|    iterations           | 244        |
|    time_elapsed         | 29756      |
|    total_timesteps      | 15990784   |
| train/                  |            |
|    approx_kl            | 0.07288928 |
|    clip_fraction        | 0.0774     |
|    clip_range           | 0.176      |
|    entropy_loss         | -0.0644    |
|    explained_variance   | 0.702      |
|    learning_rate        | 8.42e-05   |
|    loss                 | 12.4       |
|    n_updates            | 972        |
|    policy_gradient_loss | 0.0123     |
|    value_loss           | 43.7       |
----------------------------------------
Eval num_timesteps=15998976, episode_reward=-8.15 +/- 6.50
Episode length: 7.30 +/- 3.16
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 7.3        |
|    mean_reward          | -8.15      |
| time/                   |            |
|    total_timesteps      | 15998976   |
| train/                  |            |
|    approx_kl            | 0.06588362 |
|    clip_fraction        | 0.0814     |
|    clip_range           | 0.176      |
|    entropy_loss         | -0.0755    |
|    explained_variance   | 0.748      |
|    learning_rate        | 8.42e-05   |
|    loss                 | 11.8       |
|    n_updates            | 976        |
|    policy_gradient_loss | 0.0133     |
|    value_loss           | 40.4       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 719      |
|    ep_rew_mean     | 290      |
| time/              |          |
|    fps             | 537      |
|    iterations      | 245      |
|    time_elapsed    | 29880    |
|    total_timesteps | 16056320 |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 773         |
|    ep_rew_mean          | 354         |
| time/                   |             |
|    fps                  | 537         |
|    iterations           | 246         |
|    time_elapsed         | 29998       |
|    total_timesteps      | 16121856    |
| train/                  |             |
|    approx_kl            | 0.063409954 |
|    clip_fraction        | 0.0815      |
|    clip_range           | 0.176       |
|    entropy_loss         | -0.0778     |
|    explained_variance   | 0.751       |
|    learning_rate        | 8.41e-05    |
|    loss                 | 15.2        |
|    n_updates            | 980         |
|    policy_gradient_loss | 0.0103      |
|    value_loss           | 43.9        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 723        |
|    ep_rew_mean          | 318        |
| time/                   |            |
|    fps                  | 537        |
|    iterations           | 247        |
|    time_elapsed         | 30120      |
|    total_timesteps      | 16187392   |
| train/                  |            |
|    approx_kl            | 0.10460843 |
|    clip_fraction        | 0.0874     |
|    clip_range           | 0.176      |
|    entropy_loss         | -0.0666    |
|    explained_variance   | 0.655      |
|    learning_rate        | 8.4e-05    |
|    loss                 | 13.9       |
|    n_updates            | 984        |
|    policy_gradient_loss | 0.0131     |
|    value_loss           | 46.3       |
----------------------------------------
Eval num_timesteps=16248960, episode_reward=-9.19 +/- 3.13
Episode length: 7.70 +/- 2.76
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 7.7       |
|    mean_reward          | -9.19     |
| time/                   |           |
|    total_timesteps      | 16248960  |
| train/                  |           |
|    approx_kl            | 0.1096973 |
|    clip_fraction        | 0.0979    |
|    clip_range           | 0.176     |
|    entropy_loss         | -0.0758   |
|    explained_variance   | 0.729     |
|    learning_rate        | 8.4e-05   |
|    loss                 | 12        |
|    n_updates            | 988       |
|    policy_gradient_loss | 0.0172    |
|    value_loss           | 42.3      |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 752      |
|    ep_rew_mean     | 361      |
| time/              |          |
|    fps             | 537      |
|    iterations      | 248      |
|    time_elapsed    | 30245    |
|    total_timesteps | 16252928 |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 699        |
|    ep_rew_mean          | 339        |
| time/                   |            |
|    fps                  | 537        |
|    iterations           | 249        |
|    time_elapsed         | 30368      |
|    total_timesteps      | 16318464   |
| train/                  |            |
|    approx_kl            | 0.07068832 |
|    clip_fraction        | 0.0752     |
|    clip_range           | 0.176      |
|    entropy_loss         | -0.0628    |
|    explained_variance   | 0.681      |
|    learning_rate        | 8.39e-05   |
|    loss                 | 12.5       |
|    n_updates            | 992        |
|    policy_gradient_loss | 0.0139     |
|    value_loss           | 42.6       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 727        |
|    ep_rew_mean          | 345        |
| time/                   |            |
|    fps                  | 537        |
|    iterations           | 250        |
|    time_elapsed         | 30491      |
|    total_timesteps      | 16384000   |
| train/                  |            |
|    approx_kl            | 0.07413606 |
|    clip_fraction        | 0.0789     |
|    clip_range           | 0.176      |
|    entropy_loss         | -0.0698    |
|    explained_variance   | 0.667      |
|    learning_rate        | 8.38e-05   |
|    loss                 | 14.1       |
|    n_updates            | 996        |
|    policy_gradient_loss | 0.0116     |
|    value_loss           | 45.3       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 744        |
|    ep_rew_mean          | 324        |
| time/                   |            |
|    fps                  | 537        |
|    iterations           | 251        |
|    time_elapsed         | 30616      |
|    total_timesteps      | 16449536   |
| train/                  |            |
|    approx_kl            | 0.08335319 |
|    clip_fraction        | 0.081      |
|    clip_range           | 0.175      |
|    entropy_loss         | -0.0665    |
|    explained_variance   | 0.705      |
|    learning_rate        | 8.38e-05   |
|    loss                 | 11.5       |
|    n_updates            | 1000       |
|    policy_gradient_loss | 0.0102     |
|    value_loss           | 38.5       |
----------------------------------------
Eval num_timesteps=16498944, episode_reward=-8.09 +/- 4.28
Episode length: 9.10 +/- 3.62
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 9.1         |
|    mean_reward          | -8.09       |
| time/                   |             |
|    total_timesteps      | 16498944    |
| train/                  |             |
|    approx_kl            | 0.084192455 |
|    clip_fraction        | 0.0743      |
|    clip_range           | 0.175       |
|    entropy_loss         | -0.06       |
|    explained_variance   | 0.677       |
|    learning_rate        | 8.37e-05    |
|    loss                 | 12          |
|    n_updates            | 1004        |
|    policy_gradient_loss | 0.012       |
|    value_loss           | 42.8        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 678      |
|    ep_rew_mean     | 340      |
| time/              |          |
|    fps             | 537      |
|    iterations      | 252      |
|    time_elapsed    | 30740    |
|    total_timesteps | 16515072 |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 733         |
|    ep_rew_mean          | 371         |
| time/                   |             |
|    fps                  | 537         |
|    iterations           | 253         |
|    time_elapsed         | 30864       |
|    total_timesteps      | 16580608    |
| train/                  |             |
|    approx_kl            | 0.071759075 |
|    clip_fraction        | 0.0737      |
|    clip_range           | 0.175       |
|    entropy_loss         | -0.0587     |
|    explained_variance   | 0.665       |
|    learning_rate        | 8.37e-05    |
|    loss                 | 16.8        |
|    n_updates            | 1008        |
|    policy_gradient_loss | 0.0152      |
|    value_loss           | 47.1        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 665        |
|    ep_rew_mean          | 345        |
| time/                   |            |
|    fps                  | 537        |
|    iterations           | 254        |
|    time_elapsed         | 30989      |
|    total_timesteps      | 16646144   |
| train/                  |            |
|    approx_kl            | 0.23809484 |
|    clip_fraction        | 0.099      |
|    clip_range           | 0.175      |
|    entropy_loss         | -0.0751    |
|    explained_variance   | 0.607      |
|    learning_rate        | 8.36e-05   |
|    loss                 | 12.8       |
|    n_updates            | 1012       |
|    policy_gradient_loss | 0.00982    |
|    value_loss           | 41.5       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 706        |
|    ep_rew_mean          | 321        |
| time/                   |            |
|    fps                  | 537        |
|    iterations           | 255        |
|    time_elapsed         | 31112      |
|    total_timesteps      | 16711680   |
| train/                  |            |
|    approx_kl            | 0.13657936 |
|    clip_fraction        | 0.0867     |
|    clip_range           | 0.175      |
|    entropy_loss         | -0.0687    |
|    explained_variance   | 0.659      |
|    learning_rate        | 8.35e-05   |
|    loss                 | 11.5       |
|    n_updates            | 1016       |
|    policy_gradient_loss | 0.0179     |
|    value_loss           | 43.3       |
----------------------------------------
Eval num_timesteps=16748928, episode_reward=-10.18 +/- 0.49
Episode length: 6.90 +/- 1.37
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 6.9        |
|    mean_reward          | -10.2      |
| time/                   |            |
|    total_timesteps      | 16748928   |
| train/                  |            |
|    approx_kl            | 0.09193152 |
|    clip_fraction        | 0.0949     |
|    clip_range           | 0.175      |
|    entropy_loss         | -0.0726    |
|    explained_variance   | 0.631      |
|    learning_rate        | 8.35e-05   |
|    loss                 | 12.1       |
|    n_updates            | 1020       |
|    policy_gradient_loss | 0.0182     |
|    value_loss           | 37.6       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 724      |
|    ep_rew_mean     | 309      |
| time/              |          |
|    fps             | 537      |
|    iterations      | 256      |
|    time_elapsed    | 31236    |
|    total_timesteps | 16777216 |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 727         |
|    ep_rew_mean          | 318         |
| time/                   |             |
|    fps                  | 537         |
|    iterations           | 257         |
|    time_elapsed         | 31359       |
|    total_timesteps      | 16842752    |
| train/                  |             |
|    approx_kl            | 0.061436318 |
|    clip_fraction        | 0.0732      |
|    clip_range           | 0.175       |
|    entropy_loss         | -0.0665     |
|    explained_variance   | 0.676       |
|    learning_rate        | 8.34e-05    |
|    loss                 | 11.8        |
|    n_updates            | 1024        |
|    policy_gradient_loss | 0.0108      |
|    value_loss           | 38          |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 727        |
|    ep_rew_mean          | 355        |
| time/                   |            |
|    fps                  | 537        |
|    iterations           | 258        |
|    time_elapsed         | 31483      |
|    total_timesteps      | 16908288   |
| train/                  |            |
|    approx_kl            | 0.06477015 |
|    clip_fraction        | 0.0753     |
|    clip_range           | 0.175      |
|    entropy_loss         | -0.063     |
|    explained_variance   | 0.721      |
|    learning_rate        | 8.33e-05   |
|    loss                 | 11.2       |
|    n_updates            | 1028       |
|    policy_gradient_loss | 0.0133     |
|    value_loss           | 38.9       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 733         |
|    ep_rew_mean          | 336         |
| time/                   |             |
|    fps                  | 536         |
|    iterations           | 259         |
|    time_elapsed         | 31612       |
|    total_timesteps      | 16973824    |
| train/                  |             |
|    approx_kl            | 0.083455384 |
|    clip_fraction        | 0.0774      |
|    clip_range           | 0.175       |
|    entropy_loss         | -0.0582     |
|    explained_variance   | 0.659       |
|    learning_rate        | 8.33e-05    |
|    loss                 | 12.7        |
|    n_updates            | 1032        |
|    policy_gradient_loss | 0.0134      |
|    value_loss           | 42.6        |
-----------------------------------------
Eval num_timesteps=16998912, episode_reward=-4.46 +/- 9.03
Episode length: 8.10 +/- 3.21
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 8.1         |
|    mean_reward          | -4.46       |
| time/                   |             |
|    total_timesteps      | 16998912    |
| train/                  |             |
|    approx_kl            | 0.073801234 |
|    clip_fraction        | 0.0721      |
|    clip_range           | 0.175       |
|    entropy_loss         | -0.061      |
|    explained_variance   | 0.721       |
|    learning_rate        | 8.32e-05    |
|    loss                 | 10.7        |
|    n_updates            | 1036        |
|    policy_gradient_loss | 0.011       |
|    value_loss           | 42.2        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 722      |
|    ep_rew_mean     | 327      |
| time/              |          |
|    fps             | 536      |
|    iterations      | 260      |
|    time_elapsed    | 31735    |
|    total_timesteps | 17039360 |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 762        |
|    ep_rew_mean          | 331        |
| time/                   |            |
|    fps                  | 536        |
|    iterations           | 261        |
|    time_elapsed         | 31857      |
|    total_timesteps      | 17104896   |
| train/                  |            |
|    approx_kl            | 0.08757362 |
|    clip_fraction        | 0.0749     |
|    clip_range           | 0.174      |
|    entropy_loss         | -0.0558    |
|    explained_variance   | 0.735      |
|    learning_rate        | 8.31e-05   |
|    loss                 | 13.2       |
|    n_updates            | 1040       |
|    policy_gradient_loss | 0.0179     |
|    value_loss           | 39.7       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 750         |
|    ep_rew_mean          | 320         |
| time/                   |             |
|    fps                  | 536         |
|    iterations           | 262         |
|    time_elapsed         | 31977       |
|    total_timesteps      | 17170432    |
| train/                  |             |
|    approx_kl            | 0.055430874 |
|    clip_fraction        | 0.0647      |
|    clip_range           | 0.174       |
|    entropy_loss         | -0.0563     |
|    explained_variance   | 0.688       |
|    learning_rate        | 8.31e-05    |
|    loss                 | 12.7        |
|    n_updates            | 1044        |
|    policy_gradient_loss | 0.011       |
|    value_loss           | 38.4        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 742        |
|    ep_rew_mean          | 313        |
| time/                   |            |
|    fps                  | 536        |
|    iterations           | 263        |
|    time_elapsed         | 32101      |
|    total_timesteps      | 17235968   |
| train/                  |            |
|    approx_kl            | 0.07210869 |
|    clip_fraction        | 0.0677     |
|    clip_range           | 0.174      |
|    entropy_loss         | -0.0528    |
|    explained_variance   | 0.625      |
|    learning_rate        | 8.3e-05    |
|    loss                 | 12         |
|    n_updates            | 1048       |
|    policy_gradient_loss | 0.0125     |
|    value_loss           | 41.6       |
----------------------------------------
Eval num_timesteps=17248896, episode_reward=-6.86 +/- 5.09
Episode length: 7.20 +/- 2.09
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 7.2         |
|    mean_reward          | -6.86       |
| time/                   |             |
|    total_timesteps      | 17248896    |
| train/                  |             |
|    approx_kl            | 0.053929396 |
|    clip_fraction        | 0.0638      |
|    clip_range           | 0.174       |
|    entropy_loss         | -0.0551     |
|    explained_variance   | 0.656       |
|    learning_rate        | 8.29e-05    |
|    loss                 | 12.9        |
|    n_updates            | 1052        |
|    policy_gradient_loss | 0.0108      |
|    value_loss           | 40.5        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 762      |
|    ep_rew_mean     | 375      |
| time/              |          |
|    fps             | 536      |
|    iterations      | 264      |
|    time_elapsed    | 32226    |
|    total_timesteps | 17301504 |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 687        |
|    ep_rew_mean          | 301        |
| time/                   |            |
|    fps                  | 536        |
|    iterations           | 265        |
|    time_elapsed         | 32349      |
|    total_timesteps      | 17367040   |
| train/                  |            |
|    approx_kl            | 0.06435393 |
|    clip_fraction        | 0.069      |
|    clip_range           | 0.174      |
|    entropy_loss         | -0.0586    |
|    explained_variance   | 0.659      |
|    learning_rate        | 8.29e-05   |
|    loss                 | 12.2       |
|    n_updates            | 1056       |
|    policy_gradient_loss | 0.012      |
|    value_loss           | 42.7       |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 748       |
|    ep_rew_mean          | 373       |
| time/                   |           |
|    fps                  | 536       |
|    iterations           | 266       |
|    time_elapsed         | 32473     |
|    total_timesteps      | 17432576  |
| train/                  |           |
|    approx_kl            | 0.0656925 |
|    clip_fraction        | 0.0684    |
|    clip_range           | 0.174     |
|    entropy_loss         | -0.0582   |
|    explained_variance   | 0.673     |
|    learning_rate        | 8.28e-05  |
|    loss                 | 15.6      |
|    n_updates            | 1060      |
|    policy_gradient_loss | 0.0143    |
|    value_loss           | 45.5      |
---------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 818         |
|    ep_rew_mean          | 408         |
| time/                   |             |
|    fps                  | 536         |
|    iterations           | 267         |
|    time_elapsed         | 32596       |
|    total_timesteps      | 17498112    |
| train/                  |             |
|    approx_kl            | 0.082501285 |
|    clip_fraction        | 0.075       |
|    clip_range           | 0.174       |
|    entropy_loss         | -0.0581     |
|    explained_variance   | 0.613       |
|    learning_rate        | 8.27e-05    |
|    loss                 | 13.5        |
|    n_updates            | 1064        |
|    policy_gradient_loss | 0.0242      |
|    value_loss           | 42.5        |
-----------------------------------------
Eval num_timesteps=17498880, episode_reward=-8.23 +/- 4.30
Episode length: 8.90 +/- 2.95
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 8.9       |
|    mean_reward          | -8.23     |
| time/                   |           |
|    total_timesteps      | 17498880  |
| train/                  |           |
|    approx_kl            | 0.0746768 |
|    clip_fraction        | 0.0684    |
|    clip_range           | 0.174     |
|    entropy_loss         | -0.0566   |
|    explained_variance   | 0.634     |
|    learning_rate        | 8.27e-05  |
|    loss                 | 13.6      |
|    n_updates            | 1068      |
|    policy_gradient_loss | 0.0104    |
|    value_loss           | 42.7      |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 748      |
|    ep_rew_mean     | 377      |
| time/              |          |
|    fps             | 536      |
|    iterations      | 268      |
|    time_elapsed    | 32723    |
|    total_timesteps | 17563648 |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 724        |
|    ep_rew_mean          | 379        |
| time/                   |            |
|    fps                  | 536        |
|    iterations           | 269        |
|    time_elapsed         | 32846      |
|    total_timesteps      | 17629184   |
| train/                  |            |
|    approx_kl            | 0.06537496 |
|    clip_fraction        | 0.0638     |
|    clip_range           | 0.174      |
|    entropy_loss         | -0.0518    |
|    explained_variance   | 0.611      |
|    learning_rate        | 8.26e-05   |
|    loss                 | 13.9       |
|    n_updates            | 1072       |
|    policy_gradient_loss | 0.014      |
|    value_loss           | 43.3       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 717        |
|    ep_rew_mean          | 370        |
| time/                   |            |
|    fps                  | 536        |
|    iterations           | 270        |
|    time_elapsed         | 32968      |
|    total_timesteps      | 17694720   |
| train/                  |            |
|    approx_kl            | 0.06979285 |
|    clip_fraction        | 0.0722     |
|    clip_range           | 0.174      |
|    entropy_loss         | -0.0563    |
|    explained_variance   | 0.607      |
|    learning_rate        | 8.25e-05   |
|    loss                 | 12         |
|    n_updates            | 1076       |
|    policy_gradient_loss | 0.0147     |
|    value_loss           | 44.1       |
----------------------------------------
Eval num_timesteps=17748864, episode_reward=-10.38 +/- 0.35
Episode length: 5.80 +/- 0.87
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 5.8        |
|    mean_reward          | -10.4      |
| time/                   |            |
|    total_timesteps      | 17748864   |
| train/                  |            |
|    approx_kl            | 0.06429459 |
|    clip_fraction        | 0.0609     |
|    clip_range           | 0.173      |
|    entropy_loss         | -0.0502    |
|    explained_variance   | 0.604      |
|    learning_rate        | 8.25e-05   |
|    loss                 | 12.5       |
|    n_updates            | 1080       |
|    policy_gradient_loss | 0.0105     |
|    value_loss           | 45.9       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 797      |
|    ep_rew_mean     | 399      |
| time/              |          |
|    fps             | 536      |
|    iterations      | 271      |
|    time_elapsed    | 33089    |
|    total_timesteps | 17760256 |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 813         |
|    ep_rew_mean          | 377         |
| time/                   |             |
|    fps                  | 536         |
|    iterations           | 272         |
|    time_elapsed         | 33206       |
|    total_timesteps      | 17825792    |
| train/                  |             |
|    approx_kl            | 0.115357086 |
|    clip_fraction        | 0.0707      |
|    clip_range           | 0.173       |
|    entropy_loss         | -0.0494     |
|    explained_variance   | 0.62        |
|    learning_rate        | 8.24e-05    |
|    loss                 | 14.1        |
|    n_updates            | 1084        |
|    policy_gradient_loss | 0.0149      |
|    value_loss           | 45.3        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 767        |
|    ep_rew_mean          | 345        |
| time/                   |            |
|    fps                  | 536        |
|    iterations           | 273        |
|    time_elapsed         | 33328      |
|    total_timesteps      | 17891328   |
| train/                  |            |
|    approx_kl            | 0.06560223 |
|    clip_fraction        | 0.0705     |
|    clip_range           | 0.173      |
|    entropy_loss         | -0.0574    |
|    explained_variance   | 0.665      |
|    learning_rate        | 8.24e-05   |
|    loss                 | 13.7       |
|    n_updates            | 1088       |
|    policy_gradient_loss | 0.0116     |
|    value_loss           | 38.3       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 829         |
|    ep_rew_mean          | 428         |
| time/                   |             |
|    fps                  | 536         |
|    iterations           | 274         |
|    time_elapsed         | 33454       |
|    total_timesteps      | 17956864    |
| train/                  |             |
|    approx_kl            | 0.071533635 |
|    clip_fraction        | 0.0687      |
|    clip_range           | 0.173       |
|    entropy_loss         | -0.0558     |
|    explained_variance   | 0.696       |
|    learning_rate        | 8.23e-05    |
|    loss                 | 12.2        |
|    n_updates            | 1092        |
|    policy_gradient_loss | 0.0122      |
|    value_loss           | 42.1        |
-----------------------------------------
Eval num_timesteps=17998848, episode_reward=-9.00 +/- 3.48
Episode length: 7.80 +/- 1.94
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 7.8        |
|    mean_reward          | -9         |
| time/                   |            |
|    total_timesteps      | 17998848   |
| train/                  |            |
|    approx_kl            | 0.07264625 |
|    clip_fraction        | 0.0661     |
|    clip_range           | 0.173      |
|    entropy_loss         | -0.0552    |
|    explained_variance   | 0.618      |
|    learning_rate        | 8.22e-05   |
|    loss                 | 12.2       |
|    n_updates            | 1096       |
|    policy_gradient_loss | 0.0136     |
|    value_loss           | 45.7       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 700      |
|    ep_rew_mean     | 325      |
| time/              |          |
|    fps             | 536      |
|    iterations      | 275      |
|    time_elapsed    | 33575    |
|    total_timesteps | 18022400 |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 799       |
|    ep_rew_mean          | 382       |
| time/                   |           |
|    fps                  | 536       |
|    iterations           | 276       |
|    time_elapsed         | 33699     |
|    total_timesteps      | 18087936  |
| train/                  |           |
|    approx_kl            | 0.0861425 |
|    clip_fraction        | 0.0739    |
|    clip_range           | 0.173     |
|    entropy_loss         | -0.0617   |
|    explained_variance   | 0.681     |
|    learning_rate        | 8.22e-05  |
|    loss                 | 13.6      |
|    n_updates            | 1100      |
|    policy_gradient_loss | 0.0123    |
|    value_loss           | 42.9      |
---------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 774         |
|    ep_rew_mean          | 329         |
| time/                   |             |
|    fps                  | 536         |
|    iterations           | 277         |
|    time_elapsed         | 33819       |
|    total_timesteps      | 18153472    |
| train/                  |             |
|    approx_kl            | 0.079474285 |
|    clip_fraction        | 0.0751      |
|    clip_range           | 0.173       |
|    entropy_loss         | -0.0619     |
|    explained_variance   | 0.626       |
|    learning_rate        | 8.21e-05    |
|    loss                 | 13.4        |
|    n_updates            | 1104        |
|    policy_gradient_loss | 0.01        |
|    value_loss           | 43.2        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 725        |
|    ep_rew_mean          | 316        |
| time/                   |            |
|    fps                  | 536        |
|    iterations           | 278        |
|    time_elapsed         | 33947      |
|    total_timesteps      | 18219008   |
| train/                  |            |
|    approx_kl            | 0.08271598 |
|    clip_fraction        | 0.0803     |
|    clip_range           | 0.173      |
|    entropy_loss         | -0.0622    |
|    explained_variance   | 0.716      |
|    learning_rate        | 8.2e-05    |
|    loss                 | 10.3       |
|    n_updates            | 1108       |
|    policy_gradient_loss | 0.0175     |
|    value_loss           | 38.8       |
----------------------------------------
Eval num_timesteps=18248832, episode_reward=-9.29 +/- 3.16
Episode length: 7.10 +/- 2.17
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 7.1        |
|    mean_reward          | -9.29      |
| time/                   |            |
|    total_timesteps      | 18248832   |
| train/                  |            |
|    approx_kl            | 0.12940983 |
|    clip_fraction        | 0.0885     |
|    clip_range           | 0.173      |
|    entropy_loss         | -0.0719    |
|    explained_variance   | 0.705      |
|    learning_rate        | 8.2e-05    |
|    loss                 | 11.2       |
|    n_updates            | 1112       |
|    policy_gradient_loss | 0.0124     |
|    value_loss           | 39.9       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 778      |
|    ep_rew_mean     | 348      |
| time/              |          |
|    fps             | 536      |
|    iterations      | 279      |
|    time_elapsed    | 34063    |
|    total_timesteps | 18284544 |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 857        |
|    ep_rew_mean          | 390        |
| time/                   |            |
|    fps                  | 536        |
|    iterations           | 280        |
|    time_elapsed         | 34175      |
|    total_timesteps      | 18350080   |
| train/                  |            |
|    approx_kl            | 0.07295114 |
|    clip_fraction        | 0.0787     |
|    clip_range           | 0.173      |
|    entropy_loss         | -0.0645    |
|    explained_variance   | 0.663      |
|    learning_rate        | 8.19e-05   |
|    loss                 | 12.3       |
|    n_updates            | 1116       |
|    policy_gradient_loss | 0.0145     |
|    value_loss           | 44.9       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 807        |
|    ep_rew_mean          | 353        |
| time/                   |            |
|    fps                  | 536        |
|    iterations           | 281        |
|    time_elapsed         | 34303      |
|    total_timesteps      | 18415616   |
| train/                  |            |
|    approx_kl            | 0.12429825 |
|    clip_fraction        | 0.0847     |
|    clip_range           | 0.172      |
|    entropy_loss         | -0.0547    |
|    explained_variance   | 0.725      |
|    learning_rate        | 8.18e-05   |
|    loss                 | 9.64       |
|    n_updates            | 1120       |
|    policy_gradient_loss | 0.0209     |
|    value_loss           | 39         |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 821         |
|    ep_rew_mean          | 359         |
| time/                   |             |
|    fps                  | 536         |
|    iterations           | 282         |
|    time_elapsed         | 34429       |
|    total_timesteps      | 18481152    |
| train/                  |             |
|    approx_kl            | 0.072214276 |
|    clip_fraction        | 0.0669      |
|    clip_range           | 0.172       |
|    entropy_loss         | -0.0566     |
|    explained_variance   | 0.715       |
|    learning_rate        | 8.18e-05    |
|    loss                 | 11.7        |
|    n_updates            | 1124        |
|    policy_gradient_loss | 0.0125      |
|    value_loss           | 40.4        |
-----------------------------------------
Eval num_timesteps=18498816, episode_reward=-6.97 +/- 4.89
Episode length: 8.50 +/- 6.39
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 8.5        |
|    mean_reward          | -6.97      |
| time/                   |            |
|    total_timesteps      | 18498816   |
| train/                  |            |
|    approx_kl            | 0.07634851 |
|    clip_fraction        | 0.0733     |
|    clip_range           | 0.172      |
|    entropy_loss         | -0.062     |
|    explained_variance   | 0.661      |
|    learning_rate        | 8.17e-05   |
|    loss                 | 9.93       |
|    n_updates            | 1128       |
|    policy_gradient_loss | 0.014      |
|    value_loss           | 39.7       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 792      |
|    ep_rew_mean     | 308      |
| time/              |          |
|    fps             | 536      |
|    iterations      | 283      |
|    time_elapsed    | 34557    |
|    total_timesteps | 18546688 |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 775        |
|    ep_rew_mean          | 338        |
| time/                   |            |
|    fps                  | 536        |
|    iterations           | 284        |
|    time_elapsed         | 34682      |
|    total_timesteps      | 18612224   |
| train/                  |            |
|    approx_kl            | 0.06577608 |
|    clip_fraction        | 0.0651     |
|    clip_range           | 0.172      |
|    entropy_loss         | -0.053     |
|    explained_variance   | 0.637      |
|    learning_rate        | 8.16e-05   |
|    loss                 | 12.2       |
|    n_updates            | 1132       |
|    policy_gradient_loss | 0.0125     |
|    value_loss           | 41.2       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 797        |
|    ep_rew_mean          | 361        |
| time/                   |            |
|    fps                  | 536        |
|    iterations           | 285        |
|    time_elapsed         | 34800      |
|    total_timesteps      | 18677760   |
| train/                  |            |
|    approx_kl            | 0.07661636 |
|    clip_fraction        | 0.0705     |
|    clip_range           | 0.172      |
|    entropy_loss         | -0.0527    |
|    explained_variance   | 0.663      |
|    learning_rate        | 8.16e-05   |
|    loss                 | 14.6       |
|    n_updates            | 1136       |
|    policy_gradient_loss | 0.0143     |
|    value_loss           | 43.4       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 762        |
|    ep_rew_mean          | 263        |
| time/                   |            |
|    fps                  | 536        |
|    iterations           | 286        |
|    time_elapsed         | 34923      |
|    total_timesteps      | 18743296   |
| train/                  |            |
|    approx_kl            | 0.15892038 |
|    clip_fraction        | 0.0824     |
|    clip_range           | 0.172      |
|    entropy_loss         | -0.0625    |
|    explained_variance   | 0.671      |
|    learning_rate        | 8.15e-05   |
|    loss                 | 10.6       |
|    n_updates            | 1140       |
|    policy_gradient_loss | 0.0244     |
|    value_loss           | 38.4       |
----------------------------------------
Eval num_timesteps=18748800, episode_reward=-8.86 +/- 3.37
Episode length: 6.30 +/- 1.42
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 6.3        |
|    mean_reward          | -8.86      |
| time/                   |            |
|    total_timesteps      | 18748800   |
| train/                  |            |
|    approx_kl            | 0.05849557 |
|    clip_fraction        | 0.0651     |
|    clip_range           | 0.172      |
|    entropy_loss         | -0.0554    |
|    explained_variance   | 0.704      |
|    learning_rate        | 8.14e-05   |
|    loss                 | 7.53       |
|    n_updates            | 1144       |
|    policy_gradient_loss | 0.012      |
|    value_loss           | 33.9       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 784      |
|    ep_rew_mean     | 302      |
| time/              |          |
|    fps             | 536      |
|    iterations      | 287      |
|    time_elapsed    | 35045    |
|    total_timesteps | 18808832 |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 810        |
|    ep_rew_mean          | 346        |
| time/                   |            |
|    fps                  | 536        |
|    iterations           | 288        |
|    time_elapsed         | 35168      |
|    total_timesteps      | 18874368   |
| train/                  |            |
|    approx_kl            | 0.05622159 |
|    clip_fraction        | 0.0602     |
|    clip_range           | 0.172      |
|    entropy_loss         | -0.0497    |
|    explained_variance   | 0.707      |
|    learning_rate        | 8.14e-05   |
|    loss                 | 11         |
|    n_updates            | 1148       |
|    policy_gradient_loss | 0.0118     |
|    value_loss           | 34.2       |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 773       |
|    ep_rew_mean          | 285       |
| time/                   |           |
|    fps                  | 536       |
|    iterations           | 289       |
|    time_elapsed         | 35288     |
|    total_timesteps      | 18939904  |
| train/                  |           |
|    approx_kl            | 0.0881574 |
|    clip_fraction        | 0.0695    |
|    clip_range           | 0.172     |
|    entropy_loss         | -0.0497   |
|    explained_variance   | 0.605     |
|    learning_rate        | 8.13e-05  |
|    loss                 | 11.7      |
|    n_updates            | 1152      |
|    policy_gradient_loss | 0.013     |
|    value_loss           | 36.2      |
---------------------------------------
Eval num_timesteps=18998784, episode_reward=-8.87 +/- 3.39
Episode length: 8.20 +/- 3.79
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 8.2        |
|    mean_reward          | -8.87      |
| time/                   |            |
|    total_timesteps      | 18998784   |
| train/                  |            |
|    approx_kl            | 0.07680117 |
|    clip_fraction        | 0.067      |
|    clip_range           | 0.172      |
|    entropy_loss         | -0.058     |
|    explained_variance   | 0.708      |
|    learning_rate        | 8.12e-05   |
|    loss                 | 8.75       |
|    n_updates            | 1156       |
|    policy_gradient_loss | 0.0082     |
|    value_loss           | 33.5       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 843      |
|    ep_rew_mean     | 340      |
| time/              |          |
|    fps             | 536      |
|    iterations      | 290      |
|    time_elapsed    | 35412    |
|    total_timesteps | 19005440 |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 779         |
|    ep_rew_mean          | 322         |
| time/                   |             |
|    fps                  | 536         |
|    iterations           | 291         |
|    time_elapsed         | 35534       |
|    total_timesteps      | 19070976    |
| train/                  |             |
|    approx_kl            | 0.066744335 |
|    clip_fraction        | 0.0639      |
|    clip_range           | 0.171       |
|    entropy_loss         | -0.0537     |
|    explained_variance   | 0.671       |
|    learning_rate        | 8.12e-05    |
|    loss                 | 10.4        |
|    n_updates            | 1160        |
|    policy_gradient_loss | 0.0109      |
|    value_loss           | 41.5        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 811        |
|    ep_rew_mean          | 311        |
| time/                   |            |
|    fps                  | 536        |
|    iterations           | 292        |
|    time_elapsed         | 35658      |
|    total_timesteps      | 19136512   |
| train/                  |            |
|    approx_kl            | 0.05898119 |
|    clip_fraction        | 0.0662     |
|    clip_range           | 0.171      |
|    entropy_loss         | -0.0563    |
|    explained_variance   | 0.692      |
|    learning_rate        | 8.11e-05   |
|    loss                 | 11.5       |
|    n_updates            | 1164       |
|    policy_gradient_loss | 0.0141     |
|    value_loss           | 39.1       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 828        |
|    ep_rew_mean          | 312        |
| time/                   |            |
|    fps                  | 536        |
|    iterations           | 293        |
|    time_elapsed         | 35780      |
|    total_timesteps      | 19202048   |
| train/                  |            |
|    approx_kl            | 0.05626022 |
|    clip_fraction        | 0.0638     |
|    clip_range           | 0.171      |
|    entropy_loss         | -0.0552    |
|    explained_variance   | 0.706      |
|    learning_rate        | 8.11e-05   |
|    loss                 | 11.8       |
|    n_updates            | 1168       |
|    policy_gradient_loss | 0.012      |
|    value_loss           | 36.9       |
----------------------------------------
Eval num_timesteps=19248768, episode_reward=-9.12 +/- 3.11
Episode length: 6.80 +/- 1.40
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 6.8        |
|    mean_reward          | -9.12      |
| time/                   |            |
|    total_timesteps      | 19248768   |
| train/                  |            |
|    approx_kl            | 0.06275884 |
|    clip_fraction        | 0.0672     |
|    clip_range           | 0.171      |
|    entropy_loss         | -0.0562    |
|    explained_variance   | 0.671      |
|    learning_rate        | 8.1e-05    |
|    loss                 | 12         |
|    n_updates            | 1172       |
|    policy_gradient_loss | 0.0107     |
|    value_loss           | 37.8       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 826      |
|    ep_rew_mean     | 299      |
| time/              |          |
|    fps             | 536      |
|    iterations      | 294      |
|    time_elapsed    | 35903    |
|    total_timesteps | 19267584 |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 782         |
|    ep_rew_mean          | 343         |
| time/                   |             |
|    fps                  | 536         |
|    iterations           | 295         |
|    time_elapsed         | 36022       |
|    total_timesteps      | 19333120    |
| train/                  |             |
|    approx_kl            | 0.087343484 |
|    clip_fraction        | 0.0748      |
|    clip_range           | 0.171       |
|    entropy_loss         | -0.0614     |
|    explained_variance   | 0.67        |
|    learning_rate        | 8.09e-05    |
|    loss                 | 10.8        |
|    n_updates            | 1176        |
|    policy_gradient_loss | 0.0103      |
|    value_loss           | 36.9        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 859         |
|    ep_rew_mean          | 365         |
| time/                   |             |
|    fps                  | 536         |
|    iterations           | 296         |
|    time_elapsed         | 36145       |
|    total_timesteps      | 19398656    |
| train/                  |             |
|    approx_kl            | 0.097196326 |
|    clip_fraction        | 0.0895      |
|    clip_range           | 0.171       |
|    entropy_loss         | -0.0723     |
|    explained_variance   | 0.708       |
|    learning_rate        | 8.09e-05    |
|    loss                 | 13.2        |
|    n_updates            | 1180        |
|    policy_gradient_loss | 0.0156      |
|    value_loss           | 39.4        |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 828       |
|    ep_rew_mean          | 341       |
| time/                   |           |
|    fps                  | 536       |
|    iterations           | 297       |
|    time_elapsed         | 36268     |
|    total_timesteps      | 19464192  |
| train/                  |           |
|    approx_kl            | 0.0572113 |
|    clip_fraction        | 0.067     |
|    clip_range           | 0.171     |
|    entropy_loss         | -0.0559   |
|    explained_variance   | 0.702     |
|    learning_rate        | 8.08e-05  |
|    loss                 | 9.27      |
|    n_updates            | 1184      |
|    policy_gradient_loss | 0.0115    |
|    value_loss           | 35.8      |
---------------------------------------
Eval num_timesteps=19498752, episode_reward=-9.23 +/- 3.43
Episode length: 6.70 +/- 1.90
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 6.7        |
|    mean_reward          | -9.23      |
| time/                   |            |
|    total_timesteps      | 19498752   |
| train/                  |            |
|    approx_kl            | 0.08581503 |
|    clip_fraction        | 0.0874     |
|    clip_range           | 0.171      |
|    entropy_loss         | -0.0628    |
|    explained_variance   | 0.722      |
|    learning_rate        | 8.07e-05   |
|    loss                 | 10.7       |
|    n_updates            | 1188       |
|    policy_gradient_loss | 0.0218     |
|    value_loss           | 34.9       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 778      |
|    ep_rew_mean     | 269      |
| time/              |          |
|    fps             | 536      |
|    iterations      | 298      |
|    time_elapsed    | 36390    |
|    total_timesteps | 19529728 |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 797        |
|    ep_rew_mean          | 303        |
| time/                   |            |
|    fps                  | 536        |
|    iterations           | 299        |
|    time_elapsed         | 36512      |
|    total_timesteps      | 19595264   |
| train/                  |            |
|    approx_kl            | 0.05867583 |
|    clip_fraction        | 0.0703     |
|    clip_range           | 0.171      |
|    entropy_loss         | -0.0649    |
|    explained_variance   | 0.744      |
|    learning_rate        | 8.07e-05   |
|    loss                 | 11.2       |
|    n_updates            | 1192       |
|    policy_gradient_loss | 0.0129     |
|    value_loss           | 34.8       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 803        |
|    ep_rew_mean          | 309        |
| time/                   |            |
|    fps                  | 536        |
|    iterations           | 300        |
|    time_elapsed         | 36638      |
|    total_timesteps      | 19660800   |
| train/                  |            |
|    approx_kl            | 0.06330271 |
|    clip_fraction        | 0.0762     |
|    clip_range           | 0.171      |
|    entropy_loss         | -0.0654    |
|    explained_variance   | 0.77       |
|    learning_rate        | 8.06e-05   |
|    loss                 | 10         |
|    n_updates            | 1196       |
|    policy_gradient_loss | 0.00938    |
|    value_loss           | 36.7       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 785        |
|    ep_rew_mean          | 320        |
| time/                   |            |
|    fps                  | 536        |
|    iterations           | 301        |
|    time_elapsed         | 36760      |
|    total_timesteps      | 19726336   |
| train/                  |            |
|    approx_kl            | 0.06249761 |
|    clip_fraction        | 0.0759     |
|    clip_range           | 0.171      |
|    entropy_loss         | -0.0653    |
|    explained_variance   | 0.735      |
|    learning_rate        | 8.05e-05   |
|    loss                 | 11.9       |
|    n_updates            | 1200       |
|    policy_gradient_loss | 0.0101     |
|    value_loss           | 36.5       |
----------------------------------------
Eval num_timesteps=19748736, episode_reward=-9.30 +/- 3.21
Episode length: 7.30 +/- 2.69
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 7.3        |
|    mean_reward          | -9.3       |
| time/                   |            |
|    total_timesteps      | 19748736   |
| train/                  |            |
|    approx_kl            | 0.07212714 |
|    clip_fraction        | 0.0761     |
|    clip_range           | 0.17       |
|    entropy_loss         | -0.0621    |
|    explained_variance   | 0.715      |
|    learning_rate        | 8.05e-05   |
|    loss                 | 14.1       |
|    n_updates            | 1204       |
|    policy_gradient_loss | 0.0122     |
|    value_loss           | 38.8       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 758      |
|    ep_rew_mean     | 324      |
| time/              |          |
|    fps             | 536      |
|    iterations      | 302      |
|    time_elapsed    | 36884    |
|    total_timesteps | 19791872 |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 762         |
|    ep_rew_mean          | 286         |
| time/                   |             |
|    fps                  | 536         |
|    iterations           | 303         |
|    time_elapsed         | 37007       |
|    total_timesteps      | 19857408    |
| train/                  |             |
|    approx_kl            | 0.062187906 |
|    clip_fraction        | 0.0758      |
|    clip_range           | 0.17        |
|    entropy_loss         | -0.0649     |
|    explained_variance   | 0.748       |
|    learning_rate        | 8.04e-05    |
|    loss                 | 9.74        |
|    n_updates            | 1208        |
|    policy_gradient_loss | 0.0137      |
|    value_loss           | 36.9        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 717         |
|    ep_rew_mean          | 276         |
| time/                   |             |
|    fps                  | 536         |
|    iterations           | 304         |
|    time_elapsed         | 37129       |
|    total_timesteps      | 19922944    |
| train/                  |             |
|    approx_kl            | 0.059239008 |
|    clip_fraction        | 0.08        |
|    clip_range           | 0.17        |
|    entropy_loss         | -0.0725     |
|    explained_variance   | 0.737       |
|    learning_rate        | 8.03e-05    |
|    loss                 | 10.5        |
|    n_updates            | 1212        |
|    policy_gradient_loss | 0.013       |
|    value_loss           | 37.2        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 738        |
|    ep_rew_mean          | 274        |
| time/                   |            |
|    fps                  | 536        |
|    iterations           | 305        |
|    time_elapsed         | 37251      |
|    total_timesteps      | 19988480   |
| train/                  |            |
|    approx_kl            | 0.06691261 |
|    clip_fraction        | 0.0807     |
|    clip_range           | 0.17       |
|    entropy_loss         | -0.0728    |
|    explained_variance   | 0.721      |
|    learning_rate        | 8.03e-05   |
|    loss                 | 11         |
|    n_updates            | 1216       |
|    policy_gradient_loss | 0.0133     |
|    value_loss           | 38.2       |
----------------------------------------
Eval num_timesteps=19998720, episode_reward=-7.72 +/- 4.38
Episode length: 7.30 +/- 1.90
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 7.3         |
|    mean_reward          | -7.72       |
| time/                   |             |
|    total_timesteps      | 19998720    |
| train/                  |             |
|    approx_kl            | 0.056124996 |
|    clip_fraction        | 0.0697      |
|    clip_range           | 0.17        |
|    entropy_loss         | -0.0626     |
|    explained_variance   | 0.748       |
|    learning_rate        | 8.02e-05    |
|    loss                 | 11.4        |
|    n_updates            | 1220        |
|    policy_gradient_loss | 0.0109      |
|    value_loss           | 38.3        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 779      |
|    ep_rew_mean     | 298      |
| time/              |          |
|    fps             | 536      |
|    iterations      | 306      |
|    time_elapsed    | 37374    |
|    total_timesteps | 20054016 |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 730       |
|    ep_rew_mean          | 234       |
| time/                   |           |
|    fps                  | 536       |
|    iterations           | 307       |
|    time_elapsed         | 37495     |
|    total_timesteps      | 20119552  |
| train/                  |           |
|    approx_kl            | 0.1024362 |
|    clip_fraction        | 0.0848    |
|    clip_range           | 0.17      |
|    entropy_loss         | -0.0677   |
|    explained_variance   | 0.758     |
|    learning_rate        | 8.01e-05  |
|    loss                 | 10.4      |
|    n_updates            | 1224      |
|    policy_gradient_loss | 0.0163    |
|    value_loss           | 33.4      |
---------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 828         |
|    ep_rew_mean          | 329         |
| time/                   |             |
|    fps                  | 536         |
|    iterations           | 308         |
|    time_elapsed         | 37619       |
|    total_timesteps      | 20185088    |
| train/                  |             |
|    approx_kl            | 0.058769107 |
|    clip_fraction        | 0.0633      |
|    clip_range           | 0.17        |
|    entropy_loss         | -0.0622     |
|    explained_variance   | 0.767       |
|    learning_rate        | 8.01e-05    |
|    loss                 | 11.5        |
|    n_updates            | 1228        |
|    policy_gradient_loss | 0.00993     |
|    value_loss           | 37.5        |
-----------------------------------------
Eval num_timesteps=20248704, episode_reward=-10.48 +/- 0.46
Episode length: 6.60 +/- 2.69
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 6.6         |
|    mean_reward          | -10.5       |
| time/                   |             |
|    total_timesteps      | 20248704    |
| train/                  |             |
|    approx_kl            | 0.061159894 |
|    clip_fraction        | 0.0657      |
|    clip_range           | 0.17        |
|    entropy_loss         | -0.0539     |
|    explained_variance   | 0.735       |
|    learning_rate        | 8e-05       |
|    loss                 | 10.5        |
|    n_updates            | 1232        |
|    policy_gradient_loss | 0.0112      |
|    value_loss           | 37.3        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 786      |
|    ep_rew_mean     | 307      |
| time/              |          |
|    fps             | 536      |
|    iterations      | 309      |
|    time_elapsed    | 37745    |
|    total_timesteps | 20250624 |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 779        |
|    ep_rew_mean          | 328        |
| time/                   |            |
|    fps                  | 536        |
|    iterations           | 310        |
|    time_elapsed         | 37868      |
|    total_timesteps      | 20316160   |
| train/                  |            |
|    approx_kl            | 0.05098658 |
|    clip_fraction        | 0.056      |
|    clip_range           | 0.17       |
|    entropy_loss         | -0.0495    |
|    explained_variance   | 0.811      |
|    learning_rate        | 8e-05      |
|    loss                 | 11.3       |
|    n_updates            | 1236       |
|    policy_gradient_loss | 0.00888    |
|    value_loss           | 34.3       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 813        |
|    ep_rew_mean          | 337        |
| time/                   |            |
|    fps                  | 536        |
|    iterations           | 311        |
|    time_elapsed         | 37985      |
|    total_timesteps      | 20381696   |
| train/                  |            |
|    approx_kl            | 0.07566789 |
|    clip_fraction        | 0.0612     |
|    clip_range           | 0.17       |
|    entropy_loss         | -0.0497    |
|    explained_variance   | 0.741      |
|    learning_rate        | 7.99e-05   |
|    loss                 | 11.3       |
|    n_updates            | 1240       |
|    policy_gradient_loss | 0.0119     |
|    value_loss           | 38         |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 831         |
|    ep_rew_mean          | 356         |
| time/                   |             |
|    fps                  | 536         |
|    iterations           | 312         |
|    time_elapsed         | 38105       |
|    total_timesteps      | 20447232    |
| train/                  |             |
|    approx_kl            | 0.043286085 |
|    clip_fraction        | 0.0493      |
|    clip_range           | 0.169       |
|    entropy_loss         | -0.0439     |
|    explained_variance   | 0.756       |
|    learning_rate        | 7.98e-05    |
|    loss                 | 10.2        |
|    n_updates            | 1244        |
|    policy_gradient_loss | 0.00878     |
|    value_loss           | 36.5        |
-----------------------------------------
Eval num_timesteps=20498688, episode_reward=-9.31 +/- 3.27
Episode length: 8.30 +/- 4.52
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 8.3         |
|    mean_reward          | -9.31       |
| time/                   |             |
|    total_timesteps      | 20498688    |
| train/                  |             |
|    approx_kl            | 0.057280127 |
|    clip_fraction        | 0.0627      |
|    clip_range           | 0.169       |
|    entropy_loss         | -0.0549     |
|    explained_variance   | 0.762       |
|    learning_rate        | 7.98e-05    |
|    loss                 | 9.24        |
|    n_updates            | 1248        |
|    policy_gradient_loss | 0.00941     |
|    value_loss           | 34.2        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 888      |
|    ep_rew_mean     | 400      |
| time/              |          |
|    fps             | 536      |
|    iterations      | 313      |
|    time_elapsed    | 38222    |
|    total_timesteps | 20512768 |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 848         |
|    ep_rew_mean          | 421         |
| time/                   |             |
|    fps                  | 536         |
|    iterations           | 314         |
|    time_elapsed         | 38343       |
|    total_timesteps      | 20578304    |
| train/                  |             |
|    approx_kl            | 0.051290102 |
|    clip_fraction        | 0.0589      |
|    clip_range           | 0.169       |
|    entropy_loss         | -0.0507     |
|    explained_variance   | 0.784       |
|    learning_rate        | 7.97e-05    |
|    loss                 | 10          |
|    n_updates            | 1252        |
|    policy_gradient_loss | 0.00915     |
|    value_loss           | 35.2        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 784        |
|    ep_rew_mean          | 337        |
| time/                   |            |
|    fps                  | 536        |
|    iterations           | 315        |
|    time_elapsed         | 38462      |
|    total_timesteps      | 20643840   |
| train/                  |            |
|    approx_kl            | 0.05809188 |
|    clip_fraction        | 0.0667     |
|    clip_range           | 0.169      |
|    entropy_loss         | -0.0533    |
|    explained_variance   | 0.735      |
|    learning_rate        | 7.96e-05   |
|    loss                 | 12.5       |
|    n_updates            | 1256       |
|    policy_gradient_loss | 0.0104     |
|    value_loss           | 40.5       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 802         |
|    ep_rew_mean          | 359         |
| time/                   |             |
|    fps                  | 536         |
|    iterations           | 316         |
|    time_elapsed         | 38586       |
|    total_timesteps      | 20709376    |
| train/                  |             |
|    approx_kl            | 0.049755055 |
|    clip_fraction        | 0.0645      |
|    clip_range           | 0.169       |
|    entropy_loss         | -0.0548     |
|    explained_variance   | 0.739       |
|    learning_rate        | 7.96e-05    |
|    loss                 | 9.45        |
|    n_updates            | 1260        |
|    policy_gradient_loss | 0.0108      |
|    value_loss           | 35.2        |
-----------------------------------------
Eval num_timesteps=20748672, episode_reward=-9.29 +/- 3.66
Episode length: 10.70 +/- 7.87
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 10.7        |
|    mean_reward          | -9.29       |
| time/                   |             |
|    total_timesteps      | 20748672    |
| train/                  |             |
|    approx_kl            | 0.061665423 |
|    clip_fraction        | 0.0666      |
|    clip_range           | 0.169       |
|    entropy_loss         | -0.0577     |
|    explained_variance   | 0.739       |
|    learning_rate        | 7.95e-05    |
|    loss                 | 12.5        |
|    n_updates            | 1264        |
|    policy_gradient_loss | 0.00762     |
|    value_loss           | 40.7        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 825      |
|    ep_rew_mean     | 378      |
| time/              |          |
|    fps             | 536      |
|    iterations      | 317      |
|    time_elapsed    | 38709    |
|    total_timesteps | 20774912 |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 820         |
|    ep_rew_mean          | 349         |
| time/                   |             |
|    fps                  | 536         |
|    iterations           | 318         |
|    time_elapsed         | 38831       |
|    total_timesteps      | 20840448    |
| train/                  |             |
|    approx_kl            | 0.054795608 |
|    clip_fraction        | 0.0604      |
|    clip_range           | 0.169       |
|    entropy_loss         | -0.0501     |
|    explained_variance   | 0.674       |
|    learning_rate        | 7.94e-05    |
|    loss                 | 9.32        |
|    n_updates            | 1268        |
|    policy_gradient_loss | 0.0121      |
|    value_loss           | 38.1        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 831        |
|    ep_rew_mean          | 350        |
| time/                   |            |
|    fps                  | 536        |
|    iterations           | 319        |
|    time_elapsed         | 38952      |
|    total_timesteps      | 20905984   |
| train/                  |            |
|    approx_kl            | 0.07390497 |
|    clip_fraction        | 0.0593     |
|    clip_range           | 0.169      |
|    entropy_loss         | -0.0498    |
|    explained_variance   | 0.666      |
|    learning_rate        | 7.94e-05   |
|    loss                 | 8.95       |
|    n_updates            | 1272       |
|    policy_gradient_loss | 0.0103     |
|    value_loss           | 35.2       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 854        |
|    ep_rew_mean          | 369        |
| time/                   |            |
|    fps                  | 536        |
|    iterations           | 320        |
|    time_elapsed         | 39075      |
|    total_timesteps      | 20971520   |
| train/                  |            |
|    approx_kl            | 0.05011722 |
|    clip_fraction        | 0.0595     |
|    clip_range           | 0.169      |
|    entropy_loss         | -0.0505    |
|    explained_variance   | 0.699      |
|    learning_rate        | 7.93e-05   |
|    loss                 | 13.3       |
|    n_updates            | 1276       |
|    policy_gradient_loss | 0.0104     |
|    value_loss           | 37.7       |
----------------------------------------
Eval num_timesteps=20998656, episode_reward=-6.85 +/- 4.95
Episode length: 9.80 +/- 4.42
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 9.8         |
|    mean_reward          | -6.85       |
| time/                   |             |
|    total_timesteps      | 20998656    |
| train/                  |             |
|    approx_kl            | 0.060441848 |
|    clip_fraction        | 0.0617      |
|    clip_range           | 0.169       |
|    entropy_loss         | -0.0493     |
|    explained_variance   | 0.711       |
|    learning_rate        | 7.92e-05    |
|    loss                 | 13.3        |
|    n_updates            | 1280        |
|    policy_gradient_loss | 0.0129      |
|    value_loss           | 36.2        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 791      |
|    ep_rew_mean     | 366      |
| time/              |          |
|    fps             | 536      |
|    iterations      | 321      |
|    time_elapsed    | 39197    |
|    total_timesteps | 21037056 |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 778         |
|    ep_rew_mean          | 359         |
| time/                   |             |
|    fps                  | 536         |
|    iterations           | 322         |
|    time_elapsed         | 39310       |
|    total_timesteps      | 21102592    |
| train/                  |             |
|    approx_kl            | 0.062154233 |
|    clip_fraction        | 0.0638      |
|    clip_range           | 0.168       |
|    entropy_loss         | -0.0497     |
|    explained_variance   | 0.715       |
|    learning_rate        | 7.92e-05    |
|    loss                 | 13.5        |
|    n_updates            | 1284        |
|    policy_gradient_loss | 0.0129      |
|    value_loss           | 40.4        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 812        |
|    ep_rew_mean          | 372        |
| time/                   |            |
|    fps                  | 536        |
|    iterations           | 323        |
|    time_elapsed         | 39430      |
|    total_timesteps      | 21168128   |
| train/                  |            |
|    approx_kl            | 0.07303995 |
|    clip_fraction        | 0.0676     |
|    clip_range           | 0.168      |
|    entropy_loss         | -0.0535    |
|    explained_variance   | 0.705      |
|    learning_rate        | 7.91e-05   |
|    loss                 | 12.8       |
|    n_updates            | 1288       |
|    policy_gradient_loss | 0.012      |
|    value_loss           | 37.7       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 842        |
|    ep_rew_mean          | 344        |
| time/                   |            |
|    fps                  | 536        |
|    iterations           | 324        |
|    time_elapsed         | 39552      |
|    total_timesteps      | 21233664   |
| train/                  |            |
|    approx_kl            | 0.07041832 |
|    clip_fraction        | 0.0655     |
|    clip_range           | 0.168      |
|    entropy_loss         | -0.0498    |
|    explained_variance   | 0.733      |
|    learning_rate        | 7.9e-05    |
|    loss                 | 11.5       |
|    n_updates            | 1292       |
|    policy_gradient_loss | 0.0118     |
|    value_loss           | 38.5       |
----------------------------------------
Eval num_timesteps=21248640, episode_reward=-7.81 +/- 4.45
Episode length: 7.70 +/- 3.49
--------------------------------------
| eval/                   |          |
|    mean_ep_length       | 7.7      |
|    mean_reward          | -7.81    |
| time/                   |          |
|    total_timesteps      | 21248640 |
| train/                  |          |
|    approx_kl            | 0.067296 |
|    clip_fraction        | 0.0607   |
|    clip_range           | 0.168    |
|    entropy_loss         | -0.0547  |
|    explained_variance   | 0.726    |
|    learning_rate        | 7.9e-05  |
|    loss                 | 12.4     |
|    n_updates            | 1296     |
|    policy_gradient_loss | 0.00918  |
|    value_loss           | 38.4     |
--------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 800      |
|    ep_rew_mean     | 351      |
| time/              |          |
|    fps             | 536      |
|    iterations      | 325      |
|    time_elapsed    | 39674    |
|    total_timesteps | 21299200 |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 773        |
|    ep_rew_mean          | 352        |
| time/                   |            |
|    fps                  | 536        |
|    iterations           | 326        |
|    time_elapsed         | 39797      |
|    total_timesteps      | 21364736   |
| train/                  |            |
|    approx_kl            | 0.04940651 |
|    clip_fraction        | 0.0567     |
|    clip_range           | 0.168      |
|    entropy_loss         | -0.0494    |
|    explained_variance   | 0.761      |
|    learning_rate        | 7.89e-05   |
|    loss                 | 12.4       |
|    n_updates            | 1300       |
|    policy_gradient_loss | 0.00969    |
|    value_loss           | 43         |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 769        |
|    ep_rew_mean          | 328        |
| time/                   |            |
|    fps                  | 536        |
|    iterations           | 327        |
|    time_elapsed         | 39917      |
|    total_timesteps      | 21430272   |
| train/                  |            |
|    approx_kl            | 0.06896712 |
|    clip_fraction        | 0.0603     |
|    clip_range           | 0.168      |
|    entropy_loss         | -0.0484    |
|    explained_variance   | 0.756      |
|    learning_rate        | 7.88e-05   |
|    loss                 | 12.5       |
|    n_updates            | 1304       |
|    policy_gradient_loss | 0.00977    |
|    value_loss           | 40.2       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 787         |
|    ep_rew_mean          | 372         |
| time/                   |             |
|    fps                  | 536         |
|    iterations           | 328         |
|    time_elapsed         | 40034       |
|    total_timesteps      | 21495808    |
| train/                  |             |
|    approx_kl            | 0.073913254 |
|    clip_fraction        | 0.0725      |
|    clip_range           | 0.168       |
|    entropy_loss         | -0.0618     |
|    explained_variance   | 0.727       |
|    learning_rate        | 7.88e-05    |
|    loss                 | 12.2        |
|    n_updates            | 1308        |
|    policy_gradient_loss | 0.00943     |
|    value_loss           | 40.4        |
-----------------------------------------
Eval num_timesteps=21498624, episode_reward=-10.48 +/- 0.44
Episode length: 7.20 +/- 2.79
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 7.2        |
|    mean_reward          | -10.5      |
| time/                   |            |
|    total_timesteps      | 21498624   |
| train/                  |            |
|    approx_kl            | 0.28013185 |
|    clip_fraction        | 0.0789     |
|    clip_range           | 0.168      |
|    entropy_loss         | -0.0559    |
|    explained_variance   | 0.687      |
|    learning_rate        | 7.87e-05   |
|    loss                 | 11.5       |
|    n_updates            | 1312       |
|    policy_gradient_loss | 0.0176     |
|    value_loss           | 40         |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 738      |
|    ep_rew_mean     | 132      |
| time/              |          |
|    fps             | 536      |
|    iterations      | 329      |
|    time_elapsed    | 40155    |
|    total_timesteps | 21561344 |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 705         |
|    ep_rew_mean          | 57          |
| time/                   |             |
|    fps                  | 536         |
|    iterations           | 330         |
|    time_elapsed         | 40273       |
|    total_timesteps      | 21626880    |
| train/                  |             |
|    approx_kl            | 0.039435733 |
|    clip_fraction        | 0.0722      |
|    clip_range           | 0.168       |
|    entropy_loss         | -0.0747     |
|    explained_variance   | 0.795       |
|    learning_rate        | 7.87e-05    |
|    loss                 | 3.94        |
|    n_updates            | 1316        |
|    policy_gradient_loss | 0.00773     |
|    value_loss           | 16.6        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 797         |
|    ep_rew_mean          | 142         |
| time/                   |             |
|    fps                  | 536         |
|    iterations           | 331         |
|    time_elapsed         | 40398       |
|    total_timesteps      | 21692416    |
| train/                  |             |
|    approx_kl            | 0.052568093 |
|    clip_fraction        | 0.0809      |
|    clip_range           | 0.168       |
|    entropy_loss         | -0.0707     |
|    explained_variance   | 0.784       |
|    learning_rate        | 7.86e-05    |
|    loss                 | 4.74        |
|    n_updates            | 1320        |
|    policy_gradient_loss | 0.0121      |
|    value_loss           | 16.2        |
-----------------------------------------
Eval num_timesteps=21748608, episode_reward=-8.39 +/- 4.51
Episode length: 8.50 +/- 4.70
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 8.5        |
|    mean_reward          | -8.39      |
| time/                   |            |
|    total_timesteps      | 21748608   |
| train/                  |            |
|    approx_kl            | 0.05012866 |
|    clip_fraction        | 0.0641     |
|    clip_range           | 0.167      |
|    entropy_loss         | -0.0646    |
|    explained_variance   | 0.771      |
|    learning_rate        | 7.85e-05   |
|    loss                 | 7.03       |
|    n_updates            | 1324       |
|    policy_gradient_loss | 0.0105     |
|    value_loss           | 25.9       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 868      |
|    ep_rew_mean     | 252      |
| time/              |          |
|    fps             | 536      |
|    iterations      | 332      |
|    time_elapsed    | 40519    |
|    total_timesteps | 21757952 |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 824        |
|    ep_rew_mean          | 280        |
| time/                   |            |
|    fps                  | 537        |
|    iterations           | 333        |
|    time_elapsed         | 40639      |
|    total_timesteps      | 21823488   |
| train/                  |            |
|    approx_kl            | 0.06430982 |
|    clip_fraction        | 0.0652     |
|    clip_range           | 0.167      |
|    entropy_loss         | -0.0559    |
|    explained_variance   | 0.78       |
|    learning_rate        | 7.85e-05   |
|    loss                 | 11.5       |
|    n_updates            | 1328       |
|    policy_gradient_loss | 0.0115     |
|    value_loss           | 35         |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 751        |
|    ep_rew_mean          | 267        |
| time/                   |            |
|    fps                  | 537        |
|    iterations           | 334        |
|    time_elapsed         | 40758      |
|    total_timesteps      | 21889024   |
| train/                  |            |
|    approx_kl            | 0.06580366 |
|    clip_fraction        | 0.0719     |
|    clip_range           | 0.167      |
|    entropy_loss         | -0.0614    |
|    explained_variance   | 0.767      |
|    learning_rate        | 7.84e-05   |
|    loss                 | 10.1       |
|    n_updates            | 1332       |
|    policy_gradient_loss | 0.0132     |
|    value_loss           | 34         |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 789        |
|    ep_rew_mean          | 317        |
| time/                   |            |
|    fps                  | 537        |
|    iterations           | 335        |
|    time_elapsed         | 40879      |
|    total_timesteps      | 21954560   |
| train/                  |            |
|    approx_kl            | 0.06332201 |
|    clip_fraction        | 0.0598     |
|    clip_range           | 0.167      |
|    entropy_loss         | -0.0524    |
|    explained_variance   | 0.751      |
|    learning_rate        | 7.83e-05   |
|    loss                 | 12.2       |
|    n_updates            | 1336       |
|    policy_gradient_loss | 0.00841    |
|    value_loss           | 39.2       |
----------------------------------------
Eval num_timesteps=21998592, episode_reward=-3.72 +/- 7.63
Episode length: 8.00 +/- 2.83
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 8          |
|    mean_reward          | -3.72      |
| time/                   |            |
|    total_timesteps      | 21998592   |
| train/                  |            |
|    approx_kl            | 0.05269751 |
|    clip_fraction        | 0.0584     |
|    clip_range           | 0.167      |
|    entropy_loss         | -0.0491    |
|    explained_variance   | 0.79       |
|    learning_rate        | 7.83e-05   |
|    loss                 | 11.8       |
|    n_updates            | 1340       |
|    policy_gradient_loss | 0.013      |
|    value_loss           | 39.1       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 819      |
|    ep_rew_mean     | 372      |
| time/              |          |
|    fps             | 537      |
|    iterations      | 336      |
|    time_elapsed    | 41004    |
|    total_timesteps | 22020096 |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 842        |
|    ep_rew_mean          | 379        |
| time/                   |            |
|    fps                  | 537        |
|    iterations           | 337        |
|    time_elapsed         | 41126      |
|    total_timesteps      | 22085632   |
| train/                  |            |
|    approx_kl            | 0.05491082 |
|    clip_fraction        | 0.0645     |
|    clip_range           | 0.167      |
|    entropy_loss         | -0.0516    |
|    explained_variance   | 0.746      |
|    learning_rate        | 7.82e-05   |
|    loss                 | 11.7       |
|    n_updates            | 1344       |
|    policy_gradient_loss | 0.0126     |
|    value_loss           | 42.5       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 821         |
|    ep_rew_mean          | 352         |
| time/                   |             |
|    fps                  | 537         |
|    iterations           | 338         |
|    time_elapsed         | 41247       |
|    total_timesteps      | 22151168    |
| train/                  |             |
|    approx_kl            | 0.055478666 |
|    clip_fraction        | 0.0616      |
|    clip_range           | 0.167       |
|    entropy_loss         | -0.0527     |
|    explained_variance   | 0.755       |
|    learning_rate        | 7.81e-05    |
|    loss                 | 14.8        |
|    n_updates            | 1348        |
|    policy_gradient_loss | 0.0105      |
|    value_loss           | 41.8        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 828        |
|    ep_rew_mean          | 356        |
| time/                   |            |
|    fps                  | 537        |
|    iterations           | 339        |
|    time_elapsed         | 41368      |
|    total_timesteps      | 22216704   |
| train/                  |            |
|    approx_kl            | 0.06172002 |
|    clip_fraction        | 0.0634     |
|    clip_range           | 0.167      |
|    entropy_loss         | -0.0517    |
|    explained_variance   | 0.714      |
|    learning_rate        | 7.81e-05   |
|    loss                 | 12.8       |
|    n_updates            | 1352       |
|    policy_gradient_loss | 0.0129     |
|    value_loss           | 42.7       |
----------------------------------------
Eval num_timesteps=22248576, episode_reward=-10.21 +/- 0.42
Episode length: 8.00 +/- 3.58
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 8          |
|    mean_reward          | -10.2      |
| time/                   |            |
|    total_timesteps      | 22248576   |
| train/                  |            |
|    approx_kl            | 0.06710934 |
|    clip_fraction        | 0.0669     |
|    clip_range           | 0.167      |
|    entropy_loss         | -0.0573    |
|    explained_variance   | 0.745      |
|    learning_rate        | 7.8e-05    |
|    loss                 | 11.1       |
|    n_updates            | 1356       |
|    policy_gradient_loss | 0.0101     |
|    value_loss           | 39.2       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 842      |
|    ep_rew_mean     | 390      |
| time/              |          |
|    fps             | 537      |
|    iterations      | 340      |
|    time_elapsed    | 41491    |
|    total_timesteps | 22282240 |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 886        |
|    ep_rew_mean          | 393        |
| time/                   |            |
|    fps                  | 537        |
|    iterations           | 341        |
|    time_elapsed         | 41613      |
|    total_timesteps      | 22347776   |
| train/                  |            |
|    approx_kl            | 0.06440082 |
|    clip_fraction        | 0.0649     |
|    clip_range           | 0.167      |
|    entropy_loss         | -0.0533    |
|    explained_variance   | 0.652      |
|    learning_rate        | 7.79e-05   |
|    loss                 | 11.3       |
|    n_updates            | 1360       |
|    policy_gradient_loss | 0.0128     |
|    value_loss           | 44.4       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 813        |
|    ep_rew_mean          | 366        |
| time/                   |            |
|    fps                  | 537        |
|    iterations           | 342        |
|    time_elapsed         | 41736      |
|    total_timesteps      | 22413312   |
| train/                  |            |
|    approx_kl            | 0.07799699 |
|    clip_fraction        | 0.069      |
|    clip_range           | 0.166      |
|    entropy_loss         | -0.0547    |
|    explained_variance   | 0.727      |
|    learning_rate        | 7.79e-05   |
|    loss                 | 9.96       |
|    n_updates            | 1364       |
|    policy_gradient_loss | 0.00909    |
|    value_loss           | 36.1       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 866        |
|    ep_rew_mean          | 415        |
| time/                   |            |
|    fps                  | 537        |
|    iterations           | 343        |
|    time_elapsed         | 41857      |
|    total_timesteps      | 22478848   |
| train/                  |            |
|    approx_kl            | 0.08315537 |
|    clip_fraction        | 0.0701     |
|    clip_range           | 0.166      |
|    entropy_loss         | -0.0551    |
|    explained_variance   | 0.683      |
|    learning_rate        | 7.78e-05   |
|    loss                 | 12.6       |
|    n_updates            | 1368       |
|    policy_gradient_loss | 0.0113     |
|    value_loss           | 39.3       |
----------------------------------------
Eval num_timesteps=22498560, episode_reward=-7.93 +/- 4.42
Episode length: 8.60 +/- 5.04
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 8.6        |
|    mean_reward          | -7.93      |
| time/                   |            |
|    total_timesteps      | 22498560   |
| train/                  |            |
|    approx_kl            | 0.07801388 |
|    clip_fraction        | 0.071      |
|    clip_range           | 0.166      |
|    entropy_loss         | -0.054     |
|    explained_variance   | 0.727      |
|    learning_rate        | 7.77e-05   |
|    loss                 | 12.3       |
|    n_updates            | 1372       |
|    policy_gradient_loss | 0.0154     |
|    value_loss           | 41.2       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 806      |
|    ep_rew_mean     | 390      |
| time/              |          |
|    fps             | 537      |
|    iterations      | 344      |
|    time_elapsed    | 41979    |
|    total_timesteps | 22544384 |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 808         |
|    ep_rew_mean          | 388         |
| time/                   |             |
|    fps                  | 537         |
|    iterations           | 345         |
|    time_elapsed         | 42101       |
|    total_timesteps      | 22609920    |
| train/                  |             |
|    approx_kl            | 0.061275054 |
|    clip_fraction        | 0.0633      |
|    clip_range           | 0.166       |
|    entropy_loss         | -0.0504     |
|    explained_variance   | 0.667       |
|    learning_rate        | 7.77e-05    |
|    loss                 | 12.8        |
|    n_updates            | 1376        |
|    policy_gradient_loss | 0.0125      |
|    value_loss           | 41.8        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 856         |
|    ep_rew_mean          | 446         |
| time/                   |             |
|    fps                  | 537         |
|    iterations           | 346         |
|    time_elapsed         | 42221       |
|    total_timesteps      | 22675456    |
| train/                  |             |
|    approx_kl            | 0.064589776 |
|    clip_fraction        | 0.0638      |
|    clip_range           | 0.166       |
|    entropy_loss         | -0.0519     |
|    explained_variance   | 0.745       |
|    learning_rate        | 7.76e-05    |
|    loss                 | 12          |
|    n_updates            | 1380        |
|    policy_gradient_loss | 0.0112      |
|    value_loss           | 40.6        |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 810       |
|    ep_rew_mean          | 353       |
| time/                   |           |
|    fps                  | 536       |
|    iterations           | 347       |
|    time_elapsed         | 42351     |
|    total_timesteps      | 22740992  |
| train/                  |           |
|    approx_kl            | 0.1137304 |
|    clip_fraction        | 0.0672    |
|    clip_range           | 0.166     |
|    entropy_loss         | -0.0483   |
|    explained_variance   | 0.712     |
|    learning_rate        | 7.76e-05  |
|    loss                 | 12.3      |
|    n_updates            | 1384      |
|    policy_gradient_loss | 0.0143    |
|    value_loss           | 45.2      |
---------------------------------------
Eval num_timesteps=22748544, episode_reward=-8.02 +/- 6.66
Episode length: 7.60 +/- 3.72
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 7.6        |
|    mean_reward          | -8.02      |
| time/                   |            |
|    total_timesteps      | 22748544   |
| train/                  |            |
|    approx_kl            | 0.06777206 |
|    clip_fraction        | 0.0755     |
|    clip_range           | 0.166      |
|    entropy_loss         | -0.0617    |
|    explained_variance   | 0.728      |
|    learning_rate        | 7.75e-05   |
|    loss                 | 11.2       |
|    n_updates            | 1388       |
|    policy_gradient_loss | 0.0104     |
|    value_loss           | 40         |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 788      |
|    ep_rew_mean     | 376      |
| time/              |          |
|    fps             | 536      |
|    iterations      | 348      |
|    time_elapsed    | 42474    |
|    total_timesteps | 22806528 |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 804        |
|    ep_rew_mean          | 400        |
| time/                   |            |
|    fps                  | 536        |
|    iterations           | 349        |
|    time_elapsed         | 42596      |
|    total_timesteps      | 22872064   |
| train/                  |            |
|    approx_kl            | 0.08566782 |
|    clip_fraction        | 0.0739     |
|    clip_range           | 0.166      |
|    entropy_loss         | -0.0582    |
|    explained_variance   | 0.685      |
|    learning_rate        | 7.74e-05   |
|    loss                 | 14.5       |
|    n_updates            | 1392       |
|    policy_gradient_loss | 0.00987    |
|    value_loss           | 46.2       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 758        |
|    ep_rew_mean          | 363        |
| time/                   |            |
|    fps                  | 536        |
|    iterations           | 350        |
|    time_elapsed         | 42720      |
|    total_timesteps      | 22937600   |
| train/                  |            |
|    approx_kl            | 0.08971405 |
|    clip_fraction        | 0.0726     |
|    clip_range           | 0.166      |
|    entropy_loss         | -0.0538    |
|    explained_variance   | 0.672      |
|    learning_rate        | 7.74e-05   |
|    loss                 | 12.5       |
|    n_updates            | 1396       |
|    policy_gradient_loss | 0.012      |
|    value_loss           | 51.1       |
----------------------------------------
Eval num_timesteps=22998528, episode_reward=-8.23 +/- 4.68
Episode length: 6.70 +/- 2.05
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 6.7         |
|    mean_reward          | -8.23       |
| time/                   |             |
|    total_timesteps      | 22998528    |
| train/                  |             |
|    approx_kl            | 0.089870684 |
|    clip_fraction        | 0.0831      |
|    clip_range           | 0.166       |
|    entropy_loss         | -0.0571     |
|    explained_variance   | 0.742       |
|    learning_rate        | 7.73e-05    |
|    loss                 | 12.5        |
|    n_updates            | 1400        |
|    policy_gradient_loss | 0.0164      |
|    value_loss           | 45.1        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 796      |
|    ep_rew_mean     | 368      |
| time/              |          |
|    fps             | 536      |
|    iterations      | 351      |
|    time_elapsed    | 42845    |
|    total_timesteps | 23003136 |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 796        |
|    ep_rew_mean          | 340        |
| time/                   |            |
|    fps                  | 536        |
|    iterations           | 352        |
|    time_elapsed         | 42968      |
|    total_timesteps      | 23068672   |
| train/                  |            |
|    approx_kl            | 0.14349145 |
|    clip_fraction        | 0.0811     |
|    clip_range           | 0.165      |
|    entropy_loss         | -0.0557    |
|    explained_variance   | 0.728      |
|    learning_rate        | 7.72e-05   |
|    loss                 | 14.1       |
|    n_updates            | 1404       |
|    policy_gradient_loss | 0.0169     |
|    value_loss           | 45.5       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 850        |
|    ep_rew_mean          | 313        |
| time/                   |            |
|    fps                  | 536        |
|    iterations           | 353        |
|    time_elapsed         | 43092      |
|    total_timesteps      | 23134208   |
| train/                  |            |
|    approx_kl            | 0.13194957 |
|    clip_fraction        | 0.103      |
|    clip_range           | 0.165      |
|    entropy_loss         | -0.0607    |
|    explained_variance   | 0.71       |
|    learning_rate        | 7.72e-05   |
|    loss                 | 14.6       |
|    n_updates            | 1408       |
|    policy_gradient_loss | 0.0205     |
|    value_loss           | 39.3       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 871         |
|    ep_rew_mean          | 347         |
| time/                   |             |
|    fps                  | 536         |
|    iterations           | 354         |
|    time_elapsed         | 43215       |
|    total_timesteps      | 23199744    |
| train/                  |             |
|    approx_kl            | 0.057127833 |
|    clip_fraction        | 0.0666      |
|    clip_range           | 0.165       |
|    entropy_loss         | -0.0553     |
|    explained_variance   | 0.721       |
|    learning_rate        | 7.71e-05    |
|    loss                 | 10          |
|    n_updates            | 1412        |
|    policy_gradient_loss | 0.0121      |
|    value_loss           | 37.1        |
-----------------------------------------
Eval num_timesteps=23248512, episode_reward=-9.14 +/- 3.39
Episode length: 6.30 +/- 1.85
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 6.3         |
|    mean_reward          | -9.14       |
| time/                   |             |
|    total_timesteps      | 23248512    |
| train/                  |             |
|    approx_kl            | 0.068669885 |
|    clip_fraction        | 0.0638      |
|    clip_range           | 0.165       |
|    entropy_loss         | -0.0518     |
|    explained_variance   | 0.714       |
|    learning_rate        | 7.7e-05     |
|    loss                 | 12.1        |
|    n_updates            | 1416        |
|    policy_gradient_loss | 0.0132      |
|    value_loss           | 39.3        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 839      |
|    ep_rew_mean     | 347      |
| time/              |          |
|    fps             | 536      |
|    iterations      | 355      |
|    time_elapsed    | 43340    |
|    total_timesteps | 23265280 |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 795        |
|    ep_rew_mean          | 316        |
| time/                   |            |
|    fps                  | 536        |
|    iterations           | 356        |
|    time_elapsed         | 43463      |
|    total_timesteps      | 23330816   |
| train/                  |            |
|    approx_kl            | 0.07217708 |
|    clip_fraction        | 0.0675     |
|    clip_range           | 0.165      |
|    entropy_loss         | -0.0582    |
|    explained_variance   | 0.682      |
|    learning_rate        | 7.7e-05    |
|    loss                 | 12.3       |
|    n_updates            | 1420       |
|    policy_gradient_loss | 0.00995    |
|    value_loss           | 40.6       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 804         |
|    ep_rew_mean          | 325         |
| time/                   |             |
|    fps                  | 536         |
|    iterations           | 357         |
|    time_elapsed         | 43590       |
|    total_timesteps      | 23396352    |
| train/                  |             |
|    approx_kl            | 0.077780426 |
|    clip_fraction        | 0.0721      |
|    clip_range           | 0.165       |
|    entropy_loss         | -0.0524     |
|    explained_variance   | 0.756       |
|    learning_rate        | 7.69e-05    |
|    loss                 | 12.5        |
|    n_updates            | 1424        |
|    policy_gradient_loss | 0.0124      |
|    value_loss           | 43          |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 834        |
|    ep_rew_mean          | 369        |
| time/                   |            |
|    fps                  | 536        |
|    iterations           | 358        |
|    time_elapsed         | 43714      |
|    total_timesteps      | 23461888   |
| train/                  |            |
|    approx_kl            | 0.07506345 |
|    clip_fraction        | 0.0781     |
|    clip_range           | 0.165      |
|    entropy_loss         | -0.0649    |
|    explained_variance   | 0.719      |
|    learning_rate        | 7.68e-05   |
|    loss                 | 10.9       |
|    n_updates            | 1428       |
|    policy_gradient_loss | 0.013      |
|    value_loss           | 38.4       |
----------------------------------------
Eval num_timesteps=23498496, episode_reward=-10.17 +/- 0.60
Episode length: 6.20 +/- 1.33
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 6.2        |
|    mean_reward          | -10.2      |
| time/                   |            |
|    total_timesteps      | 23498496   |
| train/                  |            |
|    approx_kl            | 0.07396111 |
|    clip_fraction        | 0.0695     |
|    clip_range           | 0.165      |
|    entropy_loss         | -0.054     |
|    explained_variance   | 0.67       |
|    learning_rate        | 7.68e-05   |
|    loss                 | 13.2       |
|    n_updates            | 1432       |
|    policy_gradient_loss | 0.0138     |
|    value_loss           | 44.3       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 829      |
|    ep_rew_mean     | 376      |
| time/              |          |
|    fps             | 536      |
|    iterations      | 359      |
|    time_elapsed    | 43838    |
|    total_timesteps | 23527424 |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 866        |
|    ep_rew_mean          | 399        |
| time/                   |            |
|    fps                  | 536        |
|    iterations           | 360        |
|    time_elapsed         | 43962      |
|    total_timesteps      | 23592960   |
| train/                  |            |
|    approx_kl            | 0.07426633 |
|    clip_fraction        | 0.0708     |
|    clip_range           | 0.165      |
|    entropy_loss         | -0.0533    |
|    explained_variance   | 0.71       |
|    learning_rate        | 7.67e-05   |
|    loss                 | 10.4       |
|    n_updates            | 1436       |
|    policy_gradient_loss | 0.0112     |
|    value_loss           | 41         |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 786        |
|    ep_rew_mean          | 329        |
| time/                   |            |
|    fps                  | 536        |
|    iterations           | 361        |
|    time_elapsed         | 44085      |
|    total_timesteps      | 23658496   |
| train/                  |            |
|    approx_kl            | 0.09767147 |
|    clip_fraction        | 0.0706     |
|    clip_range           | 0.165      |
|    entropy_loss         | -0.0547    |
|    explained_variance   | 0.707      |
|    learning_rate        | 7.66e-05   |
|    loss                 | 11.5       |
|    n_updates            | 1440       |
|    policy_gradient_loss | 0.0138     |
|    value_loss           | 39.7       |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 761       |
|    ep_rew_mean          | 309       |
| time/                   |           |
|    fps                  | 536       |
|    iterations           | 362       |
|    time_elapsed         | 44212     |
|    total_timesteps      | 23724032  |
| train/                  |           |
|    approx_kl            | 0.0853014 |
|    clip_fraction        | 0.0789    |
|    clip_range           | 0.165     |
|    entropy_loss         | -0.0611   |
|    explained_variance   | 0.73      |
|    learning_rate        | 7.66e-05  |
|    loss                 | 14        |
|    n_updates            | 1444      |
|    policy_gradient_loss | 0.0129    |
|    value_loss           | 40        |
---------------------------------------
Eval num_timesteps=23748480, episode_reward=-9.60 +/- 3.37
Episode length: 8.40 +/- 4.86
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 8.4        |
|    mean_reward          | -9.6       |
| time/                   |            |
|    total_timesteps      | 23748480   |
| train/                  |            |
|    approx_kl            | 0.07661471 |
|    clip_fraction        | 0.074      |
|    clip_range           | 0.164      |
|    entropy_loss         | -0.063     |
|    explained_variance   | 0.713      |
|    learning_rate        | 7.65e-05   |
|    loss                 | 13.5       |
|    n_updates            | 1448       |
|    policy_gradient_loss | 0.0149     |
|    value_loss           | 41.5       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 757      |
|    ep_rew_mean     | 360      |
| time/              |          |
|    fps             | 536      |
|    iterations      | 363      |
|    time_elapsed    | 44339    |
|    total_timesteps | 23789568 |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 740        |
|    ep_rew_mean          | 363        |
| time/                   |            |
|    fps                  | 536        |
|    iterations           | 364        |
|    time_elapsed         | 44466      |
|    total_timesteps      | 23855104   |
| train/                  |            |
|    approx_kl            | 0.06165446 |
|    clip_fraction        | 0.0631     |
|    clip_range           | 0.164      |
|    entropy_loss         | -0.0521    |
|    explained_variance   | 0.718      |
|    learning_rate        | 7.64e-05   |
|    loss                 | 13.1       |
|    n_updates            | 1452       |
|    policy_gradient_loss | 0.0121     |
|    value_loss           | 45.1       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 739        |
|    ep_rew_mean          | 315        |
| time/                   |            |
|    fps                  | 536        |
|    iterations           | 365        |
|    time_elapsed         | 44592      |
|    total_timesteps      | 23920640   |
| train/                  |            |
|    approx_kl            | 0.08316281 |
|    clip_fraction        | 0.076      |
|    clip_range           | 0.164      |
|    entropy_loss         | -0.0557    |
|    explained_variance   | 0.69       |
|    learning_rate        | 7.64e-05   |
|    loss                 | 13.9       |
|    n_updates            | 1456       |
|    policy_gradient_loss | 0.0426     |
|    value_loss           | 45.7       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 808        |
|    ep_rew_mean          | 354        |
| time/                   |            |
|    fps                  | 536        |
|    iterations           | 366        |
|    time_elapsed         | 44721      |
|    total_timesteps      | 23986176   |
| train/                  |            |
|    approx_kl            | 0.09033379 |
|    clip_fraction        | 0.0851     |
|    clip_range           | 0.164      |
|    entropy_loss         | -0.0616    |
|    explained_variance   | 0.695      |
|    learning_rate        | 7.63e-05   |
|    loss                 | 10.7       |
|    n_updates            | 1460       |
|    policy_gradient_loss | 0.0186     |
|    value_loss           | 41.7       |
----------------------------------------
Eval num_timesteps=23998464, episode_reward=-9.40 +/- 3.28
Episode length: 7.80 +/- 4.19
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 7.8         |
|    mean_reward          | -9.4        |
| time/                   |             |
|    total_timesteps      | 23998464    |
| train/                  |             |
|    approx_kl            | 0.076450124 |
|    clip_fraction        | 0.0748      |
|    clip_range           | 0.164       |
|    entropy_loss         | -0.0509     |
|    explained_variance   | 0.705       |
|    learning_rate        | 7.63e-05    |
|    loss                 | 11.9        |
|    n_updates            | 1464        |
|    policy_gradient_loss | 0.0203      |
|    value_loss           | 40.7        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 813      |
|    ep_rew_mean     | 373      |
| time/              |          |
|    fps             | 536      |
|    iterations      | 367      |
|    time_elapsed    | 44847    |
|    total_timesteps | 24051712 |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 827        |
|    ep_rew_mean          | 380        |
| time/                   |            |
|    fps                  | 536        |
|    iterations           | 368        |
|    time_elapsed         | 44973      |
|    total_timesteps      | 24117248   |
| train/                  |            |
|    approx_kl            | 0.06851618 |
|    clip_fraction        | 0.0672     |
|    clip_range           | 0.164      |
|    entropy_loss         | -0.0528    |
|    explained_variance   | 0.709      |
|    learning_rate        | 7.62e-05   |
|    loss                 | 14.8       |
|    n_updates            | 1468       |
|    policy_gradient_loss | 0.0126     |
|    value_loss           | 44.1       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 748        |
|    ep_rew_mean          | 368        |
| time/                   |            |
|    fps                  | 536        |
|    iterations           | 369        |
|    time_elapsed         | 45098      |
|    total_timesteps      | 24182784   |
| train/                  |            |
|    approx_kl            | 0.07485475 |
|    clip_fraction        | 0.0718     |
|    clip_range           | 0.164      |
|    entropy_loss         | -0.0561    |
|    explained_variance   | 0.702      |
|    learning_rate        | 7.61e-05   |
|    loss                 | 13.7       |
|    n_updates            | 1472       |
|    policy_gradient_loss | 0.00989    |
|    value_loss           | 43.1       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 725        |
|    ep_rew_mean          | 321        |
| time/                   |            |
|    fps                  | 536        |
|    iterations           | 370        |
|    time_elapsed         | 45222      |
|    total_timesteps      | 24248320   |
| train/                  |            |
|    approx_kl            | 0.10193892 |
|    clip_fraction        | 0.064      |
|    clip_range           | 0.164      |
|    entropy_loss         | -0.0504    |
|    explained_variance   | 0.667      |
|    learning_rate        | 7.61e-05   |
|    loss                 | 15.9       |
|    n_updates            | 1476       |
|    policy_gradient_loss | 0.0119     |
|    value_loss           | 46.9       |
----------------------------------------
Eval num_timesteps=24248448, episode_reward=-5.60 +/- 7.42
Episode length: 9.50 +/- 5.97
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 9.5       |
|    mean_reward          | -5.6      |
| time/                   |           |
|    total_timesteps      | 24248448  |
| train/                  |           |
|    approx_kl            | 0.0645258 |
|    clip_fraction        | 0.0696    |
|    clip_range           | 0.164     |
|    entropy_loss         | -0.0605   |
|    explained_variance   | 0.67      |
|    learning_rate        | 7.6e-05   |
|    loss                 | 11.7      |
|    n_updates            | 1480      |
|    policy_gradient_loss | 0.0119    |
|    value_loss           | 42.8      |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 786      |
|    ep_rew_mean     | 363      |
| time/              |          |
|    fps             | 536      |
|    iterations      | 371      |
|    time_elapsed    | 45349    |
|    total_timesteps | 24313856 |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 743         |
|    ep_rew_mean          | 363         |
| time/                   |             |
|    fps                  | 536         |
|    iterations           | 372         |
|    time_elapsed         | 45476       |
|    total_timesteps      | 24379392    |
| train/                  |             |
|    approx_kl            | 0.070081845 |
|    clip_fraction        | 0.068       |
|    clip_range           | 0.164       |
|    entropy_loss         | -0.0575     |
|    explained_variance   | 0.698       |
|    learning_rate        | 7.59e-05    |
|    loss                 | 12.8        |
|    n_updates            | 1484        |
|    policy_gradient_loss | 0.0104      |
|    value_loss           | 44.8        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 775        |
|    ep_rew_mean          | 381        |
| time/                   |            |
|    fps                  | 536        |
|    iterations           | 373        |
|    time_elapsed         | 45600      |
|    total_timesteps      | 24444928   |
| train/                  |            |
|    approx_kl            | 0.07427623 |
|    clip_fraction        | 0.0693     |
|    clip_range           | 0.163      |
|    entropy_loss         | -0.0555    |
|    explained_variance   | 0.651      |
|    learning_rate        | 7.59e-05   |
|    loss                 | 18.3       |
|    n_updates            | 1488       |
|    policy_gradient_loss | 0.0139     |
|    value_loss           | 49.5       |
----------------------------------------
Eval num_timesteps=24498432, episode_reward=-7.95 +/- 4.63
Episode length: 8.90 +/- 5.73
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 8.9        |
|    mean_reward          | -7.95      |
| time/                   |            |
|    total_timesteps      | 24498432   |
| train/                  |            |
|    approx_kl            | 0.06516042 |
|    clip_fraction        | 0.062      |
|    clip_range           | 0.163      |
|    entropy_loss         | -0.0475    |
|    explained_variance   | 0.749      |
|    learning_rate        | 7.58e-05   |
|    loss                 | 13.2       |
|    n_updates            | 1492       |
|    policy_gradient_loss | 0.0115     |
|    value_loss           | 41.7       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 727      |
|    ep_rew_mean     | 340      |
| time/              |          |
|    fps             | 536      |
|    iterations      | 374      |
|    time_elapsed    | 45722    |
|    total_timesteps | 24510464 |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 803        |
|    ep_rew_mean          | 385        |
| time/                   |            |
|    fps                  | 536        |
|    iterations           | 375        |
|    time_elapsed         | 45843      |
|    total_timesteps      | 24576000   |
| train/                  |            |
|    approx_kl            | 0.06481479 |
|    clip_fraction        | 0.0671     |
|    clip_range           | 0.163      |
|    entropy_loss         | -0.0517    |
|    explained_variance   | 0.715      |
|    learning_rate        | 7.57e-05   |
|    loss                 | 13.6       |
|    n_updates            | 1496       |
|    policy_gradient_loss | 0.0119     |
|    value_loss           | 43.9       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 764         |
|    ep_rew_mean          | 351         |
| time/                   |             |
|    fps                  | 536         |
|    iterations           | 376         |
|    time_elapsed         | 45964       |
|    total_timesteps      | 24641536    |
| train/                  |             |
|    approx_kl            | 0.067674235 |
|    clip_fraction        | 0.0683      |
|    clip_range           | 0.163       |
|    entropy_loss         | -0.0496     |
|    explained_variance   | 0.733       |
|    learning_rate        | 7.57e-05    |
|    loss                 | 14.7        |
|    n_updates            | 1500        |
|    policy_gradient_loss | 0.0125      |
|    value_loss           | 48.8        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 741        |
|    ep_rew_mean          | 335        |
| time/                   |            |
|    fps                  | 536        |
|    iterations           | 377        |
|    time_elapsed         | 46086      |
|    total_timesteps      | 24707072   |
| train/                  |            |
|    approx_kl            | 0.07902938 |
|    clip_fraction        | 0.0675     |
|    clip_range           | 0.163      |
|    entropy_loss         | -0.0514    |
|    explained_variance   | 0.705      |
|    learning_rate        | 7.56e-05   |
|    loss                 | 12.9       |
|    n_updates            | 1504       |
|    policy_gradient_loss | 0.0133     |
|    value_loss           | 45.5       |
----------------------------------------
Eval num_timesteps=24748416, episode_reward=-6.96 +/- 5.32
Episode length: 11.60 +/- 8.06
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 11.6       |
|    mean_reward          | -6.96      |
| time/                   |            |
|    total_timesteps      | 24748416   |
| train/                  |            |
|    approx_kl            | 0.07027962 |
|    clip_fraction        | 0.0622     |
|    clip_range           | 0.163      |
|    entropy_loss         | -0.0523    |
|    explained_variance   | 0.731      |
|    learning_rate        | 7.55e-05   |
|    loss                 | 13.9       |
|    n_updates            | 1508       |
|    policy_gradient_loss | 0.00971    |
|    value_loss           | 44.8       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 811      |
|    ep_rew_mean     | 340      |
| time/              |          |
|    fps             | 535      |
|    iterations      | 378      |
|    time_elapsed    | 46218    |
|    total_timesteps | 24772608 |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 770        |
|    ep_rew_mean          | 350        |
| time/                   |            |
|    fps                  | 535        |
|    iterations           | 379        |
|    time_elapsed         | 46352      |
|    total_timesteps      | 24838144   |
| train/                  |            |
|    approx_kl            | 0.06469342 |
|    clip_fraction        | 0.0622     |
|    clip_range           | 0.163      |
|    entropy_loss         | -0.0476    |
|    explained_variance   | 0.711      |
|    learning_rate        | 7.55e-05   |
|    loss                 | 13         |
|    n_updates            | 1512       |
|    policy_gradient_loss | 0.0124     |
|    value_loss           | 43.8       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 726        |
|    ep_rew_mean          | 351        |
| time/                   |            |
|    fps                  | 535        |
|    iterations           | 380        |
|    time_elapsed         | 46481      |
|    total_timesteps      | 24903680   |
| train/                  |            |
|    approx_kl            | 0.08783007 |
|    clip_fraction        | 0.0675     |
|    clip_range           | 0.163      |
|    entropy_loss         | -0.0481    |
|    explained_variance   | 0.728      |
|    learning_rate        | 7.54e-05   |
|    loss                 | 12.7       |
|    n_updates            | 1516       |
|    policy_gradient_loss | 0.0146     |
|    value_loss           | 42.8       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 800         |
|    ep_rew_mean          | 402         |
| time/                   |             |
|    fps                  | 535         |
|    iterations           | 381         |
|    time_elapsed         | 46610       |
|    total_timesteps      | 24969216    |
| train/                  |             |
|    approx_kl            | 0.060118154 |
|    clip_fraction        | 0.058       |
|    clip_range           | 0.163       |
|    entropy_loss         | -0.0474     |
|    explained_variance   | 0.742       |
|    learning_rate        | 7.53e-05    |
|    loss                 | 14.8        |
|    n_updates            | 1520        |
|    policy_gradient_loss | 0.0106      |
|    value_loss           | 44.5        |
-----------------------------------------
Eval num_timesteps=24998400, episode_reward=-9.26 +/- 3.43
Episode length: 8.50 +/- 4.15
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 8.5         |
|    mean_reward          | -9.26       |
| time/                   |             |
|    total_timesteps      | 24998400    |
| train/                  |             |
|    approx_kl            | 0.053928606 |
|    clip_fraction        | 0.0603      |
|    clip_range           | 0.163       |
|    entropy_loss         | -0.0483     |
|    explained_variance   | 0.743       |
|    learning_rate        | 7.53e-05    |
|    loss                 | 14.4        |
|    n_updates            | 1524        |
|    policy_gradient_loss | 0.00936     |
|    value_loss           | 45.2        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 843      |
|    ep_rew_mean     | 461      |
| time/              |          |
|    fps             | 535      |
|    iterations      | 382      |
|    time_elapsed    | 46740    |
|    total_timesteps | 25034752 |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 877         |
|    ep_rew_mean          | 503         |
| time/                   |             |
|    fps                  | 535         |
|    iterations           | 383         |
|    time_elapsed         | 46869       |
|    total_timesteps      | 25100288    |
| train/                  |             |
|    approx_kl            | 0.057856306 |
|    clip_fraction        | 0.058       |
|    clip_range           | 0.162       |
|    entropy_loss         | -0.046      |
|    explained_variance   | 0.707       |
|    learning_rate        | 7.52e-05    |
|    loss                 | 14.7        |
|    n_updates            | 1528        |
|    policy_gradient_loss | 0.0101      |
|    value_loss           | 50.2        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 811        |
|    ep_rew_mean          | 429        |
| time/                   |            |
|    fps                  | 535        |
|    iterations           | 384        |
|    time_elapsed         | 46998      |
|    total_timesteps      | 25165824   |
| train/                  |            |
|    approx_kl            | 0.06554595 |
|    clip_fraction        | 0.0598     |
|    clip_range           | 0.162      |
|    entropy_loss         | -0.0451    |
|    explained_variance   | 0.697      |
|    learning_rate        | 7.52e-05   |
|    loss                 | 17.9       |
|    n_updates            | 1532       |
|    policy_gradient_loss | 0.0103     |
|    value_loss           | 49.6       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 804        |
|    ep_rew_mean          | 367        |
| time/                   |            |
|    fps                  | 535        |
|    iterations           | 385        |
|    time_elapsed         | 47127      |
|    total_timesteps      | 25231360   |
| train/                  |            |
|    approx_kl            | 0.06348099 |
|    clip_fraction        | 0.0601     |
|    clip_range           | 0.162      |
|    entropy_loss         | -0.0472    |
|    explained_variance   | 0.661      |
|    learning_rate        | 7.51e-05   |
|    loss                 | 12.9       |
|    n_updates            | 1536       |
|    policy_gradient_loss | 0.0116     |
|    value_loss           | 46.4       |
----------------------------------------
Eval num_timesteps=25248384, episode_reward=-7.98 +/- 4.45
Episode length: 9.40 +/- 6.42
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 9.4         |
|    mean_reward          | -7.98       |
| time/                   |             |
|    total_timesteps      | 25248384    |
| train/                  |             |
|    approx_kl            | 0.073188215 |
|    clip_fraction        | 0.06        |
|    clip_range           | 0.162       |
|    entropy_loss         | -0.0442     |
|    explained_variance   | 0.671       |
|    learning_rate        | 7.5e-05     |
|    loss                 | 14.4        |
|    n_updates            | 1540        |
|    policy_gradient_loss | 0.012       |
|    value_loss           | 49.3        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 815      |
|    ep_rew_mean     | 377      |
| time/              |          |
|    fps             | 535      |
|    iterations      | 386      |
|    time_elapsed    | 47257    |
|    total_timesteps | 25296896 |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 788         |
|    ep_rew_mean          | 406         |
| time/                   |             |
|    fps                  | 535         |
|    iterations           | 387         |
|    time_elapsed         | 47387       |
|    total_timesteps      | 25362432    |
| train/                  |             |
|    approx_kl            | 0.060370106 |
|    clip_fraction        | 0.06        |
|    clip_range           | 0.162       |
|    entropy_loss         | -0.0486     |
|    explained_variance   | 0.725       |
|    learning_rate        | 7.5e-05     |
|    loss                 | 12          |
|    n_updates            | 1544        |
|    policy_gradient_loss | 0.0119      |
|    value_loss           | 41.9        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 821        |
|    ep_rew_mean          | 428        |
| time/                   |            |
|    fps                  | 535        |
|    iterations           | 388        |
|    time_elapsed         | 47516      |
|    total_timesteps      | 25427968   |
| train/                  |            |
|    approx_kl            | 0.06499449 |
|    clip_fraction        | 0.068      |
|    clip_range           | 0.162      |
|    entropy_loss         | -0.0507    |
|    explained_variance   | 0.628      |
|    learning_rate        | 7.49e-05   |
|    loss                 | 15.1       |
|    n_updates            | 1548       |
|    policy_gradient_loss | 0.0139     |
|    value_loss           | 53         |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 805        |
|    ep_rew_mean          | 423        |
| time/                   |            |
|    fps                  | 535        |
|    iterations           | 389        |
|    time_elapsed         | 47645      |
|    total_timesteps      | 25493504   |
| train/                  |            |
|    approx_kl            | 0.08004682 |
|    clip_fraction        | 0.0831     |
|    clip_range           | 0.162      |
|    entropy_loss         | -0.0638    |
|    explained_variance   | 0.611      |
|    learning_rate        | 7.48e-05   |
|    loss                 | 14.1       |
|    n_updates            | 1552       |
|    policy_gradient_loss | 0.0131     |
|    value_loss           | 47.6       |
----------------------------------------
Eval num_timesteps=25498368, episode_reward=-7.89 +/- 4.39
Episode length: 11.00 +/- 6.63
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 11         |
|    mean_reward          | -7.89      |
| time/                   |            |
|    total_timesteps      | 25498368   |
| train/                  |            |
|    approx_kl            | 0.07030453 |
|    clip_fraction        | 0.0663     |
|    clip_range           | 0.162      |
|    entropy_loss         | -0.0508    |
|    explained_variance   | 0.641      |
|    learning_rate        | 7.48e-05   |
|    loss                 | 15.9       |
|    n_updates            | 1556       |
|    policy_gradient_loss | 0.0124     |
|    value_loss           | 53.5       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 786      |
|    ep_rew_mean     | 427      |
| time/              |          |
|    fps             | 534      |
|    iterations      | 390      |
|    time_elapsed    | 47777    |
|    total_timesteps | 25559040 |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 741        |
|    ep_rew_mean          | 391        |
| time/                   |            |
|    fps                  | 534        |
|    iterations           | 391        |
|    time_elapsed         | 47904      |
|    total_timesteps      | 25624576   |
| train/                  |            |
|    approx_kl            | 0.06935601 |
|    clip_fraction        | 0.0648     |
|    clip_range           | 0.162      |
|    entropy_loss         | -0.0471    |
|    explained_variance   | 0.714      |
|    learning_rate        | 7.47e-05   |
|    loss                 | 13.6       |
|    n_updates            | 1560       |
|    policy_gradient_loss | 0.0138     |
|    value_loss           | 46.3       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 768        |
|    ep_rew_mean          | 416        |
| time/                   |            |
|    fps                  | 534        |
|    iterations           | 392        |
|    time_elapsed         | 48039      |
|    total_timesteps      | 25690112   |
| train/                  |            |
|    approx_kl            | 0.07628928 |
|    clip_fraction        | 0.0621     |
|    clip_range           | 0.162      |
|    entropy_loss         | -0.0459    |
|    explained_variance   | 0.661      |
|    learning_rate        | 7.46e-05   |
|    loss                 | 16.4       |
|    n_updates            | 1564       |
|    policy_gradient_loss | 0.0128     |
|    value_loss           | 50.9       |
----------------------------------------
Eval num_timesteps=25748352, episode_reward=-6.93 +/- 7.11
Episode length: 9.80 +/- 3.74
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 9.8       |
|    mean_reward          | -6.93     |
| time/                   |           |
|    total_timesteps      | 25748352  |
| train/                  |           |
|    approx_kl            | 0.0725725 |
|    clip_fraction        | 0.0706    |
|    clip_range           | 0.161     |
|    entropy_loss         | -0.0479   |
|    explained_variance   | 0.65      |
|    learning_rate        | 7.46e-05  |
|    loss                 | 18.5      |
|    n_updates            | 1568      |
|    policy_gradient_loss | 0.026     |
|    value_loss           | 53.2      |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 827      |
|    ep_rew_mean     | 447      |
| time/              |          |
|    fps             | 534      |
|    iterations      | 393      |
|    time_elapsed    | 48175    |
|    total_timesteps | 25755648 |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 738        |
|    ep_rew_mean          | 362        |
| time/                   |            |
|    fps                  | 534        |
|    iterations           | 394        |
|    time_elapsed         | 48303      |
|    total_timesteps      | 25821184   |
| train/                  |            |
|    approx_kl            | 0.07336661 |
|    clip_fraction        | 0.077      |
|    clip_range           | 0.161      |
|    entropy_loss         | -0.0528    |
|    explained_variance   | 0.62       |
|    learning_rate        | 7.45e-05   |
|    loss                 | 15.8       |
|    n_updates            | 1572       |
|    policy_gradient_loss | 0.0164     |
|    value_loss           | 51.1       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 757        |
|    ep_rew_mean          | 348        |
| time/                   |            |
|    fps                  | 534        |
|    iterations           | 395        |
|    time_elapsed         | 48435      |
|    total_timesteps      | 25886720   |
| train/                  |            |
|    approx_kl            | 0.10612147 |
|    clip_fraction        | 0.0764     |
|    clip_range           | 0.161      |
|    entropy_loss         | -0.0563    |
|    explained_variance   | 0.664      |
|    learning_rate        | 7.44e-05   |
|    loss                 | 17.9       |
|    n_updates            | 1576       |
|    policy_gradient_loss | 0.013      |
|    value_loss           | 49         |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 746         |
|    ep_rew_mean          | 349         |
| time/                   |             |
|    fps                  | 534         |
|    iterations           | 396         |
|    time_elapsed         | 48563       |
|    total_timesteps      | 25952256    |
| train/                  |             |
|    approx_kl            | 0.053267777 |
|    clip_fraction        | 0.0638      |
|    clip_range           | 0.161       |
|    entropy_loss         | -0.0524     |
|    explained_variance   | 0.725       |
|    learning_rate        | 7.44e-05    |
|    loss                 | 12.7        |
|    n_updates            | 1580        |
|    policy_gradient_loss | 0.0114      |
|    value_loss           | 43.9        |
-----------------------------------------
Eval num_timesteps=25998336, episode_reward=-9.17 +/- 3.47
Episode length: 7.30 +/- 3.72
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 7.3       |
|    mean_reward          | -9.17     |
| time/                   |           |
|    total_timesteps      | 25998336  |
| train/                  |           |
|    approx_kl            | 0.0732808 |
|    clip_fraction        | 0.0709    |
|    clip_range           | 0.161     |
|    entropy_loss         | -0.0555   |
|    explained_variance   | 0.711     |
|    learning_rate        | 7.43e-05  |
|    loss                 | 13.2      |
|    n_updates            | 1584      |
|    policy_gradient_loss | 0.0105    |
|    value_loss           | 47.2      |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 719      |
|    ep_rew_mean     | 353      |
| time/              |          |
|    fps             | 534      |
|    iterations      | 397      |
|    time_elapsed    | 48696    |
|    total_timesteps | 26017792 |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 740        |
|    ep_rew_mean          | 346        |
| time/                   |            |
|    fps                  | 534        |
|    iterations           | 398        |
|    time_elapsed         | 48826      |
|    total_timesteps      | 26083328   |
| train/                  |            |
|    approx_kl            | 0.07598551 |
|    clip_fraction        | 0.0655     |
|    clip_range           | 0.161      |
|    entropy_loss         | -0.0519    |
|    explained_variance   | 0.68       |
|    learning_rate        | 7.42e-05   |
|    loss                 | 17.5       |
|    n_updates            | 1588       |
|    policy_gradient_loss | 0.0112     |
|    value_loss           | 51         |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 794         |
|    ep_rew_mean          | 372         |
| time/                   |             |
|    fps                  | 534         |
|    iterations           | 399         |
|    time_elapsed         | 48956       |
|    total_timesteps      | 26148864    |
| train/                  |             |
|    approx_kl            | 0.101337716 |
|    clip_fraction        | 0.0719      |
|    clip_range           | 0.161       |
|    entropy_loss         | -0.0575     |
|    explained_variance   | 0.631       |
|    learning_rate        | 7.42e-05    |
|    loss                 | 12.8        |
|    n_updates            | 1592        |
|    policy_gradient_loss | 0.0119      |
|    value_loss           | 45.3        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 771         |
|    ep_rew_mean          | 365         |
| time/                   |             |
|    fps                  | 534         |
|    iterations           | 400         |
|    time_elapsed         | 49087       |
|    total_timesteps      | 26214400    |
| train/                  |             |
|    approx_kl            | 0.061965253 |
|    clip_fraction        | 0.0655      |
|    clip_range           | 0.161       |
|    entropy_loss         | -0.0528     |
|    explained_variance   | 0.677       |
|    learning_rate        | 7.41e-05    |
|    loss                 | 15.9        |
|    n_updates            | 1596        |
|    policy_gradient_loss | 0.0136      |
|    value_loss           | 45.1        |
-----------------------------------------
Eval num_timesteps=26248320, episode_reward=-8.08 +/- 4.58
Episode length: 9.20 +/- 2.36
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 9.2        |
|    mean_reward          | -8.08      |
| time/                   |            |
|    total_timesteps      | 26248320   |
| train/                  |            |
|    approx_kl            | 0.05617898 |
|    clip_fraction        | 0.0592     |
|    clip_range           | 0.161      |
|    entropy_loss         | -0.0489    |
|    explained_variance   | 0.711      |
|    learning_rate        | 7.4e-05    |
|    loss                 | 13.6       |
|    n_updates            | 1600       |
|    policy_gradient_loss | 0.0113     |
|    value_loss           | 48         |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 709      |
|    ep_rew_mean     | 325      |
| time/              |          |
|    fps             | 533      |
|    iterations      | 401      |
|    time_elapsed    | 49222    |
|    total_timesteps | 26279936 |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 764        |
|    ep_rew_mean          | 296        |
| time/                   |            |
|    fps                  | 533        |
|    iterations           | 402        |
|    time_elapsed         | 49360      |
|    total_timesteps      | 26345472   |
| train/                  |            |
|    approx_kl            | 0.17847756 |
|    clip_fraction        | 0.0808     |
|    clip_range           | 0.161      |
|    entropy_loss         | -0.0547    |
|    explained_variance   | 0.74       |
|    learning_rate        | 7.4e-05    |
|    loss                 | 15.5       |
|    n_updates            | 1604       |
|    policy_gradient_loss | 0.019      |
|    value_loss           | 46.9       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 795        |
|    ep_rew_mean          | 348        |
| time/                   |            |
|    fps                  | 533        |
|    iterations           | 403        |
|    time_elapsed         | 49490      |
|    total_timesteps      | 26411008   |
| train/                  |            |
|    approx_kl            | 0.07044841 |
|    clip_fraction        | 0.0777     |
|    clip_range           | 0.16       |
|    entropy_loss         | -0.0629    |
|    explained_variance   | 0.709      |
|    learning_rate        | 7.39e-05   |
|    loss                 | 11.5       |
|    n_updates            | 1608       |
|    policy_gradient_loss | 0.00899    |
|    value_loss           | 40.5       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 786         |
|    ep_rew_mean          | 340         |
| time/                   |             |
|    fps                  | 533         |
|    iterations           | 404         |
|    time_elapsed         | 49616       |
|    total_timesteps      | 26476544    |
| train/                  |             |
|    approx_kl            | 0.076678045 |
|    clip_fraction        | 0.0715      |
|    clip_range           | 0.16        |
|    entropy_loss         | -0.0552     |
|    explained_variance   | 0.681       |
|    learning_rate        | 7.39e-05    |
|    loss                 | 16.2        |
|    n_updates            | 1612        |
|    policy_gradient_loss | 0.0127      |
|    value_loss           | 46.2        |
-----------------------------------------
Eval num_timesteps=26498304, episode_reward=-7.65 +/- 4.17
Episode length: 7.30 +/- 1.55
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 7.3        |
|    mean_reward          | -7.65      |
| time/                   |            |
|    total_timesteps      | 26498304   |
| train/                  |            |
|    approx_kl            | 0.05412239 |
|    clip_fraction        | 0.0599     |
|    clip_range           | 0.16       |
|    entropy_loss         | -0.0514    |
|    explained_variance   | 0.734      |
|    learning_rate        | 7.38e-05   |
|    loss                 | 13.6       |
|    n_updates            | 1616       |
|    policy_gradient_loss | 0.0108     |
|    value_loss           | 42.4       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 711      |
|    ep_rew_mean     | 305      |
| time/              |          |
|    fps             | 533      |
|    iterations      | 405      |
|    time_elapsed    | 49741    |
|    total_timesteps | 26542080 |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 790        |
|    ep_rew_mean          | 344        |
| time/                   |            |
|    fps                  | 533        |
|    iterations           | 406        |
|    time_elapsed         | 49867      |
|    total_timesteps      | 26607616   |
| train/                  |            |
|    approx_kl            | 0.11155387 |
|    clip_fraction        | 0.085      |
|    clip_range           | 0.16       |
|    entropy_loss         | -0.0627    |
|    explained_variance   | 0.742      |
|    learning_rate        | 7.37e-05   |
|    loss                 | 14.1       |
|    n_updates            | 1620       |
|    policy_gradient_loss | 0.0145     |
|    value_loss           | 42.4       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 756        |
|    ep_rew_mean          | 319        |
| time/                   |            |
|    fps                  | 533        |
|    iterations           | 407        |
|    time_elapsed         | 49993      |
|    total_timesteps      | 26673152   |
| train/                  |            |
|    approx_kl            | 0.09300767 |
|    clip_fraction        | 0.0692     |
|    clip_range           | 0.16       |
|    entropy_loss         | -0.0542    |
|    explained_variance   | 0.76       |
|    learning_rate        | 7.37e-05   |
|    loss                 | 12.7       |
|    n_updates            | 1624       |
|    policy_gradient_loss | 0.0113     |
|    value_loss           | 43.5       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 797         |
|    ep_rew_mean          | 330         |
| time/                   |             |
|    fps                  | 533         |
|    iterations           | 408         |
|    time_elapsed         | 50121       |
|    total_timesteps      | 26738688    |
| train/                  |             |
|    approx_kl            | 0.082821086 |
|    clip_fraction        | 0.075       |
|    clip_range           | 0.16        |
|    entropy_loss         | -0.0575     |
|    explained_variance   | 0.715       |
|    learning_rate        | 7.36e-05    |
|    loss                 | 11.6        |
|    n_updates            | 1628        |
|    policy_gradient_loss | 0.0135      |
|    value_loss           | 42.6        |
-----------------------------------------
Eval num_timesteps=26748288, episode_reward=-7.72 +/- 4.47
Episode length: 8.70 +/- 6.93
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 8.7        |
|    mean_reward          | -7.72      |
| time/                   |            |
|    total_timesteps      | 26748288   |
| train/                  |            |
|    approx_kl            | 0.05939674 |
|    clip_fraction        | 0.0655     |
|    clip_range           | 0.16       |
|    entropy_loss         | -0.0524    |
|    explained_variance   | 0.721      |
|    learning_rate        | 7.35e-05   |
|    loss                 | 12.4       |
|    n_updates            | 1632       |
|    policy_gradient_loss | 0.0105     |
|    value_loss           | 43.9       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 739      |
|    ep_rew_mean     | 305      |
| time/              |          |
|    fps             | 533      |
|    iterations      | 409      |
|    time_elapsed    | 50231    |
|    total_timesteps | 26804224 |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 763         |
|    ep_rew_mean          | 363         |
| time/                   |             |
|    fps                  | 533         |
|    iterations           | 410         |
|    time_elapsed         | 50351       |
|    total_timesteps      | 26869760    |
| train/                  |             |
|    approx_kl            | 0.058828548 |
|    clip_fraction        | 0.0637      |
|    clip_range           | 0.16        |
|    entropy_loss         | -0.052      |
|    explained_variance   | 0.735       |
|    learning_rate        | 7.35e-05    |
|    loss                 | 14          |
|    n_updates            | 1636        |
|    policy_gradient_loss | 0.0124      |
|    value_loss           | 47          |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 790        |
|    ep_rew_mean          | 395        |
| time/                   |            |
|    fps                  | 533        |
|    iterations           | 411        |
|    time_elapsed         | 50472      |
|    total_timesteps      | 26935296   |
| train/                  |            |
|    approx_kl            | 0.07933101 |
|    clip_fraction        | 0.0718     |
|    clip_range           | 0.16       |
|    entropy_loss         | -0.0552    |
|    explained_variance   | 0.721      |
|    learning_rate        | 7.34e-05   |
|    loss                 | 15.9       |
|    n_updates            | 1640       |
|    policy_gradient_loss | 0.0113     |
|    value_loss           | 48.7       |
----------------------------------------
Eval num_timesteps=26998272, episode_reward=-6.97 +/- 4.54
Episode length: 10.40 +/- 7.99
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 10.4      |
|    mean_reward          | -6.97     |
| time/                   |           |
|    total_timesteps      | 26998272  |
| train/                  |           |
|    approx_kl            | 0.0675633 |
|    clip_fraction        | 0.0644    |
|    clip_range           | 0.16      |
|    entropy_loss         | -0.0496   |
|    explained_variance   | 0.747     |
|    learning_rate        | 7.33e-05  |
|    loss                 | 12.8      |
|    n_updates            | 1644      |
|    policy_gradient_loss | 0.00984   |
|    value_loss           | 45.4      |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 688      |
|    ep_rew_mean     | 323      |
| time/              |          |
|    fps             | 533      |
|    iterations      | 412      |
|    time_elapsed    | 50598    |
|    total_timesteps | 27000832 |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 704        |
|    ep_rew_mean          | 323        |
| time/                   |            |
|    fps                  | 533        |
|    iterations           | 413        |
|    time_elapsed         | 50726      |
|    total_timesteps      | 27066368   |
| train/                  |            |
|    approx_kl            | 0.06586005 |
|    clip_fraction        | 0.0657     |
|    clip_range           | 0.159      |
|    entropy_loss         | -0.0518    |
|    explained_variance   | 0.784      |
|    learning_rate        | 7.33e-05   |
|    loss                 | 15.4       |
|    n_updates            | 1648       |
|    policy_gradient_loss | 0.0121     |
|    value_loss           | 46.8       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 769         |
|    ep_rew_mean          | 394         |
| time/                   |             |
|    fps                  | 533         |
|    iterations           | 414         |
|    time_elapsed         | 50853       |
|    total_timesteps      | 27131904    |
| train/                  |             |
|    approx_kl            | 0.060831986 |
|    clip_fraction        | 0.0618      |
|    clip_range           | 0.159       |
|    entropy_loss         | -0.0482     |
|    explained_variance   | 0.748       |
|    learning_rate        | 7.32e-05    |
|    loss                 | 17.4        |
|    n_updates            | 1652        |
|    policy_gradient_loss | 0.0129      |
|    value_loss           | 50.1        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 727         |
|    ep_rew_mean          | 331         |
| time/                   |             |
|    fps                  | 533         |
|    iterations           | 415         |
|    time_elapsed         | 50980       |
|    total_timesteps      | 27197440    |
| train/                  |             |
|    approx_kl            | 0.080752656 |
|    clip_fraction        | 0.0771      |
|    clip_range           | 0.159       |
|    entropy_loss         | -0.0551     |
|    explained_variance   | 0.735       |
|    learning_rate        | 7.31e-05    |
|    loss                 | 16.9        |
|    n_updates            | 1656        |
|    policy_gradient_loss | 0.0157      |
|    value_loss           | 50.6        |
-----------------------------------------
Eval num_timesteps=27248256, episode_reward=-8.25 +/- 4.40
Episode length: 7.00 +/- 1.55
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 7          |
|    mean_reward          | -8.25      |
| time/                   |            |
|    total_timesteps      | 27248256   |
| train/                  |            |
|    approx_kl            | 0.08798495 |
|    clip_fraction        | 0.0739     |
|    clip_range           | 0.159      |
|    entropy_loss         | -0.0557    |
|    explained_variance   | 0.731      |
|    learning_rate        | 7.31e-05   |
|    loss                 | 14.4       |
|    n_updates            | 1660       |
|    policy_gradient_loss | 0.0141     |
|    value_loss           | 48.3       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 744      |
|    ep_rew_mean     | 309      |
| time/              |          |
|    fps             | 533      |
|    iterations      | 416      |
|    time_elapsed    | 51110    |
|    total_timesteps | 27262976 |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 843         |
|    ep_rew_mean          | 389         |
| time/                   |             |
|    fps                  | 533         |
|    iterations           | 417         |
|    time_elapsed         | 51238       |
|    total_timesteps      | 27328512    |
| train/                  |             |
|    approx_kl            | 0.065164715 |
|    clip_fraction        | 0.064       |
|    clip_range           | 0.159       |
|    entropy_loss         | -0.0513     |
|    explained_variance   | 0.753       |
|    learning_rate        | 7.3e-05     |
|    loss                 | 13.2        |
|    n_updates            | 1664        |
|    policy_gradient_loss | 0.0109      |
|    value_loss           | 44          |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 822        |
|    ep_rew_mean          | 396        |
| time/                   |            |
|    fps                  | 533        |
|    iterations           | 418        |
|    time_elapsed         | 51367      |
|    total_timesteps      | 27394048   |
| train/                  |            |
|    approx_kl            | 0.07842265 |
|    clip_fraction        | 0.0617     |
|    clip_range           | 0.159      |
|    entropy_loss         | -0.0449    |
|    explained_variance   | 0.74       |
|    learning_rate        | 7.29e-05   |
|    loss                 | 14.2       |
|    n_updates            | 1668       |
|    policy_gradient_loss | 0.0121     |
|    value_loss           | 50.1       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 798         |
|    ep_rew_mean          | 354         |
| time/                   |             |
|    fps                  | 533         |
|    iterations           | 419         |
|    time_elapsed         | 51495       |
|    total_timesteps      | 27459584    |
| train/                  |             |
|    approx_kl            | 0.073793754 |
|    clip_fraction        | 0.0671      |
|    clip_range           | 0.159       |
|    entropy_loss         | -0.0514     |
|    explained_variance   | 0.662       |
|    learning_rate        | 7.29e-05    |
|    loss                 | 15.8        |
|    n_updates            | 1672        |
|    policy_gradient_loss | 0.0122      |
|    value_loss           | 48.9        |
-----------------------------------------
Eval num_timesteps=27498240, episode_reward=-10.01 +/- 4.89
Episode length: 63.60 +/- 171.14
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 63.6       |
|    mean_reward          | -10        |
| time/                   |            |
|    total_timesteps      | 27498240   |
| train/                  |            |
|    approx_kl            | 0.07179297 |
|    clip_fraction        | 0.057      |
|    clip_range           | 0.159      |
|    entropy_loss         | -0.0455    |
|    explained_variance   | 0.758      |
|    learning_rate        | 7.28e-05   |
|    loss                 | 13.1       |
|    n_updates            | 1676       |
|    policy_gradient_loss | 0.0108     |
|    value_loss           | 47.3       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 770      |
|    ep_rew_mean     | 323      |
| time/              |          |
|    fps             | 533      |
|    iterations      | 420      |
|    time_elapsed    | 51631    |
|    total_timesteps | 27525120 |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 808        |
|    ep_rew_mean          | 353        |
| time/                   |            |
|    fps                  | 533        |
|    iterations           | 421        |
|    time_elapsed         | 51759      |
|    total_timesteps      | 27590656   |
| train/                  |            |
|    approx_kl            | 0.07023181 |
|    clip_fraction        | 0.061      |
|    clip_range           | 0.159      |
|    entropy_loss         | -0.0449    |
|    explained_variance   | 0.743      |
|    learning_rate        | 7.28e-05   |
|    loss                 | 11.3       |
|    n_updates            | 1680       |
|    policy_gradient_loss | 0.0161     |
|    value_loss           | 41.6       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 786        |
|    ep_rew_mean          | 320        |
| time/                   |            |
|    fps                  | 532        |
|    iterations           | 422        |
|    time_elapsed         | 51890      |
|    total_timesteps      | 27656192   |
| train/                  |            |
|    approx_kl            | 0.07375708 |
|    clip_fraction        | 0.0653     |
|    clip_range           | 0.159      |
|    entropy_loss         | -0.0481    |
|    explained_variance   | 0.729      |
|    learning_rate        | 7.27e-05   |
|    loss                 | 14.6       |
|    n_updates            | 1684       |
|    policy_gradient_loss | 0.0142     |
|    value_loss           | 46.1       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 796         |
|    ep_rew_mean          | 301         |
| time/                   |             |
|    fps                  | 532         |
|    iterations           | 423         |
|    time_elapsed         | 52021       |
|    total_timesteps      | 27721728    |
| train/                  |             |
|    approx_kl            | 0.075403064 |
|    clip_fraction        | 0.0674      |
|    clip_range           | 0.159       |
|    entropy_loss         | -0.0543     |
|    explained_variance   | 0.723       |
|    learning_rate        | 7.26e-05    |
|    loss                 | 14.1        |
|    n_updates            | 1688        |
|    policy_gradient_loss | 0.0132      |
|    value_loss           | 42.5        |
-----------------------------------------
Eval num_timesteps=27748224, episode_reward=-10.13 +/- 0.48
Episode length: 7.50 +/- 1.57
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 7.5        |
|    mean_reward          | -10.1      |
| time/                   |            |
|    total_timesteps      | 27748224   |
| train/                  |            |
|    approx_kl            | 0.07196872 |
|    clip_fraction        | 0.0758     |
|    clip_range           | 0.158      |
|    entropy_loss         | -0.0445    |
|    explained_variance   | 0.738      |
|    learning_rate        | 7.26e-05   |
|    loss                 | 11.1       |
|    n_updates            | 1692       |
|    policy_gradient_loss | 0.0188     |
|    value_loss           | 40.2       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 850      |
|    ep_rew_mean     | 366      |
| time/              |          |
|    fps             | 532      |
|    iterations      | 424      |
|    time_elapsed    | 52155    |
|    total_timesteps | 27787264 |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 838        |
|    ep_rew_mean          | 415        |
| time/                   |            |
|    fps                  | 532        |
|    iterations           | 425        |
|    time_elapsed         | 52286      |
|    total_timesteps      | 27852800   |
| train/                  |            |
|    approx_kl            | 0.07919723 |
|    clip_fraction        | 0.0644     |
|    clip_range           | 0.158      |
|    entropy_loss         | -0.0489    |
|    explained_variance   | 0.707      |
|    learning_rate        | 7.25e-05   |
|    loss                 | 13.9       |
|    n_updates            | 1696       |
|    policy_gradient_loss | 0.0142     |
|    value_loss           | 46.3       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 784         |
|    ep_rew_mean          | 381         |
| time/                   |             |
|    fps                  | 532         |
|    iterations           | 426         |
|    time_elapsed         | 52411       |
|    total_timesteps      | 27918336    |
| train/                  |             |
|    approx_kl            | 0.067126036 |
|    clip_fraction        | 0.0601      |
|    clip_range           | 0.158       |
|    entropy_loss         | -0.0443     |
|    explained_variance   | 0.727       |
|    learning_rate        | 7.24e-05    |
|    loss                 | 14.8        |
|    n_updates            | 1700        |
|    policy_gradient_loss | 0.0197      |
|    value_loss           | 47.6        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 800        |
|    ep_rew_mean          | 363        |
| time/                   |            |
|    fps                  | 532        |
|    iterations           | 427        |
|    time_elapsed         | 52545      |
|    total_timesteps      | 27983872   |
| train/                  |            |
|    approx_kl            | 0.08568895 |
|    clip_fraction        | 0.0781     |
|    clip_range           | 0.158      |
|    entropy_loss         | -0.0495    |
|    explained_variance   | 0.711      |
|    learning_rate        | 7.24e-05   |
|    loss                 | 12.6       |
|    n_updates            | 1704       |
|    policy_gradient_loss | 0.0186     |
|    value_loss           | 44.5       |
----------------------------------------
Eval num_timesteps=27998208, episode_reward=-10.09 +/- 0.35
Episode length: 7.90 +/- 2.34
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 7.9        |
|    mean_reward          | -10.1      |
| time/                   |            |
|    total_timesteps      | 27998208   |
| train/                  |            |
|    approx_kl            | 0.06930413 |
|    clip_fraction        | 0.06       |
|    clip_range           | 0.158      |
|    entropy_loss         | -0.0444    |
|    explained_variance   | 0.74       |
|    learning_rate        | 7.23e-05   |
|    loss                 | 13.6       |
|    n_updates            | 1708       |
|    policy_gradient_loss | 0.0103     |
|    value_loss           | 47.8       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 796      |
|    ep_rew_mean     | 384      |
| time/              |          |
|    fps             | 532      |
|    iterations      | 428      |
|    time_elapsed    | 52669    |
|    total_timesteps | 28049408 |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 792       |
|    ep_rew_mean          | 381       |
| time/                   |           |
|    fps                  | 532       |
|    iterations           | 429       |
|    time_elapsed         | 52797     |
|    total_timesteps      | 28114944  |
| train/                  |           |
|    approx_kl            | 0.0753293 |
|    clip_fraction        | 0.0649    |
|    clip_range           | 0.158     |
|    entropy_loss         | -0.0413   |
|    explained_variance   | 0.766     |
|    learning_rate        | 7.22e-05  |
|    loss                 | 17.6      |
|    n_updates            | 1712      |
|    policy_gradient_loss | 0.0166    |
|    value_loss           | 49.4      |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 809        |
|    ep_rew_mean          | 369        |
| time/                   |            |
|    fps                  | 532        |
|    iterations           | 430        |
|    time_elapsed         | 52929      |
|    total_timesteps      | 28180480   |
| train/                  |            |
|    approx_kl            | 0.06892164 |
|    clip_fraction        | 0.0589     |
|    clip_range           | 0.158      |
|    entropy_loss         | -0.0474    |
|    explained_variance   | 0.777      |
|    learning_rate        | 7.22e-05   |
|    loss                 | 15.3       |
|    n_updates            | 1716       |
|    policy_gradient_loss | 0.0106     |
|    value_loss           | 48.1       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 747        |
|    ep_rew_mean          | 326        |
| time/                   |            |
|    fps                  | 532        |
|    iterations           | 431        |
|    time_elapsed         | 53061      |
|    total_timesteps      | 28246016   |
| train/                  |            |
|    approx_kl            | 0.06430518 |
|    clip_fraction        | 0.0558     |
|    clip_range           | 0.158      |
|    entropy_loss         | -0.0439    |
|    explained_variance   | 0.722      |
|    learning_rate        | 7.21e-05   |
|    loss                 | 10.4       |
|    n_updates            | 1720       |
|    policy_gradient_loss | 0.0127     |
|    value_loss           | 43.6       |
----------------------------------------
Eval num_timesteps=28248192, episode_reward=-5.98 +/- 7.67
Episode length: 9.80 +/- 5.06
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 9.8        |
|    mean_reward          | -5.98      |
| time/                   |            |
|    total_timesteps      | 28248192   |
| train/                  |            |
|    approx_kl            | 0.08197896 |
|    clip_fraction        | 0.0576     |
|    clip_range           | 0.158      |
|    entropy_loss         | -0.0458    |
|    explained_variance   | 0.767      |
|    learning_rate        | 7.2e-05    |
|    loss                 | 17.3       |
|    n_updates            | 1724       |
|    policy_gradient_loss | 0.0101     |
|    value_loss           | 47.2       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 747      |
|    ep_rew_mean     | 331      |
| time/              |          |
|    fps             | 532      |
|    iterations      | 432      |
|    time_elapsed    | 53193    |
|    total_timesteps | 28311552 |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 725        |
|    ep_rew_mean          | 366        |
| time/                   |            |
|    fps                  | 532        |
|    iterations           | 433        |
|    time_elapsed         | 53323      |
|    total_timesteps      | 28377088   |
| train/                  |            |
|    approx_kl            | 0.05187983 |
|    clip_fraction        | 0.0541     |
|    clip_range           | 0.158      |
|    entropy_loss         | -0.0436    |
|    explained_variance   | 0.738      |
|    learning_rate        | 7.2e-05    |
|    loss                 | 14.4       |
|    n_updates            | 1728       |
|    policy_gradient_loss | 0.0125     |
|    value_loss           | 47.4       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 810        |
|    ep_rew_mean          | 414        |
| time/                   |            |
|    fps                  | 531        |
|    iterations           | 434        |
|    time_elapsed         | 53504      |
|    total_timesteps      | 28442624   |
| train/                  |            |
|    approx_kl            | 0.08392115 |
|    clip_fraction        | 0.0658     |
|    clip_range           | 0.157      |
|    entropy_loss         | -0.0487    |
|    explained_variance   | 0.714      |
|    learning_rate        | 7.19e-05   |
|    loss                 | 17.2       |
|    n_updates            | 1732       |
|    policy_gradient_loss | 0.0142     |
|    value_loss           | 50.6       |
----------------------------------------
Eval num_timesteps=28498176, episode_reward=-7.76 +/- 4.52
Episode length: 7.50 +/- 1.02
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 7.5         |
|    mean_reward          | -7.76       |
| time/                   |             |
|    total_timesteps      | 28498176    |
| train/                  |             |
|    approx_kl            | 0.074470185 |
|    clip_fraction        | 0.0637      |
|    clip_range           | 0.157       |
|    entropy_loss         | -0.049      |
|    explained_variance   | 0.632       |
|    learning_rate        | 7.18e-05    |
|    loss                 | 14.6        |
|    n_updates            | 1736        |
|    policy_gradient_loss | 0.0132      |
|    value_loss           | 50.7        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 860      |
|    ep_rew_mean     | 378      |
| time/              |          |
|    fps             | 531      |
|    iterations      | 435      |
|    time_elapsed    | 53677    |
|    total_timesteps | 28508160 |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 845        |
|    ep_rew_mean          | 365        |
| time/                   |            |
|    fps                  | 530        |
|    iterations           | 436        |
|    time_elapsed         | 53867      |
|    total_timesteps      | 28573696   |
| train/                  |            |
|    approx_kl            | 0.08660543 |
|    clip_fraction        | 0.071      |
|    clip_range           | 0.157      |
|    entropy_loss         | -0.0512    |
|    explained_variance   | 0.666      |
|    learning_rate        | 7.18e-05   |
|    loss                 | 12.6       |
|    n_updates            | 1740       |
|    policy_gradient_loss | 0.0142     |
|    value_loss           | 45.4       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 828         |
|    ep_rew_mean          | 359         |
| time/                   |             |
|    fps                  | 529         |
|    iterations           | 437         |
|    time_elapsed         | 54044       |
|    total_timesteps      | 28639232    |
| train/                  |             |
|    approx_kl            | 0.083870366 |
|    clip_fraction        | 0.0713      |
|    clip_range           | 0.157       |
|    entropy_loss         | -0.0547     |
|    explained_variance   | 0.723       |
|    learning_rate        | 7.17e-05    |
|    loss                 | 14.9        |
|    n_updates            | 1744        |
|    policy_gradient_loss | 0.01        |
|    value_loss           | 42.9        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 843        |
|    ep_rew_mean          | 377        |
| time/                   |            |
|    fps                  | 529        |
|    iterations           | 438        |
|    time_elapsed         | 54199      |
|    total_timesteps      | 28704768   |
| train/                  |            |
|    approx_kl            | 0.12563287 |
|    clip_fraction        | 0.0935     |
|    clip_range           | 0.157      |
|    entropy_loss         | -0.0559    |
|    explained_variance   | 0.71       |
|    learning_rate        | 7.16e-05   |
|    loss                 | 12.6       |
|    n_updates            | 1748       |
|    policy_gradient_loss | 0.0188     |
|    value_loss           | 43.3       |
----------------------------------------
Eval num_timesteps=28748160, episode_reward=-7.95 +/- 4.31
Episode length: 9.50 +/- 4.61
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 9.5        |
|    mean_reward          | -7.95      |
| time/                   |            |
|    total_timesteps      | 28748160   |
| train/                  |            |
|    approx_kl            | 0.07538383 |
|    clip_fraction        | 0.0631     |
|    clip_range           | 0.157      |
|    entropy_loss         | -0.05      |
|    explained_variance   | 0.727      |
|    learning_rate        | 7.16e-05   |
|    loss                 | 15.3       |
|    n_updates            | 1752       |
|    policy_gradient_loss | 0.012      |
|    value_loss           | 45.5       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 765      |
|    ep_rew_mean     | 365      |
| time/              |          |
|    fps             | 529      |
|    iterations      | 439      |
|    time_elapsed    | 54374    |
|    total_timesteps | 28770304 |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 789        |
|    ep_rew_mean          | 369        |
| time/                   |            |
|    fps                  | 528        |
|    iterations           | 440        |
|    time_elapsed         | 54547      |
|    total_timesteps      | 28835840   |
| train/                  |            |
|    approx_kl            | 0.06591921 |
|    clip_fraction        | 0.0639     |
|    clip_range           | 0.157      |
|    entropy_loss         | -0.0488    |
|    explained_variance   | 0.683      |
|    learning_rate        | 7.15e-05   |
|    loss                 | 14.9       |
|    n_updates            | 1756       |
|    policy_gradient_loss | 0.012      |
|    value_loss           | 45.4       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 788         |
|    ep_rew_mean          | 367         |
| time/                   |             |
|    fps                  | 528         |
|    iterations           | 441         |
|    time_elapsed         | 54698       |
|    total_timesteps      | 28901376    |
| train/                  |             |
|    approx_kl            | 0.082334846 |
|    clip_fraction        | 0.0622      |
|    clip_range           | 0.157       |
|    entropy_loss         | -0.0447     |
|    explained_variance   | 0.659       |
|    learning_rate        | 7.15e-05    |
|    loss                 | 13.9        |
|    n_updates            | 1760        |
|    policy_gradient_loss | 0.0136      |
|    value_loss           | 46          |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 757       |
|    ep_rew_mean          | 346       |
| time/                   |           |
|    fps                  | 527       |
|    iterations           | 442       |
|    time_elapsed         | 54863     |
|    total_timesteps      | 28966912  |
| train/                  |           |
|    approx_kl            | 0.0582392 |
|    clip_fraction        | 0.0538    |
|    clip_range           | 0.157     |
|    entropy_loss         | -0.043    |
|    explained_variance   | 0.735     |
|    learning_rate        | 7.14e-05  |
|    loss                 | 10.5      |
|    n_updates            | 1764      |
|    policy_gradient_loss | 0.00989   |
|    value_loss           | 42.1      |
---------------------------------------
Eval num_timesteps=28998144, episode_reward=-9.01 +/- 3.41
Episode length: 8.30 +/- 3.47
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 8.3        |
|    mean_reward          | -9.01      |
| time/                   |            |
|    total_timesteps      | 28998144   |
| train/                  |            |
|    approx_kl            | 0.05667133 |
|    clip_fraction        | 0.0543     |
|    clip_range           | 0.157      |
|    entropy_loss         | -0.0419    |
|    explained_variance   | 0.745      |
|    learning_rate        | 7.13e-05   |
|    loss                 | 16.9       |
|    n_updates            | 1768       |
|    policy_gradient_loss | 0.011      |
|    value_loss           | 44.9       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 781      |
|    ep_rew_mean     | 380      |
| time/              |          |
|    fps             | 527      |
|    iterations      | 443      |
|    time_elapsed    | 55032    |
|    total_timesteps | 29032448 |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 781        |
|    ep_rew_mean          | 361        |
| time/                   |            |
|    fps                  | 526        |
|    iterations           | 444        |
|    time_elapsed         | 55214      |
|    total_timesteps      | 29097984   |
| train/                  |            |
|    approx_kl            | 0.05459258 |
|    clip_fraction        | 0.0531     |
|    clip_range           | 0.156      |
|    entropy_loss         | -0.0408    |
|    explained_variance   | 0.758      |
|    learning_rate        | 7.13e-05   |
|    loss                 | 15.5       |
|    n_updates            | 1772       |
|    policy_gradient_loss | 0.0105     |
|    value_loss           | 47.6       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 780        |
|    ep_rew_mean          | 382        |
| time/                   |            |
|    fps                  | 526        |
|    iterations           | 445        |
|    time_elapsed         | 55372      |
|    total_timesteps      | 29163520   |
| train/                  |            |
|    approx_kl            | 0.07761319 |
|    clip_fraction        | 0.0726     |
|    clip_range           | 0.156      |
|    entropy_loss         | -0.0508    |
|    explained_variance   | 0.713      |
|    learning_rate        | 7.12e-05   |
|    loss                 | 12.1       |
|    n_updates            | 1776       |
|    policy_gradient_loss | 0.0147     |
|    value_loss           | 42.9       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 797        |
|    ep_rew_mean          | 342        |
| time/                   |            |
|    fps                  | 526        |
|    iterations           | 446        |
|    time_elapsed         | 55517      |
|    total_timesteps      | 29229056   |
| train/                  |            |
|    approx_kl            | 0.07335388 |
|    clip_fraction        | 0.0686     |
|    clip_range           | 0.156      |
|    entropy_loss         | -0.0498    |
|    explained_variance   | 0.673      |
|    learning_rate        | 7.11e-05   |
|    loss                 | 15.3       |
|    n_updates            | 1780       |
|    policy_gradient_loss | 0.0129     |
|    value_loss           | 48.2       |
----------------------------------------
Eval num_timesteps=29248128, episode_reward=-8.32 +/- 4.31
Episode length: 10.90 +/- 7.96
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 10.9       |
|    mean_reward          | -8.32      |
| time/                   |            |
|    total_timesteps      | 29248128   |
| train/                  |            |
|    approx_kl            | 0.06016745 |
|    clip_fraction        | 0.0549     |
|    clip_range           | 0.156      |
|    entropy_loss         | -0.0434    |
|    explained_variance   | 0.718      |
|    learning_rate        | 7.11e-05   |
|    loss                 | 15         |
|    n_updates            | 1784       |
|    policy_gradient_loss | 0.00864    |
|    value_loss           | 47         |
----------------------------------------
