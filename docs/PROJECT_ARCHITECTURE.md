# Snake AI Project Architecture / è´ªåƒè›‡AIé¡¹ç›®æ¶æ„

## é¡¹ç›®æ¦‚è¿° / Project Overview

è¿™æ˜¯ä¸€ä¸ªåŸºäºå¼ºåŒ–å­¦ä¹ ï¼ˆReinforcement Learningï¼‰çš„è´ªåƒè›‡AIé¡¹ç›®ï¼Œä½¿ç”¨ PPO (Proximal Policy Optimization) ç®—æ³•è®­ç»ƒæ™ºèƒ½ä½“ã€‚

This is a Snake AI project based on Reinforcement Learning, using PPO (Proximal Policy Optimization) algorithm to train agents.

---

## æ ¸å¿ƒæ¶æ„ / Core Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     Snake AI System                          â”‚
â”‚                    è´ªåƒè›‡AIç³»ç»Ÿ                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                   â”‚                   â”‚
   â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”
   â”‚  Game   â”‚        â”‚ Wrapper â”‚        â”‚ Trainingâ”‚
   â”‚  Core   â”‚        â”‚  Layer  â”‚        â”‚  Layer  â”‚
   â”‚ æ¸¸æˆæ ¸å¿ƒ â”‚        â”‚ åŒ…è£…å±‚   â”‚        â”‚ è®­ç»ƒå±‚   â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## æ–‡ä»¶ç»“æ„ä¸åŠŸèƒ½ / File Structure and Functions

### 1ï¸âƒ£ æ¸¸æˆæ ¸å¿ƒå±‚ / Game Core Layer

#### `snake_game.py` ğŸ®
**åŠŸèƒ½ / Function:**
- å®ç°åŸºç¡€è´ªåƒè›‡æ¸¸æˆé€»è¾‘
- å¤„ç†æ¸¸æˆçŠ¶æ€ã€ç¢°æ’æ£€æµ‹ã€é£Ÿç‰©ç”Ÿæˆ
- æä¾›å¯è§†åŒ–æ¸²æŸ“ï¼ˆPygameï¼‰

**æ ¸å¿ƒç±» / Core Class:**
```python
class SnakeGame:
    - __init__(): åˆå§‹åŒ–æ¸¸æˆ
    - reset(): é‡ç½®æ¸¸æˆçŠ¶æ€
    - step(action): æ‰§è¡ŒåŠ¨ä½œï¼Œè¿”å›æ¸¸æˆçŠ¶æ€
    - render(): æ¸²æŸ“æ¸¸æˆç”»é¢
```

**ä¾èµ– / Dependencies:**
- `pygame`: æ¸¸æˆæ¸²æŸ“
- `numpy`: æ•°å€¼è®¡ç®—

**è¢«è°ƒç”¨ / Called by:**
- æ‰€æœ‰ wrapper æ–‡ä»¶

---

### 2ï¸âƒ£ ç¯å¢ƒåŒ…è£…å±‚ / Environment Wrapper Layer

è¿™ä¸€å±‚å°†æ¸¸æˆåŒ…è£…æˆç¬¦åˆ Gymnasium æ ‡å‡†çš„å¼ºåŒ–å­¦ä¹ ç¯å¢ƒã€‚

#### `snake_game_custom_wrapper_cnn.py` ğŸ“¸
**åŠŸèƒ½ / Function:**
- CNNç‰ˆæœ¬çš„ç¯å¢ƒåŒ…è£…å™¨ï¼ˆåŸå§‹ç‰ˆæœ¬ï¼‰
- è§‚å¯Ÿç©ºé—´ï¼š84Ã—84Ã—3 çš„RGBå›¾åƒ
- å¥–åŠ±å‡½æ•°ï¼šåŸºäºè·ç¦»å’Œé£Ÿç‰©è·å–

**è§‚å¯Ÿç©ºé—´ / Observation Space:**
```python
Box(low=0, high=255, shape=(84, 84, 3), dtype=uint8)
```

**å¥–åŠ±è®¾è®¡ / Reward Design:**
- åƒåˆ°é£Ÿç‰©ï¼š`snake_size / grid_size`
- é è¿‘é£Ÿç‰©ï¼š`+0.1 / snake_size`
- è¿œç¦»é£Ÿç‰©ï¼š`-0.1 / snake_size`
- æ­»äº¡ï¼š`-pow(max_growth, remaining / max_growth) * 0.1`

**è¢«ä½¿ç”¨ / Used by:**
- `train_cnn.py`
- `test_cnn.py`

---

#### `snake_game_custom_wrapper_cnn_v2.py` ğŸ“¸âœ¨ (æ”¹è¿›ç‰ˆ)
**åŠŸèƒ½ / Function:**
- CNNç‰ˆæœ¬çš„æ”¹è¿›ç¯å¢ƒåŒ…è£…å™¨
- **æ”¹è¿›çš„å¥–åŠ±å‡½æ•°**ï¼Œå­¦ä¹ é€Ÿåº¦æ›´å¿«
- ä½¿ç”¨æ›¼å“ˆé¡¿è·ç¦»æ›¿ä»£æ¬§æ°è·ç¦»

**å…³é”®æ”¹è¿› / Key Improvements:**
```python
# åƒåˆ°é£Ÿç‰© / Food obtained
reward = 10.0 + (snake_size - init_size) * 0.5  # æ›´å¤§çš„å¥–åŠ±

# é è¿‘é£Ÿç‰© / Moving closer
reward = +0.1  # å›ºå®šæ­£å¥–åŠ±

# è¿œç¦»é£Ÿç‰© / Moving away
reward = -0.15  # æ›´å¤§çš„æƒ©ç½š

# æ­»äº¡ / Death
reward = -10.0 * (1.0 - progress)  # æ ¹æ®è¿›åº¦ç¼©æ”¾

# èƒœåˆ© / Victory
reward = 100.0  # å¤§å¥–åŠ±
```

**è¢«ä½¿ç”¨ / Used by:**
- `train_cnn_v2.py`
- `train_cnn_simple.py`
- `train_cnn_curriculum.py`
- `test_cnn_v2.py`

---

#### `snake_game_custom_wrapper_mlp.py` ğŸ§ 
**åŠŸèƒ½ / Function:**
- MLPç‰ˆæœ¬çš„ç¯å¢ƒåŒ…è£…å™¨
- è§‚å¯Ÿç©ºé—´ï¼š13ç»´ç‰¹å¾å‘é‡
- æ›´å¿«çš„è®­ç»ƒé€Ÿåº¦ï¼Œä½†å¯èƒ½æ€§èƒ½ç•¥ä½

**è§‚å¯Ÿç©ºé—´ / Observation Space:**
```python
Box(low=0, high=board_size, shape=(13,), dtype=float32)

ç‰¹å¾ / Features:
[0-1]   è›‡å¤´ä½ç½® (x, y)
[2-3]   é£Ÿç‰©ä½ç½® (x, y)
[4]     è›‡é•¿åº¦
[5-8]   å±é™©æ£€æµ‹ (ä¸Šä¸‹å·¦å³)
[9-12]  é£Ÿç‰©æ–¹å‘ (ä¸Šä¸‹å·¦å³)
```

**è¢«ä½¿ç”¨ / Used by:**
- `train_mlp.py`
- `test_mlp.py`

---

### 3ï¸âƒ£ è®­ç»ƒå±‚ / Training Layer

#### `train_config.py` âš™ï¸ (é…ç½®ä¸­å¿ƒ)
**åŠŸèƒ½ / Function:**
- é›†ä¸­ç®¡ç†æ‰€æœ‰è®­ç»ƒè¶…å‚æ•°
- æä¾›é…ç½®æ‘˜è¦å’Œæ€§èƒ½å»ºè®®
- ä¾¿äºå¿«é€Ÿè°ƒæ•´è®­ç»ƒè®¾ç½®

**æ ¸å¿ƒé…ç½® / Core Configurations:**
```python
NUM_ENV: å¹¶è¡Œç¯å¢ƒæ•°é‡ (16/32/64)
TOTAL_TIMESTEPS: æ€»è®­ç»ƒæ­¥æ•° (100M)
BATCH_SIZE: æ‰¹æ¬¡å¤§å° (512/1024)
LEARNING_RATE: å­¦ä¹ ç‡ (3e-4 â†’ 1e-6)
GAMMA: æŠ˜æ‰£å› å­ (0.99)
ENT_COEF: ç†µç³»æ•° (0.01)
```

**è¢«ä½¿ç”¨ / Used by:**
- `train_cnn_simple.py`

---

#### `train_cnn.py` ğŸš‚ (åŸå§‹è®­ç»ƒ)
**åŠŸèƒ½ / Function:**
- åŸå§‹CNNæ¨¡å‹è®­ç»ƒè„šæœ¬
- ä½¿ç”¨ `snake_game_custom_wrapper_cnn.py`
- åŸºå‡†æ€§èƒ½å‚è€ƒ

**è®­ç»ƒé…ç½® / Training Config:**
- ç¯å¢ƒæ•°ï¼š32 (CPU) / 64 (GPU/MPS)
- æ€»æ­¥æ•°ï¼š100M
- å­¦ä¹ ç‡ï¼š2.5e-4 â†’ 2.5e-6
- Gamma: 0.94

**è¾“å‡º / Output:**
- æ¨¡å‹ï¼š`trained_models_cnn/`
- æ—¥å¿—ï¼š`logs/PPO_CNN/`

---

#### `train_cnn_v2.py` ğŸš‚âœ¨ (æ”¹è¿›è®­ç»ƒ)
**åŠŸèƒ½ / Function:**
- æ”¹è¿›çš„CNNæ¨¡å‹è®­ç»ƒè„šæœ¬
- ä½¿ç”¨ `snake_game_custom_wrapper_cnn_v2.py`
- **æ›´å¥½çš„è¶…å‚æ•°å’Œå¥–åŠ±å‡½æ•°**

**è®­ç»ƒé…ç½® / Training Config:**
- ç¯å¢ƒæ•°ï¼š64 (GPU/MPS)
- æ€»æ­¥æ•°ï¼š100M
- å­¦ä¹ ç‡ï¼š3e-4 â†’ 1e-6
- Gamma: 0.99 (æ›´é«˜)
- N_epochs: 10 (æ›´å¤š)
- æ·»åŠ è¯„ä¼°å›è°ƒ

**å…³é”®æ”¹è¿› / Key Improvements:**
- âœ… æ›´é«˜çš„ gamma (é•¿æœŸè§„åˆ’)
- âœ… æ›´å¤šçš„è®­ç»ƒè½®æ•°
- âœ… è¯„ä¼°å›è°ƒè‡ªåŠ¨ä¿å­˜æœ€ä½³æ¨¡å‹
- âœ… æ”¹è¿›çš„å¥–åŠ±å¡‘å½¢

**è¾“å‡º / Output:**
- æ¨¡å‹ï¼š`trained_models_cnn_v2_{device}/`
- æ—¥å¿—ï¼š`logs/PPO_CNN_V2/`

---

#### `train_cnn_simple.py` ğŸš‚ğŸ¯ (ç®€åŒ–è®­ç»ƒ)
**åŠŸèƒ½ / Function:**
- ä½¿ç”¨ `train_config.py` çš„ç®€åŒ–è®­ç»ƒè„šæœ¬
- äº¤äº’å¼ç¡®è®¤è®­ç»ƒå‚æ•°
- ä¾¿äºå¿«é€Ÿè°ƒæ•´å’Œå®éªŒ

**ç‰¹ç‚¹ / Features:**
- ä» `train_config.py` è¯»å–é…ç½®
- æ˜¾ç¤ºé…ç½®æ‘˜è¦å’Œæ€§èƒ½å»ºè®®
- è®­ç»ƒå‰ç¡®è®¤

**è¾“å‡º / Output:**
- æ¨¡å‹ï¼š`trained_models_cnn_v2_{device}/`
- æ—¥å¿—ï¼š`logs/PPO_CNN_V2/`

---

#### `train_cnn_curriculum.py` ğŸš‚ğŸ“š (è¯¾ç¨‹å­¦ä¹ )
**åŠŸèƒ½ / Function:**
- æ¸è¿›å¼è®­ç»ƒç­–ç•¥
- ä»å°æ£‹ç›˜é€æ­¥å¢åŠ åˆ°å¤§æ£‹ç›˜
- æ›´é«˜çš„æ ·æœ¬æ•ˆç‡

**è®­ç»ƒé˜¶æ®µ / Training Stages:**
```python
Stage 0: 6Ã—6  æ£‹ç›˜ (5M steps)   - å­¦ä¹ åŸºæœ¬ç§»åŠ¨
Stage 1: 8Ã—8  æ£‹ç›˜ (10M steps)  - å‘å±•ç­–ç•¥
Stage 2: 10Ã—10 æ£‹ç›˜ (20M steps) - å¤„ç†å¤æ‚æ€§
Stage 3: 12Ã—12 æ£‹ç›˜ (50M steps) - æŒæ¡å®Œæ•´æ¸¸æˆ
```

**ä¼˜åŠ¿ / Advantages:**
- æ›´å¿«çš„åˆæœŸå­¦ä¹ 
- æ›´ç¨³å®šçš„è®­ç»ƒè¿‡ç¨‹
- è¿ç§»å­¦ä¹ æ•ˆæœ

**è¾“å‡º / Output:**
- æ¨¡å‹ï¼š`trained_models_cnn_curriculum/stage_X_size_Y/`
- æ—¥å¿—ï¼š`logs/PPO_CNN_CURRICULUM/`

---

#### `train_mlp.py` ğŸš‚ğŸ§  (MLPè®­ç»ƒ)
**åŠŸèƒ½ / Function:**
- MLPæ¨¡å‹è®­ç»ƒè„šæœ¬
- ä½¿ç”¨ `snake_game_custom_wrapper_mlp.py`
- è®­ç»ƒé€Ÿåº¦æœ€å¿«

**è®­ç»ƒé…ç½® / Training Config:**
- ç¯å¢ƒæ•°ï¼š32
- æ€»æ­¥æ•°ï¼š100M
- è§‚å¯Ÿç©ºé—´ï¼š13ç»´å‘é‡

**è¾“å‡º / Output:**
- æ¨¡å‹ï¼š`trained_models_mlp/`
- æ—¥å¿—ï¼š`logs/PPO_MLP/`

---

### 4ï¸âƒ£ æµ‹è¯•å±‚ / Testing Layer

#### `test_cnn.py` ğŸ§ª
**åŠŸèƒ½ / Function:**
- æµ‹è¯•åŸå§‹CNNæ¨¡å‹
- å¯è§†åŒ–æ™ºèƒ½ä½“è¡¨ç°
- ç»Ÿè®¡æ€§èƒ½æŒ‡æ ‡

**ä½¿ç”¨æ–¹æ³• / Usage:**
```bash
python test_cnn.py
```

---

#### `test_cnn_v2.py` ğŸ§ªâœ¨ (å¢å¼ºæµ‹è¯•)
**åŠŸèƒ½ / Function:**
- æµ‹è¯•æ”¹è¿›çš„CNNæ¨¡å‹
- æ”¯æŒå•æ¨¡å‹æµ‹è¯•å’Œå¤šæ¨¡å‹å¯¹æ¯”
- è¯¦ç»†çš„ç»Ÿè®¡åˆ†æ

**ä½¿ç”¨æ–¹æ³• / Usage:**
```bash
# å•æ¨¡å‹æµ‹è¯•
python test_cnn_v2.py model.zip [episodes] [render] [delay]

# å¤šæ¨¡å‹å¯¹æ¯”
python test_cnn_v2.py --compare model1.zip model2.zip [episodes]
```

**è¾“å‡ºæŒ‡æ ‡ / Output Metrics:**
- å¹³å‡å¥–åŠ± (Average Reward)
- å¹³å‡å›åˆé•¿åº¦ (Average Length)
- å¹³å‡/æœ€å¤§è›‡é•¿åº¦ (Avg/Max Snake Size)
- èƒœç‡ (Win Rate)

---

#### `test_mlp.py` ğŸ§ªğŸ§ 
**åŠŸèƒ½ / Function:**
- æµ‹è¯•MLPæ¨¡å‹
- ä¸CNNç‰ˆæœ¬ç±»ä¼¼çš„åŠŸèƒ½

---

### 5ï¸âƒ£ åŸºå‡†ç®—æ³• / Baseline Algorithm

#### `hamiltonian_agent.py` ğŸ”„
**åŠŸèƒ½ / Function:**
- å“ˆå¯†å°”é¡¿å›è·¯ç®—æ³•å®ç°
- ç†è®ºä¸Šå¯ä»¥100%å®Œæˆæ¸¸æˆ
- ä½œä¸ºæ€§èƒ½ä¸Šé™å‚è€ƒ

**ç®—æ³•åŸç† / Algorithm:**
- ç”Ÿæˆè¦†ç›–æ•´ä¸ªæ£‹ç›˜çš„å“ˆå¯†å°”é¡¿å›è·¯
- è›‡æ²¿ç€å›ºå®šè·¯å¾„ç§»åŠ¨
- ä¿è¯ä¸ä¼šæ’åˆ°è‡ªå·±

**ç”¨é€” / Purpose:**
- æ€§èƒ½åŸºå‡†å¯¹æ¯”
- éªŒè¯ç¯å¢ƒæ­£ç¡®æ€§
- ç†è®ºä¸Šé™å‚è€ƒ

---

## æ•°æ®æµå›¾ / Data Flow Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ snake_game.pyâ”‚  â† æ¸¸æˆæ ¸å¿ƒ / Game Core
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚                                 â”‚
â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ wrapper_cnn.py  â”‚            â”‚ wrapper_mlp.py  â”‚
â”‚ wrapper_cnn_v2  â”‚            â”‚                 â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                                 â”‚
       â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
       â”‚          â”‚          â”‚          â”‚
â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â” â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â” â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â” â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”
â”‚train_cnn â”‚ â”‚train_v2â”‚ â”‚train   â”‚ â”‚train   â”‚
â”‚          â”‚ â”‚        â”‚ â”‚simple  â”‚ â”‚mlp     â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”˜ â””â”€â”€â”€â”¬â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”¬â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
       â”‚         â”‚          â”‚          â”‚
       â”‚         â”‚          â”‚          â”‚
       â–¼         â–¼          â–¼          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Trained Models / è®­ç»ƒæ¨¡å‹         â”‚
â”‚  trained_models_cnn/                    â”‚
â”‚  trained_models_cnn_v2_{device}/        â”‚
â”‚  trained_models_mlp/                    â”‚
â”‚  trained_models_cnn_curriculum/         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Testing / æµ‹è¯•                   â”‚
â”‚  test_cnn.py                            â”‚
â”‚  test_cnn_v2.py                         â”‚
â”‚  test_mlp.py                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## è®­ç»ƒæµç¨‹ / Training Pipeline

```
1. åˆå§‹åŒ– / Initialization
   â”œâ”€ åˆ›å»ºå¤šä¸ªå¹¶è¡Œç¯å¢ƒ (SubprocVecEnv)
   â”œâ”€ åˆå§‹åŒ–PPOæ¨¡å‹
   â””â”€ è®¾ç½®å›è°ƒå‡½æ•° (Checkpoint, Eval)

2. æ•°æ®æ”¶é›†é˜¶æ®µ / Rollout Phase
   â”œâ”€ 64ä¸ªå­è¿›ç¨‹å¹¶è¡Œè¿è¡Œæ¸¸æˆ
   â”œâ”€ æ¯ä¸ªç¯å¢ƒæ”¶é›†2048æ­¥æ•°æ®
   â”œâ”€ ä½¿ç”¨å½“å‰ç­–ç•¥é€‰æ‹©åŠ¨ä½œ
   â””â”€ è®°å½• (çŠ¶æ€, åŠ¨ä½œ, å¥–åŠ±, ä¸‹ä¸€çŠ¶æ€)

3. è®­ç»ƒæ›´æ–°é˜¶æ®µ / Training Phase
   â”œâ”€ æ”¶é›†æ‰€æœ‰ç¯å¢ƒçš„æ•°æ® (64 Ã— 2048 = 131Kæ­¥)
   â”œâ”€ è®¡ç®—ä¼˜åŠ¿å‡½æ•° (GAE)
   â”œâ”€ è¿›è¡Œ10ä¸ªepochçš„ç­–ç•¥æ›´æ–°
   â”‚  â”œâ”€ æ‰¹æ¬¡å¤§å°: 1024
   â”‚  â”œâ”€ è®¡ç®—ç­–ç•¥æ¢¯åº¦
   â”‚  â”œâ”€ æ›´æ–°ç¥ç»ç½‘ç»œæƒé‡
   â”‚  â””â”€ è£å‰ªæ¢¯åº¦
   â””â”€ æ›´æ–°ä»·å€¼å‡½æ•°

4. è¯„ä¼°ä¸ä¿å­˜ / Evaluation & Saving
   â”œâ”€ æ¯500Kæ­¥è¯„ä¼°ä¸€æ¬¡
   â”œâ”€ ä¿å­˜æœ€ä½³æ¨¡å‹
   â””â”€ æ¯1Mæ­¥ä¿å­˜æ£€æŸ¥ç‚¹

5. å¾ªç¯ / Loop
   â””â”€ é‡å¤æ­¥éª¤2-4ç›´åˆ°è¾¾åˆ°æ€»æ­¥æ•°
```

---

## ç›®å½•ç»“æ„ / Directory Structure

```
main/
â”œâ”€â”€ ğŸ“„ æ ¸å¿ƒæ–‡ä»¶ / Core Files
â”‚   â”œâ”€â”€ snake_game.py                    # æ¸¸æˆæ ¸å¿ƒ
â”‚   â”œâ”€â”€ snake_game_custom_wrapper_cnn.py # CNNåŒ…è£…å™¨(åŸå§‹)
â”‚   â”œâ”€â”€ snake_game_custom_wrapper_cnn_v2.py # CNNåŒ…è£…å™¨(æ”¹è¿›)
â”‚   â””â”€â”€ snake_game_custom_wrapper_mlp.py # MLPåŒ…è£…å™¨
â”‚
â”œâ”€â”€ ğŸš‚ è®­ç»ƒè„šæœ¬ / Training Scripts
â”‚   â”œâ”€â”€ train_config.py                  # é…ç½®ä¸­å¿ƒ
â”‚   â”œâ”€â”€ train_cnn.py                     # CNNè®­ç»ƒ(åŸå§‹)
â”‚   â”œâ”€â”€ train_cnn_v2.py                  # CNNè®­ç»ƒ(æ”¹è¿›)
â”‚   â”œâ”€â”€ train_cnn_simple.py              # ç®€åŒ–è®­ç»ƒ
â”‚   â”œâ”€â”€ train_cnn_curriculum.py          # è¯¾ç¨‹å­¦ä¹ 
â”‚   â””â”€â”€ train_mlp.py                     # MLPè®­ç»ƒ
â”‚
â”œâ”€â”€ ğŸ§ª æµ‹è¯•è„šæœ¬ / Testing Scripts
â”‚   â”œâ”€â”€ test_cnn.py                      # CNNæµ‹è¯•
â”‚   â”œâ”€â”€ test_cnn_v2.py                   # CNNæµ‹è¯•(å¢å¼º)
â”‚   â””â”€â”€ test_mlp.py                      # MLPæµ‹è¯•
â”‚
â”œâ”€â”€ ğŸ”„ åŸºå‡†ç®—æ³• / Baseline
â”‚   â””â”€â”€ hamiltonian_agent.py             # å“ˆå¯†å°”é¡¿å›è·¯
â”‚
â”œâ”€â”€ ğŸ“ è¾“å‡ºç›®å½• / Output Directories
â”‚   â”œâ”€â”€ trained_models_cnn/              # CNNæ¨¡å‹(åŸå§‹)
â”‚   â”œâ”€â”€ trained_models_cnn_v2_mps/       # CNNæ¨¡å‹(æ”¹è¿›,MPS)
â”‚   â”œâ”€â”€ trained_models_cnn_v2_cuda/      # CNNæ¨¡å‹(æ”¹è¿›,CUDA)
â”‚   â”œâ”€â”€ trained_models_mlp/              # MLPæ¨¡å‹
â”‚   â”œâ”€â”€ trained_models_cnn_curriculum/   # è¯¾ç¨‹å­¦ä¹ æ¨¡å‹
â”‚   â””â”€â”€ logs/                            # TensorBoardæ—¥å¿—
â”‚       â”œâ”€â”€ PPO_CNN/
â”‚       â”œâ”€â”€ PPO_CNN_V2/
â”‚       â”œâ”€â”€ PPO_CNN_CURRICULUM/
â”‚       â””â”€â”€ PPO_MLP/
â”‚
â””â”€â”€ ğŸ”Š èµ„æºæ–‡ä»¶ / Resources
    â””â”€â”€ sound/                           # éŸ³æ•ˆæ–‡ä»¶
        â”œâ”€â”€ eat.wav
        â”œâ”€â”€ game_over.wav
        â””â”€â”€ victory.wav
```

---

## æ¨èä½¿ç”¨æµç¨‹ / Recommended Workflow

### æ–°æ‰‹å…¥é—¨ / Beginner
```bash
1. å¿«é€Ÿæµ‹è¯•å·²æœ‰æ¨¡å‹
   python test_cnn.py

2. çŸ­æ—¶é—´è®­ç»ƒä½“éªŒ
   # ä¿®æ”¹ train_config.py: TOTAL_TIMESTEPS = 10_000_000
   python train_cnn_simple.py

3. æŸ¥çœ‹è®­ç»ƒæ›²çº¿
   tensorboard --logdir logs
```

### æ ‡å‡†è®­ç»ƒ / Standard Training
```bash
1. ä½¿ç”¨æ”¹è¿›ç‰ˆæœ¬è®­ç»ƒ
   python train_cnn_v2.py

2. ç›‘æ§è®­ç»ƒè¿›åº¦
   tensorboard --logdir logs/PPO_CNN_V2

3. æµ‹è¯•è®­ç»ƒç»“æœ
   python test_cnn_v2.py trained_models_cnn_v2_mps/ppo_snake_final_v2.zip
```

### é«˜çº§ä¼˜åŒ– / Advanced Optimization
```bash
1. è°ƒæ•´é…ç½®å‚æ•°
   ç¼–è¾‘ train_config.py

2. ä½¿ç”¨è¯¾ç¨‹å­¦ä¹ 
   python train_cnn_curriculum.py

3. å¯¹æ¯”å¤šä¸ªæ¨¡å‹
   python test_cnn_v2.py --compare model1.zip model2.zip model3.zip
```

---

## æ€§èƒ½å¯¹æ¯” / Performance Comparison

| æ¨¡å‹ | è§‚å¯Ÿç©ºé—´ | è®­ç»ƒé€Ÿåº¦ | æœ€ç»ˆå¥–åŠ± | æ¨èåœºæ™¯ |
|------|----------|----------|----------|----------|
| MLP | 13ç»´å‘é‡ | âš¡âš¡âš¡ | ~17 | å¿«é€ŸåŸå‹ |
| CNN (åŸå§‹) | 84Ã—84Ã—3 | âš¡ | ~13 | åŸºå‡†æµ‹è¯• |
| CNN V2 (æ”¹è¿›) | 84Ã—84Ã—3 | âš¡âš¡ | ~15+ | **ç”Ÿäº§ç¯å¢ƒ** â­ |
| Curriculum | 84Ã—84Ã—3 | âš¡âš¡ | ~14-16 | ç¨³å®šè®­ç»ƒ |
| Hamiltonian | - | - | ç†è®º100% | æ€§èƒ½ä¸Šé™ |

---

## å…³é”®æŠ€æœ¯ç‚¹ / Key Technical Points

### 1. å¹¶è¡Œè®­ç»ƒ / Parallel Training
- ä½¿ç”¨ `SubprocVecEnv` åˆ›å»ºå¤šä¸ªå¹¶è¡Œç¯å¢ƒ
- æ¯ä¸ªç¯å¢ƒåœ¨ç‹¬ç«‹è¿›ç¨‹ä¸­è¿è¡Œ
- æ˜¾è‘—åŠ é€Ÿæ•°æ®æ”¶é›†

### 2. åŠ¨ä½œæ©ç  / Action Masking
- ä½¿ç”¨ `ActionMasker` é˜²æ­¢éæ³•åŠ¨ä½œ
- é¿å…è›‡åå‘ç§»åŠ¨æˆ–æ’å¢™
- æé«˜è®­ç»ƒæ•ˆç‡

### 3. å¥–åŠ±å¡‘å½¢ / Reward Shaping
- V2ç‰ˆæœ¬ä½¿ç”¨æ›´å¤§çš„å¥–åŠ±å€¼
- æ˜ç¡®çš„æ­£è´Ÿåé¦ˆ
- æ ¹æ®è¿›åº¦ç¼©æ”¾æƒ©ç½š

### 4. è¯¾ç¨‹å­¦ä¹  / Curriculum Learning
- ä»ç®€å•ä»»åŠ¡å¼€å§‹
- é€æ­¥å¢åŠ éš¾åº¦
- è¿ç§»å­¦ä¹ æé«˜æ•ˆç‡

### 5. å­¦ä¹ ç‡è°ƒåº¦ / Learning Rate Scheduling
- çº¿æ€§è¡°å‡: 3e-4 â†’ 1e-6
- åˆæœŸå¿«é€Ÿå­¦ä¹ 
- åæœŸç²¾ç»†è°ƒæ•´

---

## å¸¸è§é—®é¢˜ / FAQ

### Q: ä¸ºä»€ä¹ˆæœ‰è¿™ä¹ˆå¤šPythonè¿›ç¨‹ï¼Ÿ
A: æ¯ä¸ªå¹¶è¡Œç¯å¢ƒè¿è¡Œåœ¨ç‹¬ç«‹è¿›ç¨‹ä¸­ã€‚64ä¸ªç¯å¢ƒ = 64ä¸ªå­è¿›ç¨‹ + 1ä¸ªä¸»è¿›ç¨‹ã€‚

### Q: è®­ç»ƒéœ€è¦å¤šé•¿æ—¶é—´ï¼Ÿ
A: 100Mæ­¥çº¦éœ€8-12å°æ—¶ï¼ˆå–å†³äºç¡¬ä»¶ï¼‰ã€‚å¯åœ¨ `train_config.py` ä¸­è°ƒæ•´ã€‚

### Q: å“ªä¸ªæ¨¡å‹æœ€å¥½ï¼Ÿ
A: æ¨èä½¿ç”¨ `train_cnn_v2.py`ï¼Œå®ƒæœ‰æ”¹è¿›çš„å¥–åŠ±å‡½æ•°å’Œè¶…å‚æ•°ã€‚

### Q: å¦‚ä½•åŠ é€Ÿè®­ç»ƒï¼Ÿ
A: 1) å¢åŠ å¹¶è¡Œç¯å¢ƒæ•° 2) ä½¿ç”¨GPU/MPS 3) å‡å°‘æ€»æ­¥æ•°

### Q: å¦‚ä½•æé«˜æ€§èƒ½ï¼Ÿ
A: 1) è°ƒæ•´å¥–åŠ±å‡½æ•° 2) ä½¿ç”¨è¯¾ç¨‹å­¦ä¹  3) å¢åŠ è®­ç»ƒæ—¶é—´

---

## ä¾èµ–å…³ç³»å›¾ / Dependency Graph

```
pygame â”€â”€â”
numpy â”€â”€â”€â”¼â”€â”€> snake_game.py
random â”€â”€â”˜         â”‚
                   â”‚
gymnasium â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€> wrapper_*.py
numpy â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
                             â”‚
torch â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
stable_baselines3 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€> train_*.py
sb3_contrib â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
                             â”‚
                             â–¼
                      Trained Models
                             â”‚
                             â–¼
                       test_*.py
```

---

## ç‰ˆæœ¬å†å² / Version History

### V1 (Original)
- åŸºç¡€CNNå’ŒMLPå®ç°
- åŸå§‹å¥–åŠ±å‡½æ•°
- åŸºå‡†æ€§èƒ½

### V2 (Improved)
- æ”¹è¿›çš„å¥–åŠ±å‡½æ•°
- æ›´å¥½çš„è¶…å‚æ•°
- è¯„ä¼°å›è°ƒ
- é…ç½®ä¸­å¿ƒ

### V3 (Curriculum)
- è¯¾ç¨‹å­¦ä¹ ç­–ç•¥
- æ¸è¿›å¼è®­ç»ƒ
- æ›´é«˜æ ·æœ¬æ•ˆç‡

---

## è´¡çŒ®æŒ‡å— / Contributing

### æ·»åŠ æ–°çš„è®­ç»ƒç­–ç•¥
1. åˆ›å»ºæ–°çš„ wrapper (å¦‚éœ€è¦)
2. åˆ›å»ºæ–°çš„ train è„šæœ¬
3. æ›´æ–°æ­¤æ–‡æ¡£

### ä¼˜åŒ–å¥–åŠ±å‡½æ•°
1. ä¿®æ”¹ `snake_game_custom_wrapper_*.py`
2. åœ¨ `step()` æ–¹æ³•ä¸­è°ƒæ•´å¥–åŠ±è®¡ç®—
3. æµ‹è¯•å¹¶å¯¹æ¯”æ€§èƒ½

### è°ƒæ•´è¶…å‚æ•°
1. ç¼–è¾‘ `train_config.py`
2. æˆ–ç›´æ¥ä¿®æ”¹è®­ç»ƒè„šæœ¬
3. è®°å½•å®éªŒç»“æœ

---

## å‚è€ƒèµ„æ–™ / References

- [Stable-Baselines3 Documentation](https://stable-baselines3.readthedocs.io/)
- [Gymnasium Documentation](https://gymnasium.farama.org/)
- [PPO Paper](https://arxiv.org/abs/1707.06347)
- [Reward Shaping](https://people.eecs.berkeley.edu/~pabbeel/cs287-fa09/readings/NgHaradaRussell-shaping-ICML1999.pdf)

---

**æœ€åæ›´æ–° / Last Updated:** 2024-12-09
**ç»´æŠ¤è€… / Maintainer:** Snake AI Team
